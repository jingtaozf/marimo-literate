 -*- Mode: POLY-ORG ;  indent-tabs-mode: nil; lsp-diagnostics-provider: :none -*- ---
#+Title: ast
#+OPTIONS: tex:verbatim toc:nil \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+STARTUP: noindent
#+STARTUP: inlineimages
#+PROPERTY: literate-lang python
#+PROPERTY: literate-load yes
#+PROPERTY: literate-insert-header no
#+PROPERTY: header-args :results silent :session
#+PROPERTY: LITERATE_ORG_LANGUAGE python
#+PROPERTY: LITERATE_ORG_ROOT_MODULE marimo._runtime
#+PROPERTY: LITERATE_ORG_ROOT_MODULE_PATH ~/projects/marimo
#+PROPERTY: LITERATE_ORG_MODULE_CREATE_METHOD import
* __init__
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.__init__
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/__init__.py
:END:
** Comment
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.

#+END_SRC
* app_meta
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.app_meta
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/app_meta.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import Literal, Optional

from marimo._config.utils import load_config
from marimo._runtime.context.utils import get_mode

#+END_SRC
** Class AppMeta
#+BEGIN_SRC python
class AppMeta:
    """
    Metadata about the app.

    This class provides access to runtime metadata about a marimo app, such as
    its display theme and execution mode.
    """

    def __init__(self) -> None:
        self.user_config = load_config()

    @property
    def theme(self) -> str:
        """The display theme of the app.

        Returns either "light" or "dark". If the user's configuration is set to
        "system", currently returns "light".

        **Examples**:

        Get the current theme and conditionally set a plotting library's theme:

        ```python
        import altair as alt

        # Enable dark theme for Altair when marimo is in dark mode
        alt.themes.enable(
            "dark" if mo.app_meta().theme == "dark" else "default"
        )
        ```

        **Returns**:

        - "light" or "dark", indicating the app's display theme
        """
        theme = self.user_config["display"]["theme"] or "light"
        if theme == "system":
            # TODO(mscolnick): have frontend tell the backend the system theme
            return "light"
        return theme

    @property
    def mode(self) -> Optional[Literal["edit", "run", "script"]]:
        """The execution mode of the app.

         **Examples**:

        Show content only in edit mode:

        ```python
        # Only show this content when editing the notebook
        mo.md("# Developer Notes") if mo.app_meta().mode == "edit" else None
        ```

        **Returns**:

        - "edit": The notebook is being edited in the marimo editor
        - "run": The notebook is being run as an app
        - "script": The notebook is being run as a script
        - None: The mode could not be determined
        """
        return get_mode()

#+END_SRC
* capture
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.capture
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/capture.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
import contextlib
import io
import sys
from typing import Iterator

from marimo._plugins.stateless.plain_text import plain_text
from marimo._runtime.output import _output

#+END_SRC
** @contextlib.contextmanager: Function capture_stdout
#+BEGIN_SRC python
@contextlib.contextmanager
def capture_stdout() -> Iterator[io.StringIO]:
    """Capture standard output.

    Use this context manager to capture print statements and
    other output sent to standard output.

    **Example.**

    ```python
    with mo.capture_stdout() as buffer:
        print("Hello!")
    output = buffer.getvalue()
    ```
    """
    with contextlib.redirect_stdout(io.StringIO()) as buffer:
        yield buffer

#+END_SRC
** @contextlib.contextmanager: Function capture_stderr
#+BEGIN_SRC python
@contextlib.contextmanager
def capture_stderr() -> Iterator[io.StringIO]:
    """Capture standard error.

    Use this context manager to capture output sent to standard error.

    **Example.**

    ```python
    with mo.capture_stderr() as buffer:
        sys.stderr.write("Hello!")
    output = buffer.getvalue()
    ```
    """
    with contextlib.redirect_stderr(io.StringIO()) as buffer:
        yield buffer

#+END_SRC
** Function _redirect
#+BEGIN_SRC python
def _redirect(msg: str) -> None:
    _output.append(plain_text(msg))

#+END_SRC
** @contextlib.contextmanager: Function redirect_stdout
#+BEGIN_SRC python
@contextlib.contextmanager
def redirect_stdout() -> Iterator[None]:
    """Redirect stdout to a cell's output area.

    ```python
    with mo.redirect_stdout():
        # These print statements will show up in the cell's output area
        print("Hello!")
        print("World!")
    ```
    """
    old_stdout_write = sys.stdout.write
    sys.stdout.write = _redirect  # type: ignore
    try:
        yield
    finally:
        sys.stdout.write = old_stdout_write  # type: ignore

#+END_SRC
** @contextlib.contextmanager: Function redirect_stderr
#+BEGIN_SRC python
@contextlib.contextmanager
def redirect_stderr() -> Iterator[None]:
    """Redirect `stderr` to a cell's output area.

    ```python
    with mo.redirect_stderr():
        # These messages will show up in the cell's output area
        sys.stderr.write("Hello!")
        sys.stderr.write("World!")
    ```
    """
    old_stderr_write = sys.stderr.write
    sys.stderr.write = _redirect  # type: ignore
    try:
        yield
    finally:
        sys.stderr.write = old_stderr_write  # type: ignore

#+END_SRC
* cell_lifecycle_item
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.cell_lifecycle_item
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/cell_lifecycle_item.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import abc
from typing import TYPE_CHECKING

#+END_SRC
** Class CellLifecycleItem
#+BEGIN_SRC python
if TYPE_CHECKING:
    from marimo._runtime.context.types import RuntimeContext


class CellLifecycleItem(abc.ABC):
    @abc.abstractmethod
    def create(self, context: "RuntimeContext") -> None:
        """Create this item

        This method is executed at the beginning of a cell's lifecycle.
        Use it to run side-effects or create state.
        """
        ...

    @abc.abstractmethod
    def dispose(self, context: "RuntimeContext", deletion: bool) -> bool:
        """Dispose this item

        This method is executed at the end of a cell's lifecycle. Use
        it to clean-up side-effects or state associated with the lifecycle
        item.

        The `deletion` flag indicates whether the cell is being removed
        from the graph, which may influence disposal strategy.

        Return True if the disposal is successful and the lifecycle item
        should be removed from the registry. Return False if the disposal
        needs to be retried in the next cell lifecycle (note that `create`
        will not be re-run, only `dispose`).
        """
        ...

#+END_SRC
* cell_lifecycle_registry
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.cell_lifecycle_registry
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/cell_lifecycle_registry.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import dataclasses

from marimo._ast.cell import CellId_t
from marimo._runtime.cell_lifecycle_item import CellLifecycleItem

#+END_SRC
** @dataclasses.dataclass: Class CellLifecycleRegistry
#+BEGIN_SRC python
@dataclasses.dataclass
class CellLifecycleRegistry:
    registry: dict[CellId_t, set[CellLifecycleItem]] = dataclasses.field(
        default_factory=dict
    )

    def add(self, item: CellLifecycleItem) -> None:
        """Add a lifecycle item for the currently running cell.

        Calls the item's create method upon adding. No-op if no cell
        is running.
        """
        from marimo._runtime.context import get_context

        ctx = get_context()

        cell_id = ctx.cell_id
        if cell_id is None:
            return

        if cell_id not in self.registry:
            self.registry[cell_id] = set()
        item.create(ctx)
        self.registry[cell_id].add(item)

    def dispose(self, cell_id: CellId_t, deletion: bool) -> None:
        """Dispose lifecycle items associated with `cell_id`

        Calls `dispose` hooks and clears items from the registry.

        If `deletion` is `True`, the cell is being removed from the graph.
        """
        from marimo._runtime.context import get_context

        ctx = get_context()
        # LifecycleItems can request that their `dispose` method is retried in
        # the next cell lifecycle; these items are persisted.
        persisted_lifecycle_items = set()
        if cell_id in self.registry:
            for lifecycle_item in self.registry[cell_id]:
                if not lifecycle_item.dispose(context=ctx, deletion=deletion):
                    persisted_lifecycle_items.add(lifecycle_item)

            if persisted_lifecycle_items:
                self.registry[cell_id] = persisted_lifecycle_items
            else:
                del self.registry[cell_id]

#+END_SRC
* complete
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.complete
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/complete.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import html
import threading
import time
from typing import TYPE_CHECKING, Any, cast

import jedi  # type: ignore # noqa: F401
import jedi.api  # type: ignore # noqa: F401

from marimo import _loggers as loggers
from marimo._messaging.completion_option import CompletionOption
from marimo._messaging.ops import CompletionResult
from marimo._messaging.types import Stream
from marimo._output.md import _md
from marimo._runtime import dataflow
from marimo._runtime.requests import CodeCompletionRequest
from marimo._server.types import QueueType
from marimo._utils.format_signature import format_signature
from marimo._utils.rst_to_html import convert_rst_to_html

#+END_SRC
** Assignment LOGGER = loggers.marimo_logger()
#+BEGIN_SRC python
if TYPE_CHECKING:
    import threading

LOGGER = loggers.marimo_logger()

#+END_SRC
** Assignment jedi.settings.allow_unsafe_interpreter_executions = False
#+BEGIN_SRC python
# Don't execute properties or __get_item__: when falling back to the Jedi
# interpreter, this leads to an incorrect type hint of properties as modules,
# but at least it prevents execution of side-effecting code.
jedi.settings.allow_unsafe_interpreter_executions = False

#+END_SRC
** Function _is_dunder_name
#+BEGIN_SRC python
def _is_dunder_name(name: str) -> bool:
    return name.startswith("__") and name.endswith("__")

#+END_SRC
** Function _should_include_name
#+BEGIN_SRC python
def _should_include_name(name: str, prefix: str) -> bool:
    """Exclude names starting with an underscore, except dunder names."""
    is_dunder_name = _is_dunder_name(name)
    if name.startswith("_"):
        if not is_dunder_name:
            # Never include names that start with a single underscore
            return False
        elif not prefix.startswith("_"):
            return False
        else:
            # Only include dunder names when prefix starts with an underscore
            return True
    else:
        return True

#+END_SRC
** Function _get_docstring
#+BEGIN_SRC python
def _get_docstring(completion: jedi.api.classes.BaseName) -> str:
    try:
        body = cast(str, completion.docstring(raw=True))
    except Exception:
        LOGGER.debug("Failed to get docstring for %s", completion.name)
        return ""

    if completion.type == "function":
        prefix = "def "
    elif completion.type == "class":
        prefix = "class "
    else:
        prefix = ""

    try:
        signature_text = "\n\n".join(
            [
                format_signature(prefix, s.to_string())
                for s in completion.get_signatures()
            ]
        )
    except Exception:
        LOGGER.debug("Maybe failed getting signature for %s", completion.name)
        return ""

    if completion.type == "module" and not signature_text:
        signature_text = "module " + completion.name
    elif completion.type == "keyword" and not signature_text:
        signature_text = "keyword " + completion.name

    if signature_text:
        signature_text = _md(
            "```python3\n" + signature_text + "\n```",
            apply_markdown_class=False,
        ).text

    if body:
        # for marimo docstrings, treat them as markdown
        # for other modules, treat them as plain text
        if completion.module_name.startswith("marimo"):
            body = _md(body, apply_markdown_class=False).text
        else:
            try:
                body = (
                    "<div class='external-docs'>"
                    + convert_rst_to_html(body)
                    + "</div>"
                )
            except Exception as e:
                # if docutils chokes, we don't want to crash the completion
                # worker
                LOGGER.debug("Converting RST to HTML failed: ", e)
                body = (
                    "<pre class='external-docs'>"
                    + html.escape(body)
                    + "</pre>"
                )

    if signature_text and body:
        docstring = signature_text + "\n\n" + body
    else:
        docstring = signature_text + body

    if completion.type == "class":
        # Append the __init__ docstring.
        definitions = completion.goto()
        if (
            definitions
            and len(definitions) == 1
            and isinstance(definitions[0], jedi.api.classes.Name)
        ):
            name = definitions[0]
            for subname in name.defined_names():
                if subname.name.endswith("__init__"):
                    init_docstring = subname.docstring(raw=True)
                    if init_docstring:
                        init_docstring = (
                            "__init__ docstring:\n\n"
                            + _md(
                                init_docstring, apply_markdown_class=False
                            ).text
                        )
                    if docstring and init_docstring:
                        docstring += "\n\n" + init_docstring
                    else:
                        docstring += init_docstring

    return docstring

#+END_SRC
** Function _get_type_hint
#+BEGIN_SRC python
def _get_type_hint(completion: jedi.api.classes.BaseName) -> str:
    try:
        type_hint = cast(str, completion.get_type_hint())
    except Exception:
        # sometimes Jedi unexpectedly fails
        return ""

    if type_hint:
        return cast(str, completion.name) + ": " + type_hint
    else:
        return ""

#+END_SRC
** Function _get_completion_info
#+BEGIN_SRC python
def _get_completion_info(completion: jedi.api.classes.BaseName) -> str:
    if completion.type != "statement":
        try:
            return _get_docstring(completion)
        except Exception as e:
            LOGGER.debug("jedi failed to get docstring: %s", str(e))
            return ""
    else:
        try:
            return _get_type_hint(completion)
        except Exception as e:
            LOGGER.debug("jedi failed to get type hint: %s", str(e))
            return ""

#+END_SRC
** Function _get_completion_option
#+BEGIN_SRC python
def _get_completion_option(
    completion: jedi.api.classes.Completion,
    script: jedi.Script,
    compute_completion_info: bool,
) -> CompletionOption:
    name = completion.name
    kind = completion.type

    if compute_completion_info:
        # Choose whether the completion info should be from the name
        # or the enclosing function's signature, if any
        symbol_to_lookup = completion
        if completion.type == "param":
            # Show the function/class docstring if available
            signatures = script.get_signatures()
            if len(signatures) == 1:
                symbol_to_lookup = signatures[0]
        completion_info = _get_completion_info(symbol_to_lookup)
    else:
        completion_info = ""

    return CompletionOption(
        name=name, type=kind, completion_info=completion_info
    )

#+END_SRC
** Function _get_completion_options
#+BEGIN_SRC python
def _get_completion_options(
    completions: list[jedi.api.classes.Completion],
    script: jedi.Script,
    prefix: str,
    limit: int,
    timeout: float,
) -> list[CompletionOption]:
    if len(completions) > limit:
        return [
            _get_completion_option(
                completion, script, compute_completion_info=False
            )
            for completion in completions
            if _should_include_name(completion.name, prefix)
        ]

    completion_options: list[CompletionOption] = []
    start_time = time.time()
    for completion in completions:
        if not _should_include_name(completion.name, prefix):
            continue
        elapsed_time = time.time() - start_time
        completion_options.append(
            _get_completion_option(
                completion,
                script,
                compute_completion_info=elapsed_time < timeout,
            )
        )
    return completion_options

#+END_SRC
** Function _write_completion_result
#+BEGIN_SRC python
def _write_completion_result(
    stream: Stream,
    completion_id: str,
    prefix_length: int,
    options: list[CompletionOption],
) -> None:
    CompletionResult(
        completion_id=completion_id,
        prefix_length=prefix_length,
        options=options,
    ).broadcast(stream=stream)

#+END_SRC
** Function _write_no_completions
#+BEGIN_SRC python
def _write_no_completions(stream: Stream, completion_id: str) -> None:
    _write_completion_result(stream, completion_id, 0, [])

#+END_SRC
** Function _drain_queue
#+BEGIN_SRC python
def _drain_queue(
    completion_queue: QueueType[CodeCompletionRequest],
) -> CodeCompletionRequest:
    """Drain the queue of completion requests, returning the most recent one"""

    request = completion_queue.get()
    while not completion_queue.empty():
        request = completion_queue.get()
    return request

#+END_SRC
** Function _get_completions_with_script
#+BEGIN_SRC python
def _get_completions_with_script(
    codes: list[str], document: str
) -> tuple[jedi.Script, list[jedi.api.classes.Completion]]:
    script = jedi.Script("\n".join(codes + [document]))
    completions = script.complete()
    return script, completions

#+END_SRC
** Function _get_completions_with_interpreter
#+BEGIN_SRC python
def _get_completions_with_interpreter(
    document: str, glbls: dict[str, Any], glbls_lock: threading.RLock
) -> tuple[jedi.Script, list[jedi.api.classes.Completion]]:
    # Jedi fails to statically analyze some libraries, like ibis,
    # so we fall back to interpreter-based completions.
    #
    # Interpreter-based completions execute code, so we need to grab a
    # lock on the globals dict. This is best-effort -- if the kernel
    # has locked globals, we simply don't complete instead of waiting
    # for the lock to be released.
    script = jedi.Interpreter(document, [glbls])
    locked = False
    completions = []
    locked = glbls_lock.acquire(blocking=False)
    if locked:
        LOGGER.debug("Completion worker acquired globals lock")
        completions = script.complete()
    return script, completions

#+END_SRC
** Function _get_completions
#+BEGIN_SRC python
def _get_completions(
    codes: list[str],
    document: str,
    glbls: dict[str, Any],
    glbls_lock: threading.RLock,
    prefer_interpreter_completion: bool,
) -> tuple[jedi.Script, list[jedi.api.classes.Completion]]:
    if prefer_interpreter_completion:
        script, completions = _get_completions_with_interpreter(
            document, glbls, glbls_lock
        )
        if not completions:
            script, completions = _get_completions_with_script(codes, document)
        return script, completions
    else:
        script, completions = _get_completions_with_script(codes, document)
        if not completions:
            script, completions = _get_completions_with_interpreter(
                document, glbls, glbls_lock
            )
        return script, completions

#+END_SRC
** Function complete
#+BEGIN_SRC python
def complete(
    request: CodeCompletionRequest,
    graph: dataflow.DirectedGraph,
    glbls: dict[str, Any],
    glbls_lock: threading.RLock,
    stream: Stream,
    docstrings_limit: int = 80,
    timeout: float | None = None,
    prefer_interpreter_completion: bool = False,
) -> None:
    """Gets code completions for a request.

    If `prefer_interpreter_completion`, a runtime-based method is used,
    falling back to a static analysis method. Otherwise the static method
    is used, with the interpreter method as a fallback.

    Static completions are safer since they don't execute code, but they
    are slower and sometimes fail. Interpreter executions are faster
    and more comprehensive, but can only be carried out when the kernel
    isn't executing or otherwise handling a request.

    **Args.**

    - `request`: the completion request
    - `graph`: dataflow graph backing the marimo program
    - `glbls`: global namespace
    - `glbls_lock`: lock protecting the global namespace, for interpreter-based
         completion
    - `stream`: Stream through which to communicate completion results
    - `docstrings_limit`: limit past which we won't attempt to fetch type hints
          and docstrings
    - `timeout`: timeout after which we'll stop fetching type hints/docstrings
    - `prefer_interpreter_completion`: whether to prefer interpreter completion
    """
    if not request.document.strip():
        _write_no_completions(stream, request.id)
        return

    with graph.lock:
        codes = [
            graph.cells[cid].code
            for cid in dataflow.topological_sort(
                graph,
                set(graph.cells.keys()) - set([request.cell_id]),
            )
        ]

    try:
        script, completions = _get_completions(
            codes,
            request.document,
            glbls,
            glbls_lock,
            prefer_interpreter_completion,
        )
        prefix_length = (
            completions[0].get_completion_prefix_length() if completions else 0
        )

        # Only complete an empty symbol (prefix length == 0) when we're
        # using dot notation; this prevents autocomplete from kicking in at
        # awkward times, such as when parentheses are first opened
        if (
            prefix_length == 0
            and len(request.document) >= 1
            and request.document[-1] != "."
        ):
            # Empty prefix, not dot notation; don't complete ...
            completions = []

            # Get docstring in function context. A bit of a hack, since
            # this isn't actually a completion, just a tooltip.
            #
            # If no completions, we might be getting a signature ...
            # for example, if the document is "mo.ui.slider(start=1,
            signatures = script.get_signatures()
            if signatures:
                _write_completion_result(
                    stream=stream,
                    completion_id=request.id,
                    prefix_length=0,
                    options=[
                        CompletionOption(
                            name=signatures[0].name,
                            type="tooltip",
                            completion_info=_get_completion_info(
                                signatures[0]
                            ),
                        )
                    ],
                )
                return

        if not completions:
            # If there are still no completions, then bail.
            _write_no_completions(stream, request.id)
            return

        prefix = request.document[-prefix_length:]
        if timeout is None and isinstance(script, jedi.Interpreter):
            # We're holding the globals lock; set a short timeout so we don't
            # block the kernel
            timeout = 1
        elif timeout is None:
            # We're not blocking the kernel so we can afford to take longer
            timeout = 2

        options = _get_completion_options(
            completions,
            script,
            prefix=prefix,
            limit=docstrings_limit,
            timeout=timeout,
        )
        _write_completion_result(
            stream=stream,
            completion_id=request.id,
            prefix_length=prefix_length,
            options=options,
        )
    except Exception as e:
        # jedi failed to provide completion
        LOGGER.debug("Completion with jedi failed: ", str(e))
        _write_no_completions(stream, request.id)
    finally:
        try:
            # if an interpreter was used, the lock might be held
            glbls_lock.release()
        except Exception:
            # RLock raises if released when not acquired.
            pass
        else:
            LOGGER.debug("Completion worker released globals lock.")

#+END_SRC
** Function completion_worker
#+BEGIN_SRC python
def completion_worker(
    completion_queue: QueueType[CodeCompletionRequest],
    graph: dataflow.DirectedGraph,
    glbls: dict[str, Any],
    glbls_lock: threading.RLock,
    stream: Stream,
) -> None:
    """Code completion worker.


    **Args:**

    - `completion_queue`: queue from which requests are pulled.
    - `graph`: dataflow graph backing the marimo program
    - `glbls`: dictionary of global variables in interpreter memory
    - `glbls_lock`: lock protecting globals
    - `stream`: stream used to communicate completion results
    """

    while True:
        request = _drain_queue(completion_queue)
        complete(
            request=request,
            graph=graph,
            glbls=glbls,
            glbls_lock=glbls_lock,
            stream=stream,
        )

#+END_SRC
* control_flow
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.control_flow
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/control_flow.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from typing import Optional

from marimo._output.rich_help import mddoc

#+END_SRC
** Class MarimoInterrupt
#+BEGIN_SRC python
class MarimoInterrupt(BaseException):
    """Raised when user stops execution of entire program with interrupt.

    Inherits from `BaseException` to prevent accidental capture with
    `except Exception` (similar to `KeyboardInterrupt`)
    """

    pass

#+END_SRC
** Class MarimoStopError
#+BEGIN_SRC python
class MarimoStopError(BaseException):
    """Raised by `marimo.stop` to stop execution of a cell and descendants.

    Inherits from `BaseException` to prevent accidental capture with
    `except Exception` (similar to `KeyboardInterrupt`)
    """

    def __init__(self, output: Optional[object]) -> None:
        self.output = output

#+END_SRC
** @mddoc: Function stop
#+BEGIN_SRC python
@mddoc
def stop(predicate: bool, output: Optional[object] = None) -> None:
    """Stops execution of a cell when `predicate` is `True`

    When `predicate` is `True`, this function raises a `MarimoStopError`. If
    uncaught, this exception stops execution of the current cell and makes
    `output` its output. Any descendants of this cell that were previously
    scheduled to run will not be run, and their defs will be removed from
    program memory.

    **Example:**

    ```python
    mo.stop(form.value is None, mo.md("**Submit the form to continue.**"))
    ```

    **Raises:**

    When `predicate` is `True`, raises a `MarimoStopError`.
    """
    if predicate:
        raise MarimoStopError(output)

#+END_SRC
* copy
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.copy
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/copy.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import inspect
import weakref
from copy import copy
from typing import (
    Any,
    Callable,
    Generic,
    Type,
    TypeVar,
    Union,
    cast,
)

#+END_SRC
** Assignment T = TypeVar("T")
#+BEGIN_SRC python
T = TypeVar("T")

#+END_SRC
** Assignment Ref = Union[weakref.ReferenceType[T], Callable[[], T]]
#+BEGIN_SRC python
Ref = Union[weakref.ReferenceType[T], Callable[[], T]]

#+END_SRC
** Class CloneError
#+BEGIN_SRC python
class CloneError(Exception):
    """Thrown when strict execution fail to deep copy or clone."""

#+END_SRC
** Class ReadOnlyError
#+BEGIN_SRC python
class ReadOnlyError(Exception):
    """Thrown when attempting to modify a read-only object."""

#+END_SRC
** Class _Copy
#+BEGIN_SRC python
class _Copy(Generic[T]):
    """Base wrapper class for strict execution."""

    __ref__: Ref[T]

#+END_SRC
** Class ZeroCopy
#+BEGIN_SRC python
class ZeroCopy(_Copy[T]):
    """Wrapper class for strict execution (stops deepcopy)."""

#+END_SRC
** Class ShallowCopy
#+BEGIN_SRC python
class ShallowCopy(_Copy[T]):
    """Wrapper class for strict execution (does copy over deepcopy)."""

#+END_SRC
** Function _ro_fail
#+BEGIN_SRC python
def _ro_fail() -> None:
    raise ReadOnlyError(
        "Weakly copied objects are directly read only."
        " Modification is not encouraged, but is"
        " possible by utilizing the marimo.unwrap_copy() function."
    )

#+END_SRC
** Function shadow_wrap
#+BEGIN_SRC python
def shadow_wrap(ref_cls: Type[_Copy[T]], base: T) -> T:
    """
    Wraps the base object by copying all attributes over to slots, and the then
    restricting write access to the object attributes / items directly. This is
    very agrressive and makes the wrapped object difficult to tell apart from
    the base object without inspect.

    However, there are some limitations, e.g. some operations of the wrapped
    object may not be associative if they are not defined for both the left
    and right operations. For instance:

    >>> a = shadow_wrap(ZeroCopy, [1, 2, 3])
    >>> b = [4, 5, 6]
    >>> a + b
    [1, 2, 3, 4, 5, 6]

    will work, but:

    >>> b + a

    will not work, as the `__add__` method is not defined for custom objects in
    the right operand. However, The original wrapped object can still be
    accessed with unwrap_copy(). The internal class is named as a hint for this
    reason, although most times this will be invisible.
    """

    # Apply attributes as slots reflection, but remove the attributes that are
    # set explicitly by the wrapper class (or not allowed like __dict__).
    slots = set(dir(base)) - set(
        [
            "__new__",
            "__setattr__",
            "__setitem__",
            "__doc__",
            "__class__",
            "__dict__",
            "__module__",
            "__slots__",
            "__dir__",
            "__init__",
            "__weakref__",
            "__ref__",
        ]
    )
    # pointer off the class to lock attributes / items.
    _fixed = [False]

    # Not seeing a non-verbose work around for mypy, as this needs to inherit
    # from the provided class and not some generic for this to work.
    class ReadOnly_try_marimo_unwrap_copy(ref_cls):  # type: ignore
        __doc__ = base.__class__.__doc__
        __slots__ = list(slots)
        # ensure reference for gc
        __base = base
        __class__ = type(
            base.__class__.__name__, (base.__class__, ref_cls), {}
        )

        def __init__(self) -> None:
            """No-op constructor to prevent parent constructor from running."""

        def __setattr__(self, name: str, value: Any) -> None:
            # Has to be read only as wouldn't actually mutate the underlying
            # object. Easier to defer and require and an unwrap then trying to
            # manage it,
            if _fixed[0]:
                _ro_fail()
            super.__setattr__(self, name, value)

        def __setitem__(self, name: str, value: Any) -> None:
            _ro_fail()

        def __new__(cls) -> ReadOnly_try_marimo_unwrap_copy:
            instance = ref_cls.__new__(cls)
            for n, m in inspect.getmembers(base):
                if n != "__weakref__":
                    setattr(instance, n, m)
            # Not a weak ref, but reasonable fallback
            ref: Ref[T] = lambda: base  # noqa: E731
            if hasattr(base, "__weakref__"):
                maybe_ref = weakref.ref(base)
                if maybe_ref is not None:
                    ref = maybe_ref
            instance.__ref__ = ref
            _fixed[0] = True
            return instance

    return cast(T, ReadOnly_try_marimo_unwrap_copy())

#+END_SRC
** Function unwrap_copy
#+BEGIN_SRC python
def unwrap_copy(base: T) -> T:
    """
    Given a ZeroCopy or ShallowCopy object, returns the original object.
    """
    for cls in [ZeroCopy, ShallowCopy]:
        if isinstance(base, cls):
            # It's pretty hidden, but it's there
            ref: Ref[T] = super(cls, base).__dict__["__ref__"]  # type: ignore
            return cast(T, ref())
    return base

#+END_SRC
** Function zero_copy
#+BEGIN_SRC python
def zero_copy(base: T) -> T:
    """
    Wraps object in a ZeroCopy wrapper to mark the object for no copying /
    cloning when running in strict execution mode.
    """
    if isinstance(base, ShallowCopy):
        return cast(T, shadow_wrap(ZeroCopy, unwrap_copy(base)))
    if isinstance(base, ZeroCopy):
        return cast(T, base)
    return cast(T, shadow_wrap(ZeroCopy, base))

#+END_SRC
** Function shallow_copy
#+BEGIN_SRC python
def shallow_copy(base: T) -> T:
    """
    Wraps object in a ShallowCopy wrapper to mark the object for "copy" over
    "deepcopy" when running in strict execution mode.
    """
    if isinstance(base, _Copy):
        return cast(T, shadow_wrap(ShallowCopy, copy(unwrap_copy(base))))
    return cast(T, shadow_wrap(ShallowCopy, copy(base)))

#+END_SRC
* dataflow
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.dataflow
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/dataflow.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import threading
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any, Callable, List, Literal, Optional, Tuple

from marimo import _loggers
from marimo._ast.cell import (
    CellId_t,
    CellImpl,
)
from marimo._ast.compiler import code_key
from marimo._ast.visitor import ImportData, Name, VariableData
from marimo._runtime.executor import execute_cell, execute_cell_async
from marimo._utils.variables import is_mangled_local

#+END_SRC
** Assignment Edge = Tuple[CellId_t, CellId_t]
#+BEGIN_SRC python
if TYPE_CHECKING:
    from collections.abc import Collection


Edge = Tuple[CellId_t, CellId_t]

#+END_SRC
** Assignment EdgeWithVar = Tuple[CellId_t, List[str], CellId_t]
#+BEGIN_SRC python
# EdgeWithVar uses a list rather than a set for the variables linking the cells
# as sets are not JSON-serializable (required by static_notebook_template()).
# The first entry is the source node; the second entry is a list of defs from
# the source read by the destination; and the third entry is the destination
# node.
EdgeWithVar = Tuple[CellId_t, List[str], CellId_t]

#+END_SRC
** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
LOGGER = _loggers.marimo_logger()

#+END_SRC
** @dataclass(frozen=True): Class DirectedGraph
#+BEGIN_SRC python
# TODO(akshayka): Add method disable_cell, enable_cell which handle
# state transitions on cells
@dataclass(frozen=True)
class DirectedGraph:
    # Nodes in the graph
    cells: dict[CellId_t, CellImpl] = field(default_factory=dict)

    # Edge (u, v) means v is a child of u, i.e., v has a reference
    # to something defined in u
    children: dict[CellId_t, set[CellId_t]] = field(default_factory=dict)

    # Reversed edges (parent pointers) for convenience
    parents: dict[CellId_t, set[CellId_t]] = field(default_factory=dict)

    # Cells that define the same name
    #
    # siblings[cell_id] is a set of cell ids, one for each cell that shares a
    # definition with cell_id.
    #
    # If this dict is non-empty, then the marimo program contains multiply
    # defined names (and is therefore in an error state)
    siblings: dict[CellId_t, set[CellId_t]] = field(default_factory=dict)

    # A mapping from defs to the cells that define them
    definitions: dict[Name, set[CellId_t]] = field(default_factory=dict)

    # The set of cycles in the graph
    cycles: set[tuple[Edge, ...]] = field(default_factory=set)

    # This lock must be acquired during methods that mutate the graph; it's
    # only needed because a graph is shared between the kernel and the code
    # completion service. It should almost always be uncontended.
    lock: threading.Lock = field(default_factory=threading.Lock)

    def is_cell_cached(self, cell_id: CellId_t, code: str) -> bool:
        """Whether a cell with id `cell_id` and code `code` is in the graph."""
        return (
            cell_id in self.cells and code_key(code) == self.cells[cell_id].key
        )

    # TODO: language type?
    def get_defining_cells(self, name: Name) -> set[CellId_t]:
        """Get all cells that define name.

        This is a singleton for well-formed graphs.
        """
        return self.definitions[name]

    def get_referring_cells(
        self, name: Name, language: Literal["python", "sql"]
    ) -> set[CellId_t]:
        """Get all cells that have a ref to `name`.

        The variable can be either a Python variable or a SQL variable (table).
        """
        children = set()
        for cid, cell in self.cells.items():
            if name not in cell.refs:
                continue
            elif language == "sql" and cell.language == "python":
                # SQL variables don't leak to Python cells, but
                # Python variables do leak to SQL cells
                continue
            children.add(cid)

        return children

    def get_path(self, source: CellId_t, dst: CellId_t) -> list[Edge]:
        """Get a path from `source` to `dst`, if any."""
        if source == dst:
            return []

        queue: list[tuple[CellId_t, list[Edge]]] = [(source, [])]
        found = set()
        while queue:
            node, path = queue.pop(0)
            found.add(node)
            for cid in self.children[node]:
                if cid not in found:
                    next_path = path + [(node, cid)]
                    if cid == dst:
                        return next_path
                    queue.append((cid, next_path))
        return []

    def register_cell(self, cell_id: CellId_t, cell: CellImpl) -> None:
        """Add a cell to the graph.

        Mutates the graph, acquiring `self.lock`.

        Requires that `cell_id` is not already in the graph.
        """
        LOGGER.debug("Acquiring graph lock to register cell %s", cell_id)
        with self.lock:
            LOGGER.debug("Acquired graph lock.")
            assert cell_id not in self.cells
            self.cells[cell_id] = cell
            # Children are the set of cells that refer to a name defined in
            # `cell`
            children: set[CellId_t] = set()
            # Cells that define the same name as this one
            siblings: set[CellId_t] = set()
            # Parents are the set of cells that define a name referred to by
            # `cell`
            parents: set[CellId_t] = set()

            # Populate children, siblings, and parents
            self.children[cell_id] = children
            self.siblings[cell_id] = siblings
            self.parents[cell_id] = parents
            for name, variable_data in cell.variable_data.items():
                self.definitions.setdefault(name, set()).add(cell_id)
                for sibling in self.definitions[name]:
                    # TODO(akshayka): Distinguish between Python/SQL?
                    if sibling != cell_id:
                        siblings.add(sibling)
                        self.siblings[sibling].add(cell_id)

                # a cell can refer to its own defs, but that doesn't add an
                # edge to the dependency graph
                referring_cells = self.get_referring_cells(
                    name,
                    language=variable_data[-1].language,
                ) - set((cell_id,))
                # we will add an edge (cell_id, v) for each v in
                # referring_cells; if there is a path from v to cell_id, then
                # the new edge will form a cycle
                for v in referring_cells:
                    path = self.get_path(v, cell_id)
                    if path:
                        self.cycles.add(tuple([(cell_id, v)] + path))

                children.update(referring_cells)
                for child in referring_cells:
                    self.parents[child].add(cell_id)

            for name in cell.refs:
                other_ids_defining_name = (
                    self.definitions[name]
                    if name in self.definitions
                    else set()
                ) - set((cell_id,))
                # if other is empty, this means that the user is going to
                # get a NameError once the cell is run, unless the symbol
                # is say a builtin
                for other_id in other_ids_defining_name:
                    language = (
                        self.cells[other_id].variable_data[name][-1].language
                    )
                    if language == "sql" and cell.language == "python":
                        # SQL table/db def -> Python ref is not an edge
                        continue
                    parents.add(other_id)
                    # we are adding an edge (other_id, cell_id). If there
                    # is a path from cell_id to other_id, then the new
                    # edge forms a cycle
                    path = self.get_path(cell_id, other_id)
                    if path:
                        self.cycles.add(tuple([(other_id, cell_id)] + path))
                    self.children[other_id].add(cell_id)
        LOGGER.debug("Registered cell %s and released graph lock", cell_id)
        if self.is_any_ancestor_stale(cell_id):
            self.set_stale(set([cell_id]))

        if self.is_any_ancestor_disabled(cell_id):
            cell.set_runtime_state(status="disabled-transitively")

    def is_any_ancestor_stale(self, cell_id: CellId_t) -> bool:
        return any(self.cells[cid].stale for cid in self.ancestors(cell_id))

    def is_any_ancestor_disabled(self, cell_id: CellId_t) -> bool:
        return any(
            self.cells[cid].config.disabled for cid in self.ancestors(cell_id)
        )

    def disable_cell(self, cell_id: CellId_t) -> None:
        """
        Disables a cell in the graph.

        Does not mutate the graph (but does mutate cell statuses).

        Returns the ids of descendants that are disabled transitively.
        """
        if cell_id not in self.cells:
            raise ValueError(f"Cell {cell_id} not found")

        for cid in transitive_closure(self, set([cell_id])) - set([cell_id]):
            cell = self.cells[cid]
            cell.set_runtime_state(status="disabled-transitively")

    def enable_cell(self, cell_id: CellId_t) -> set[CellId_t]:
        """
        Enables a cell in the graph.

        Does not mutate the graph (but does mutate cell statuses).

        Returns:
        - set of cells that were stale and should be re-run
        """
        if cell_id not in self.cells:
            raise ValueError(f"Cell {cell_id} not found")

        cells_to_run: set[CellId_t] = set()
        for cid in transitive_closure(self, set([cell_id])):
            if not self.is_disabled(cid):
                child = self.cells[cid]
                if child.stale:
                    # cell was previously disabled, is no longer
                    # disabled, and is stale: needs to run.
                    cells_to_run.add(cid)
                if child.disabled_transitively:
                    # cell is no longer disabled: status -> idle
                    child.set_runtime_state("idle")
        return cells_to_run

    def delete_cell(self, cell_id: CellId_t) -> set[CellId_t]:
        """Removes a cell from the graph.

        Mutates the graph, acquiring `self.lock`.

        Returns the ids of the children of the removed cell.
        """
        LOGGER.debug("Acquiring graph lock to delete cell %s", cell_id)
        with self.lock:
            LOGGER.debug("Acquired graph lock to delete cell %s", cell_id)
            if cell_id not in self.cells:
                raise ValueError(f"Cell {cell_id} not found")

            # Removing this cell from its defs' definer sets
            for name in self.cells[cell_id].defs:
                name_defs = self.definitions[name]
                name_defs.remove(cell_id)
                if not name_defs:
                    # No more cells define this name, so we remove it from the
                    # graph
                    del self.definitions[name]

            # Remove cycles that are broken from removing this cell.
            edges = [(cell_id, child) for child in self.children[cell_id]] + [
                (parent, cell_id) for parent in self.parents[cell_id]
            ]
            for e in edges:
                broken_cycles = [c for c in self.cycles if e in c]
                for c in broken_cycles:
                    self.cycles.remove(c)

            # Grab a reference to children before we remove it from our map.
            children = self.children[cell_id]

            # Purge this cell from the graph.
            del self.cells[cell_id]
            del self.children[cell_id]
            del self.parents[cell_id]
            del self.siblings[cell_id]

            for elems in self.parents.values():
                if cell_id in elems:
                    elems.remove(cell_id)
            for elems in self.children.values():
                if cell_id in elems:
                    elems.remove(cell_id)
            for elems in self.siblings.values():
                if cell_id in elems:
                    elems.remove(cell_id)
        LOGGER.debug("Deleted cell %s and Released graph lock.", cell_id)
        return children

    def is_disabled(self, cell_id: CellId_t) -> bool:
        if cell_id not in self.cells:
            raise ValueError(f"Cell {cell_id} not in graph.")
        cell = self.cells[cell_id]
        if cell.config.disabled:
            return True
        seen: set[CellId_t] = set()
        queue = [cell_id]
        while queue:
            cid = queue.pop()
            seen.add(cid)
            for parent_id in self.parents[cid]:
                if parent_id in seen:
                    continue
                elif self.cells[parent_id].config.disabled:
                    return True
                else:
                    queue.append(parent_id)
        return False

    def get_imports(
        self, cell_id: Optional[CellId_t] = None
    ) -> dict[Name, ImportData]:
        imports = {}
        cells = (
            self.cells.values() if cell_id is None else [self.cells[cell_id]]
        )
        for cell in cells:
            for imported in cell.imports:
                imports[imported.definition] = imported
        return imports

    def get_multiply_defined(self) -> list[Name]:
        names = []
        for name, definers in self.definitions.items():
            if len(definers) > 1:
                names.append(name)
        return names

    def get_deleted_nonlocal_ref(self) -> list[Name]:
        names = []
        for cell in self.cells.values():
            for ref in cell.deleted_refs:
                if ref in self.definitions:
                    names.append(ref)
        return names

    def descendants(self, cell_id: CellId_t) -> set[CellId_t]:
        return transitive_closure(self, set([cell_id]), inclusive=False)

    def ancestors(self, cell_id: CellId_t) -> set[CellId_t]:
        return transitive_closure(
            self, set([cell_id]), children=False, inclusive=False
        )

    def set_stale(
        self, cell_ids: set[CellId_t], prune_imports: bool = False
    ) -> None:
        relatives = None if not prune_imports else import_block_relatives
        for cid in transitive_closure(self, cell_ids, relatives=relatives):
            self.cells[cid].set_stale(stale=True)

    def get_stale(self) -> set[CellId_t]:
        return set([cid for cid, cell in self.cells.items() if cell.stale])

    def get_transitive_references(
        self,
        refs: set[Name],
        inclusive: bool = True,
        predicate: Callable[[Name, VariableData], bool] | None = None,
    ) -> set[Name]:
        """Return a set of the passed-in cells' references and their
        references on the block (function / class) level.

        If inclusive, includes the references of the passed-in cells in the
        set.

        If predicate, only references satisfying predicate(ref) are included
        """
        # TODO: Consider caching on the graph level and updating on register /
        # delete
        processed = set()
        queue = set(refs & self.definitions.keys())
        predicate = predicate or (lambda *_: True)

        while queue:
            # Should ideally be one cell per ref, but for completion, stay
            # agnostic to potenital cycles.
            cells = set().union(*[self.definitions[ref] for ref in queue])
            for cell_id in cells:
                data = self.cells[cell_id].variable_data
                variables = set(data.keys())
                # intersection of variables and queue
                newly_processed = variables & queue
                processed.update(newly_processed)
                queue.difference_update(newly_processed)
                for variable in newly_processed:
                    # variables can be defined multiple times in a single
                    # cell ...
                    for datum in data[variable]:
                        if predicate(variable, datum):
                            to_process = datum.required_refs - processed
                            queue.update(to_process & self.definitions.keys())
                            # Private variables referenced by public functions
                            # have to be included.
                            for maybe_private in (
                                to_process - self.definitions.keys()
                            ):
                                if is_mangled_local(maybe_private, cell_id):
                                    processed.add(maybe_private)

        if inclusive:
            return processed | refs
        return processed - refs

#+END_SRC
** Function transitive_closure
#+BEGIN_SRC python
def transitive_closure(
    graph: DirectedGraph,
    cell_ids: set[CellId_t],
    children: bool = True,
    inclusive: bool = True,
    relatives: (
        Callable[[DirectedGraph, CellId_t, bool], set[CellId_t]] | None
    ) = None,
    predicate: Callable[[CellImpl], bool] | None = None,
) -> set[CellId_t]:
    """Return a set of the passed-in cells and their descendants or ancestors

    If children is True, returns descendants; otherwise, returns ancestors

    If inclusive, includes passed-in cells in the set.

    If relatives is not None, it computes the parents/children of a
        cell

    If predicate, only cells satisfying predicate(cell) are included; applied
        after the relatives are computed
    """
    seen = set()
    cells = set()
    queue = list(cell_ids)
    predicate = predicate or (lambda _: True)

    def _relatives(cid: CellId_t) -> set[CellId_t]:
        if relatives is None:
            return graph.children[cid] if children else graph.parents[cid]

        return relatives(graph, cid, children)

    while queue:
        cid = queue.pop(0)
        seen.add(cid)
        cell = graph.cells[cid]
        if inclusive and predicate(cell):
            cells.add(cid)
        elif cid not in cell_ids and predicate(cell):
            cells.add(cid)
        for relative in _relatives(cid):
            if relative not in seen:
                queue.append(relative)
    return cells

#+END_SRC
** Function induced_subgraph
#+BEGIN_SRC python
def induced_subgraph(
    graph: DirectedGraph, cell_ids: Collection[CellId_t]
) -> tuple[dict[CellId_t, set[CellId_t]], dict[CellId_t, set[CellId_t]]]:
    """Return parents and children for each node in `cell_ids`

    Represents the subgraph induced by `cell_ids`.
    """
    parents = {}
    children = {}
    for cid in cell_ids:
        parents[cid] = set(p for p in graph.parents[cid] if p in cell_ids)
        children[cid] = set(c for c in graph.children[cid] if c in cell_ids)
    return parents, children

#+END_SRC
** Function get_cycles
#+BEGIN_SRC python
def get_cycles(
    graph: DirectedGraph, cell_ids: Collection[CellId_t]
) -> list[tuple[Edge, ...]]:
    """Get all cycles among `cell_ids`."""
    _, induced_children = induced_subgraph(graph, cell_ids)
    induced_edges = set(
        [(u, v) for u in induced_children for v in induced_children[u]]
    )
    return [c for c in graph.cycles if all(e in induced_edges for e in c)]

#+END_SRC
** Function topological_sort
#+BEGIN_SRC python
def topological_sort(
    graph: DirectedGraph, cell_ids: Collection[CellId_t]
) -> list[CellId_t]:
    """Sort `cell_ids` in a topological order."""
    parents, children = induced_subgraph(graph, cell_ids)
    roots = [cid for cid in cell_ids if not parents[cid]]
    sorted_cell_ids = []
    while roots:
        cid = roots.pop(0)
        sorted_cell_ids.append(cid)
        for child in children[cid]:
            parents[child].remove(cid)
            if not parents[child]:
                roots.append(child)
    # TODO make sure parents for each id is empty, otherwise cycle
    return sorted_cell_ids

#+END_SRC
** Function import_block_relatives
#+BEGIN_SRC python
def import_block_relatives(
    graph: DirectedGraph, cid: CellId_t, children: bool
) -> set[CellId_t]:
    if not children:
        return graph.parents[cid]

    cell = graph.cells[cid]
    if not cell.import_workspace.is_import_block:
        return graph.children[cid]

    # This cell is an import block, which should be special cased:
    #
    # We prune definitions that have already been imported from the set of
    # definitions used to find the descendants of this cell.
    unimported_defs = cell.defs - cell.import_workspace.imported_defs
    children_ids = set().union(
        *[
            graph.get_referring_cells(name, language="python")
            for name in unimported_defs
        ]
    )

    # If children haven't been executed, then still use imported defs;
    # handle an edge case when an import cell is interrupted by an
    # exception or user interrupt, so that a module is imported but the
    # cell's children haven't run.
    for name in cell.import_workspace.imported_defs:
        for child_id in graph.get_referring_cells(name, language="python"):
            if graph.cells[child_id].run_result_status in (
                "interrupted",
                "cancelled",
                "marimo-error",
                None,
            ):
                children_ids.add(child_id)

    return children_ids

#+END_SRC
** Class Runner
#+BEGIN_SRC python
class Runner:
    """Utility for running individual cells in a graph

    This class provides methods to a run a cell in the graph and obtain its
    output (last expression) and the values of its defs.

    If needed, the runner will recursively compute the values of the cell's
    refs by executing its ancestors. Refs can also be substituted by the
    caller.

    TODO(akshayka): Add an API for caching defs across cell runs.
    """

    def __init__(self, graph: DirectedGraph) -> None:
        self._graph = graph

    @staticmethod
    def _returns(cell_impl: CellImpl, glbls: dict[str, Any]) -> dict[str, Any]:
        return {name: glbls[name] for name in cell_impl.defs if name in glbls}

    @staticmethod
    def _substitute_refs(
        cell_impl: CellImpl,
        glbls: dict[str, Any],
        kwargs: dict[str, Any],
    ) -> None:
        for argname, argvalue in kwargs.items():
            if argname in cell_impl.refs:
                glbls[argname] = argvalue
            else:
                raise ValueError(
                    f"Cell got unexpected argument {argname}"
                    f"The allowed arguments are {cell_impl.refs}."
                )

    def _get_ancestors(
        self, cell_impl: CellImpl, kwargs: dict[str, Any]
    ) -> set[CellId_t]:
        # Get the transitive closure of parents defining unsubstituted refs
        graph = self._graph
        substitutions = set(kwargs.values())
        unsubstituted_refs = cell_impl.refs - substitutions
        parent_ids = set(
            [
                parent_id
                for parent_id in graph.parents[cell_impl.cell_id]
                if graph.cells[parent_id].defs.intersection(unsubstituted_refs)
            ]
        )
        return transitive_closure(graph, parent_ids, children=False)

    @staticmethod
    def _validate_kwargs(cell_impl: CellImpl, kwargs: dict[str, Any]) -> None:
        for argname in kwargs:
            if argname not in cell_impl.refs:
                raise ValueError(
                    f"Cell got unexpected argument {argname}"
                    f"The allowed arguments are {cell_impl.refs}."
                )

    def is_coroutine(self, cell_id: CellId_t) -> bool:
        return self._graph.cells[cell_id].is_coroutine() or any(
            self._graph.cells[cid].is_coroutine()
            for cid in self._get_ancestors(
                self._graph.cells[cell_id], kwargs={}
            )
        )

    async def run_cell_async(
        self, cell_id: CellId_t, kwargs: dict[str, Any]
    ) -> tuple[Any, dict[str, Any]]:
        """Run a possibly async cell and its ancestors

        Substitutes kwargs as refs for the cell, omitting ancestors that
        whose refs are substituted.
        """
        graph = self._graph
        cell_impl = graph.cells[cell_id]
        Runner._validate_kwargs(cell_impl, kwargs)
        ancestor_ids = self._get_ancestors(cell_impl, kwargs)

        glbls: dict[str, Any] = {}
        for cid in topological_sort(graph, ancestor_ids):
            await execute_cell_async(graph.cells[cid], glbls, graph)

        Runner._substitute_refs(cell_impl, glbls, kwargs)
        output = await execute_cell_async(
            graph.cells[cell_impl.cell_id], glbls, graph
        )
        defs = Runner._returns(cell_impl, glbls)
        return output, defs

    def run_cell_sync(
        self, cell_id: CellId_t, kwargs: dict[str, Any]
    ) -> tuple[Any, dict[str, Any]]:
        """Run a synchronous cell and its ancestors

        Substitutes kwargs as refs for the cell, omitting ancestors that
        whose refs are substituted.

        Raises a `RuntimeError` if the cell or any of its unsubstituted
        ancestors are coroutine functions.
        """
        graph = self._graph
        cell_impl = graph.cells[cell_id]
        if cell_impl.is_coroutine():
            raise RuntimeError(
                "A coroutine function can't be run synchronously. "
                "Use `run_async()` instead"
            )

        Runner._validate_kwargs(cell_impl, kwargs)
        ancestor_ids = self._get_ancestors(cell_impl, kwargs)

        if any(graph.cells[cid].is_coroutine() for cid in ancestor_ids):
            raise RuntimeError(
                "Cell has an ancestor that is a "
                "coroutine (async) cell. Use `run_async()` instead"
            )

        glbls: dict[str, Any] = {}
        for cid in topological_sort(graph, ancestor_ids):
            execute_cell(graph.cells[cid], glbls, graph)

        self._substitute_refs(cell_impl, glbls, kwargs)
        output = execute_cell(graph.cells[cell_impl.cell_id], glbls, graph)
        defs = Runner._returns(cell_impl, glbls)
        return output, defs

#+END_SRC
* executor
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.executor
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/executor.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import inspect
import re
from abc import ABC, abstractmethod
from copy import deepcopy
from typing import TYPE_CHECKING, Any, Callable, Optional, Type

from marimo._ast.cell import CellImpl, _is_coroutine
from marimo._runtime.copy import (
    CloneError,
    ShallowCopy,
    ZeroCopy,
    shallow_copy,
)
from marimo._runtime.primitives import (
    CLONE_PRIMITIVES,
    build_ref_predicate_for_primitives,
    from_unclonable_module,
    is_unclonable_type,
)
from marimo._utils.variables import is_mangled_local, unmangle_local

#+END_SRC
** Assignment EXECUTION_TYPES: dict[str, Type[Executor]] = {}
#+BEGIN_SRC python
if TYPE_CHECKING:
    from marimo._runtime.dataflow import DirectedGraph


EXECUTION_TYPES: dict[str, Type[Executor]] = {}

#+END_SRC
** Class MarimoRuntimeException
#+BEGIN_SRC python
class MarimoRuntimeException(BaseException):
    """Wrapper for all marimo runtime exceptions."""

#+END_SRC
** Class MarimoNameError
#+BEGIN_SRC python
class MarimoNameError(NameError):
    """Wrap a name error to rethrow later."""

    def __init__(self, msg: str, ref: str) -> None:
        super().__init__(msg)
        self.ref = ref

#+END_SRC
** Class MarimoMissingRefError
#+BEGIN_SRC python
class MarimoMissingRefError(BaseException):
    def __init__(
        self, ref: str, name_error: Optional[NameError] = None
    ) -> None:
        super(MarimoMissingRefError, self).__init__(ref)
        self.ref = ref
        self.name_error = name_error

#+END_SRC
** Function raise_name_error
#+BEGIN_SRC python
def raise_name_error(
    graph: Optional[DirectedGraph], name_error: NameError
) -> None:
    if graph is None:
        raise MarimoRuntimeException from name_error
    (missing_name,) = re.findall(r"'([^']*)'", str(name_error))
    _, private_cell_id = unmangle_local(missing_name)
    if missing_name in graph.definitions or private_cell_id:
        raise MarimoRuntimeException from MarimoMissingRefError(
            missing_name, name_error
        )
    raise MarimoRuntimeException from name_error

#+END_SRC
** Function register_execution_type
#+BEGIN_SRC python
def register_execution_type(
    key: str,
) -> Callable[[Type[Executor]], Type[Executor]]:
    # Potentially expose as part of custom kernel API
    def wrapper(cls: Type[Executor]) -> Type[Executor]:
        EXECUTION_TYPES[key] = cls
        return cls

    return wrapper

#+END_SRC
** Function execute_cell_async
#+BEGIN_SRC python
async def execute_cell_async(
    cell: CellImpl,
    glbls: dict[str, Any],
    graph: DirectedGraph,
    execution_type: str = "relaxed",
) -> Any:
    return await EXECUTION_TYPES[execution_type].execute_cell_async(
        cell, glbls, graph
    )

#+END_SRC
** Function execute_cell
#+BEGIN_SRC python
def execute_cell(
    cell: CellImpl,
    glbls: dict[str, Any],
    graph: DirectedGraph,
    execution_type: str = "relaxed",
) -> Any:
    return EXECUTION_TYPES[execution_type].execute_cell(cell, glbls, graph)

#+END_SRC
** Class Executor
#+BEGIN_SRC python
class Executor(ABC):
    @staticmethod
    @abstractmethod
    def execute_cell(
        cell: CellImpl,
        glbls: dict[str, Any],
        graph: DirectedGraph,
    ) -> Any:
        pass

    @staticmethod
    @abstractmethod
    async def execute_cell_async(
        cell: CellImpl,
        glbls: dict[str, Any],
        graph: DirectedGraph,
    ) -> Any:
        pass

#+END_SRC
** @register_execution_type("relaxed"): Class DefaultExecutor
#+BEGIN_SRC python
@register_execution_type("relaxed")
class DefaultExecutor(Executor):
    @staticmethod
    async def execute_cell_async(
        cell: CellImpl,
        glbls: dict[str, Any],
        graph: Optional[DirectedGraph] = None,
    ) -> Any:
        if cell.body is None:
            return None
        assert cell.last_expr is not None
        try:
            if _is_coroutine(cell.body):
                await eval(cell.body, glbls)
            else:
                exec(cell.body, glbls)

            if _is_coroutine(cell.last_expr):
                return await eval(cell.last_expr, glbls)
            else:
                return eval(cell.last_expr, glbls)
        except NameError as e:
            raise_name_error(graph, e)
        except (BaseException, Exception) as e:
            # Raising from a BaseException will fold in the stacktrace prior
            # to execution
            raise MarimoRuntimeException from e

    @staticmethod
    def execute_cell(
        cell: CellImpl,
        glbls: dict[str, Any],
        graph: Optional[DirectedGraph] = None,
    ) -> Any:
        try:
            if cell.body is None:
                return None
            assert cell.last_expr is not None

            exec(cell.body, glbls)
            return eval(cell.last_expr, glbls)
        except NameError as e:
            raise_name_error(graph, e)
        except (BaseException, Exception) as e:
            raise MarimoRuntimeException from e

#+END_SRC
** @register_execution_type("strict"): Class StrictExecutor
#+BEGIN_SRC python
@register_execution_type("strict")
class StrictExecutor(Executor):
    @staticmethod
    async def execute_cell_async(
        cell: CellImpl, glbls: dict[str, Any], graph: DirectedGraph
    ) -> Any:
        # Manage globals and references, but refers to the default beyond that.
        refs = graph.get_transitive_references(
            cell.refs,
            predicate=build_ref_predicate_for_primitives(
                glbls, CLONE_PRIMITIVES
            ),
        )
        backup = StrictExecutor.sanitize_inputs(cell, refs, glbls)
        try:
            response = await DefaultExecutor.execute_cell_async(
                cell, glbls, graph
            )
        finally:
            # Restore globals from backup and backfill outputs
            StrictExecutor.update_outputs(cell, glbls, backup)
        return response

    @staticmethod
    def execute_cell(
        cell: CellImpl, glbls: dict[str, Any], graph: DirectedGraph
    ) -> Any:
        refs = graph.get_transitive_references(
            cell.refs,
            predicate=build_ref_predicate_for_primitives(
                glbls, CLONE_PRIMITIVES
            ),
        )
        backup = StrictExecutor.sanitize_inputs(cell, refs, glbls)
        try:
            response = DefaultExecutor.execute_cell(cell, glbls, graph)
        finally:
            StrictExecutor.update_outputs(cell, glbls, backup)
        return response

    @staticmethod
    def sanitize_inputs(
        cell: CellImpl, refs: set[str], glbls: dict[str, Any]
    ) -> dict[str, Any]:
        # Some attributes should remain global
        lcls = {
            key: glbls[key]
            for key in [
                "_MicropipFinder",
                "_MicropipLoader",
                "__builtin__",
                "__doc__",
                "__file__",
                "__marimo__",
                "__name__",
                "__package__",
                "__loader__",
                "__spec__",
                "input",
            ]
            if key in glbls
        }

        for ref in refs:
            if ref in glbls:
                if (
                    isinstance(
                        glbls[ref],
                        (ZeroCopy),
                    )
                    or inspect.ismodule(glbls[ref])
                    or inspect.isfunction(glbls[ref])
                    or from_unclonable_module(glbls[ref])
                    or is_unclonable_type(glbls[ref])
                ):
                    lcls[ref] = glbls[ref]
                elif isinstance(glbls[ref], ShallowCopy):
                    lcls[ref] = shallow_copy(glbls[ref])
                else:
                    try:
                        lcls[ref] = deepcopy(glbls[ref])
                    except TypeError as e:
                        raise CloneError(
                            f"Could not clone reference `{ref}` of type "
                            f"{getattr(glbls[ref], '__module__', '<module>')}."
                            f"{glbls[ref].__class__.__name__}"
                            " try wrapping the object in a `zero_copy`"
                            "call. If this is a common object type, consider "
                            "making an issue on the marimo GitHub "
                            "repository to never deepcopy."
                        ) from e
            elif ref not in glbls["__builtins__"]:
                if ref in cell.defs:
                    raise MarimoNameError(
                        f"name `{ref}` is referenced before definition.", ref
                    )
                raise MarimoMissingRefError(ref)

        # NOTE: Execution expects the globals dictionary by memory reference,
        # so we need to clear it and update it with the sanitized locals,
        # returning a backup of the original globals for later restoration.
        # This must be performed at the end of the function to ensure valid
        # state in case of failure.
        backup = {**glbls}
        glbls.clear()
        glbls.update(lcls)
        return backup

    @staticmethod
    def update_outputs(
        cell: CellImpl, glbls: dict[str, Any], backup: dict[str, Any]
    ) -> None:
        # NOTE: After execution, restore global state and update outputs.
        lcls = {**glbls}
        glbls.clear()
        glbls.update(backup)

        defs = cell.defs
        for df in defs:
            if df in lcls:
                # Overwrite will delete the reference.
                # Weak copy holds on with references.
                glbls[df] = lcls[df]
            # Captures the case where a variable was previously defined by the
            # cell but this most recent run did not define it. The value is now
            # stale and needs to be flushed.
            elif df in glbls:
                del glbls[df]

        # Flush all private variables from memory
        for df in backup:
            if is_mangled_local(df, cell.cell_id):
                del glbls[df]

        # Now repopulate all private variables.
        for df in lcls:
            if is_mangled_local(df, cell.cell_id):
                glbls[df] = lcls[df]

#+END_SRC
* Functions associated with a graph.
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.functions
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/functions.py
:END:
** Docstring
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
"""Functions associated with a graph."""

#+END_SRC
** Import statements
#+BEGIN_SRC python
from __future__ import annotations

import dataclasses
from typing import Any, Callable, Coroutine, Generic, Type, TypeVar

from marimo._ast.cell import CellId_t
from marimo._loggers import marimo_logger
from marimo._utils.parse_dataclass import parse_raw

#+END_SRC
** Assignment LOGGER = marimo_logger()
#+BEGIN_SRC python
LOGGER = marimo_logger()

#+END_SRC
** Assignment S = TypeVar("S")
#+BEGIN_SRC python
S = TypeVar("S")

#+END_SRC
** Assignment T = TypeVar("T")
#+BEGIN_SRC python
T = TypeVar("T")

#+END_SRC
** @dataclasses.dataclass: Class EmptyArgs
#+BEGIN_SRC python
@dataclasses.dataclass
class EmptyArgs:
    """Utility type for functions that take no arguments."""

    ...

#+END_SRC
** @dataclasses.dataclass: Class Function
#+BEGIN_SRC python
@dataclasses.dataclass
class Function(Generic[S, T]):
    name: str
    arg_cls: Type[S]
    function: Callable[[S], T] | Callable[[S], Coroutine[Any, Any, T]]
    cell_id: CellId_t | None

    def __init__(
        self,
        name: str,
        arg_cls: Type[S],
        function: Callable[[S], T],
    ) -> None:
        from marimo._runtime.context import (
            ContextNotInitializedError,
            get_context,
        )

        self.name = name
        self.arg_cls = arg_cls
        self.function = function

        try:
            ctx = get_context()
        except ContextNotInitializedError:
            ctx = None

        if ctx is not None and ctx.execution_context is not None:
            self.cell_id = ctx.execution_context.cell_id
        else:
            self.cell_id = None

    def __call__(self, args: dict[Any, Any]) -> T | Coroutine[Any, Any, T]:
        try:
            return self.function(parse_raw(args, self.arg_cls))
        except Exception as e:
            LOGGER.error(f"Error calling function {self.name}: {e}")
            raise e

#+END_SRC
** @dataclasses.dataclass: Class FunctionNamespace
#+BEGIN_SRC python
@dataclasses.dataclass
class FunctionNamespace:
    namespace: str
    functions: dict[str, Function[Any, Any]] = dataclasses.field(
        default_factory=dict
    )

    def add(self, function: Function[Any, Any]) -> None:
        self.functions[function.name] = function

    def get(self, name: str) -> Function[Any, Any] | None:
        if name in self.functions:
            return self.functions[name]
        return None

#+END_SRC
** Class FunctionRegistry
#+BEGIN_SRC python
class FunctionRegistry:
    def __init__(self) -> None:
        self.namespaces: dict[str, FunctionNamespace] = {}

    def register(self, namespace: str, function: Function[Any, Any]) -> None:
        if namespace not in self.namespaces:
            self.namespaces[namespace] = FunctionNamespace(namespace=namespace)
        self.namespaces[namespace].add(function)

    def get_function(
        self, namespace: str, function_name: str
    ) -> Function[Any, Any] | None:
        if namespace in self.namespaces:
            return self.namespaces[namespace].get(function_name)
        return None

    def delete(self, namespace: str) -> None:
        if namespace in self.namespaces:
            del self.namespaces[namespace]

#+END_SRC
* handlers
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.handlers
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/handlers.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
import os
from dataclasses import dataclass
from typing import TYPE_CHECKING, Any, Callable

from marimo import _loggers
from marimo._messaging.ops import Interrupted
from marimo._runtime.context import get_context
from marimo._runtime.control_flow import MarimoInterrupt

#+END_SRC
** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
LOGGER = _loggers.marimo_logger()

#+END_SRC
** Function construct_interrupt_handler
#+BEGIN_SRC python
if TYPE_CHECKING:
    from marimo._runtime.runtime import Kernel


def construct_interrupt_handler(
    kernel: "Kernel",
) -> Callable[[int, Any], None]:
    def interrupt_handler(signum: int, frame: Any) -> None:
        """Tries to interrupt the kernel."""
        del signum
        del frame

        LOGGER.debug("Interrupt request received")
        # TODO(akshayka): if kernel is in `run` but not executing,
        # it won't be interrupted, which isn't right ... but the
        # probability of that happening is low.
        if kernel.execution_context is not None:
            Interrupted().broadcast()
            raise MarimoInterrupt

    return interrupt_handler

#+END_SRC
** Function construct_sigterm_handler
#+BEGIN_SRC python
def construct_sigterm_handler(kernel: "Kernel") -> Callable[[int, Any], None]:
    del kernel

    @dataclass
    class Bit:
        value: bool = False

    shutting_down = Bit()

    def sigterm_handler(signum: int, frame: Any) -> None:
        """Cleans up the kernel and exits."""
        del signum
        del frame

        if shutting_down.value:
            # give previous SIGTERM a chance to quit ... makes
            # sure this method is reentrant
            return
        shutting_down.value = True

        get_context().virtual_file_registry.shutdown()
        # Force this process to exit.
        #
        # We use os._exit() instead of sys.exit() because we don't want the
        # child process to also run atexit handlers, which may result in
        # undefined behavior. Using sys.exit() on Linux sometimes causes
        # the parent process to hang on shutdown, leading to orphaned
        # processes and port.
        #
        # TODO(akshayka): The Python docs say this method is appropriate
        # for processes created with fork(), but they don't say anything
        # about processes made with spawn. macOS and Windows default to
        # spawn. If we have further issues with clean exits, we might
        # investigate here.
        #
        # https://docs.python.org/3/library/os.html#os._exit
        # https://www.unixguide.net/unix/programming/1.1.3.shtml
        os._exit(0)

    return sigterm_handler

#+END_SRC
* input_override
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.input_override
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/input_override.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
import functools
import sys

#+END_SRC
** @functools.wraps(input): Function input_override
#+BEGIN_SRC python
@functools.wraps(input)
def input_override(prompt: str = "") -> str:
    # sys.stdin is overridden
    return sys.stdin._readline_with_prompt(prompt)  # type: ignore[attr-defined, no-any-return]  # noqa: E501

#+END_SRC
* marimo_pdb
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.marimo_pdb
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/marimo_pdb.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import inspect
import sys
from pdb import Pdb
from typing import TYPE_CHECKING, Any

from marimo import _loggers
from marimo._messaging.types import Stdin, Stdout

#+END_SRC
** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
if TYPE_CHECKING:
    from types import FrameType

LOGGER = _loggers.marimo_logger()

#+END_SRC
** Class MarimoPdb
#+BEGIN_SRC python
class MarimoPdb(Pdb):
    # Because we are patching Pdb, we need copy the exact constructor signature
    def __init__(
        self,
        completekey: str = "tab",
        stdout: Stdout | None = None,
        stdin: Stdin | None = None,
        skip: Any = None,
        nosigint: bool = False,
        readrc: bool = True,
    ):
        super().__init__(
            completekey=completekey,
            stdout=stdout,  # type: ignore[arg-type]
            stdin=stdin,  # type: ignore[arg-type]
            skip=skip,
            nosigint=nosigint,
            readrc=readrc,
        )  # type: ignore[arg-type]
        # it's fine to use input() since marimo overrides it, but disable
        # it anyway -- stdin is fine too ...
        self.use_rawinput = stdin is None

    def set_trace(
        self, frame: FrameType | None = None, header: str | None = None
    ) -> None:
        if header is not None:
            sys.stdout.write(header)
        return super().set_trace(frame)

#+END_SRC
** Function set_trace
#+BEGIN_SRC python
def set_trace(
    debugger: MarimoPdb,
    frame: FrameType | None = None,
    header: str | None = None,
) -> None:
    if frame is None:
        # make sure the frame points to user code
        current_frame = inspect.currentframe()
        frame = current_frame.f_back if current_frame is not None else None
    debugger.set_trace(frame, header=header)

#+END_SRC
* params
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.params
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/params.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import Dict, Iterator, List, Optional, Union

from marimo._messaging.mimetypes import KnownMimeType
from marimo._messaging.ops import (
    QueryParamsAppend,
    QueryParamsClear,
    QueryParamsDelete,
    QueryParamsSet,
)
from marimo._messaging.types import Stream
from marimo._output.rich_help import mddoc
from marimo._runtime.requests import (
    ListOrValue,
    Primitive,
    SerializedCLIArgs,
    SerializedQueryParams,
)
from marimo._runtime.state import State, StateRegistry

#+END_SRC
** @mddoc: Class QueryParams
#+BEGIN_SRC python
@mddoc
class QueryParams(State[SerializedQueryParams]):
    """Query parameters for a marimo app."""

    IGNORED_KEYS = {"access_token", "refresh_token", "session_id"}

    def __init__(
        self,
        params: Dict[str, Union[str, List[str]]],
        stream: Optional[Stream] = None,
        _registry: Optional[StateRegistry] = None,
    ):
        super().__init__(params, _registry=_registry)
        self._params = params
        self._stream = stream

    def get(self, key: str) -> Optional[Union[str, List[str]]]:
        """Get the value of the query parameter.

        Returns a str if there is only one item, a list of str otherwise.
        """
        if key not in self._params:
            return None
        return self._params[key]

    def get_all(self, key: str) -> List[str]:
        """Get the value of a query parameter as a list."""
        value = self._params.get(key)
        if value is None:
            return []
        if isinstance(value, list):
            return value
        return [value]

    def __getitem__(self, key: str) -> Optional[Union[str, List[str]]]:
        return self.get(key)

    def __contains__(self, key: str) -> bool:
        return key in self._params

    def __len__(self) -> int:
        return len(self._params)

    def __iter__(self) -> Iterator[str]:
        return iter(self._params)

    def __repr__(self) -> str:
        return f"QueryParams({self._params})"

    def __str__(self) -> str:
        return str(self._params)

    def __setitem__(self, key: str, value: Union[str, List[str]]) -> None:
        if value is None or value == []:  # type: ignore
            self.remove(key)
            return
        # We always overwrite the value
        self._params[key] = value
        QueryParamsSet(key, value).broadcast(self._stream)
        self._set_value(self._params)

    def __delitem__(self, key: str) -> None:
        del self._params[key]
        QueryParamsDelete(key, None).broadcast(self._stream)
        self._set_value(self._params)

    def set(self, key: str, value: Union[str, List[str]]) -> None:
        """Set the value of a query parameter."""
        self[key] = value

    def append(self, key: str, value: str) -> None:
        """Append a value to a list of values"""
        if key not in self._params:
            self._params[key] = value
            QueryParamsAppend(key, value).broadcast(self._stream)
            self._set_value(self._params)
            return

        current_value = self._params[key]
        if isinstance(current_value, list):
            current_value.append(value)
        else:
            self._params[key] = [current_value, value]

        QueryParamsAppend(key, value).broadcast(self._stream)
        self._set_value(self._params)

    def remove(self, key: str, value: Optional[str] = None) -> None:
        """Remove a value from a list of values."""
        if key not in self._params:
            return
        # If value is None, remove the key
        if value is None:
            del self._params[key]
            QueryParamsDelete(key, value).broadcast(self._stream)
            self._set_value(self._params)
            return

        current_value = self._params[key]
        if isinstance(current_value, list):
            current_value.remove(value)
        elif current_value == value:
            del self._params[key]

        QueryParamsDelete(key, value).broadcast(self._stream)
        self._set_value(self._params)

    def _mime_(self) -> tuple[KnownMimeType, str]:
        from marimo._plugins.stateless.tree import tree

        return tree(self._params)._mime_()

    def clear(self) -> None:
        """Clear all query params."""
        self._params.clear()
        QueryParamsClear().broadcast(self._stream)
        self._set_value(self._params)

    def to_dict(self) -> Dict[str, Union[str, List[str]]]:
        return self._params

#+END_SRC
** @mddoc: Class CLIArgs
#+BEGIN_SRC python
@mddoc
class CLIArgs:
    """CLI args passed to a marimo app."""

    def __init__(
        self,
        params: SerializedCLIArgs,
    ):
        self._params = params

    def get(self, key: str) -> Optional[ListOrValue[Primitive]]:
        """Get the value of the CLI arg.

        Returns a singleton value if there is only one item,
        a list of values otherwise.
        """
        if key not in self._params:
            return None
        return self._params[key]

    def get_all(self, key: str) -> List[Primitive]:
        """Get the value of a CLI arg as a list."""
        value = self._params.get(key)
        if value is None:
            return []
        if isinstance(value, list):
            return value
        return [value]

    def __getitem__(self, key: str) -> Optional[ListOrValue[Primitive]]:
        return self.get(key)

    def __contains__(self, key: str) -> bool:
        return key in self._params

    def __len__(self) -> int:
        return len(self._params)

    def __iter__(self) -> Iterator[ListOrValue[Primitive]]:
        return iter(self._params)

    def __repr__(self) -> str:
        return f"CLIArgs({self._params})"

    def __str__(self) -> str:
        return str(self._params)

    def _mime_(self) -> tuple[KnownMimeType, str]:
        from marimo._plugins.stateless.tree import tree

        return tree(self._params)._mime_()

    def to_dict(self) -> SerializedCLIArgs:
        return self._params

#+END_SRC
* patches
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.patches
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/patches.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import contextlib
import functools
import sys
import textwrap
import types
from typing import Any, Callable, Iterator

from marimo._runtime import marimo_pdb

#+END_SRC
** Function patch_pdb
#+BEGIN_SRC python
def patch_pdb(debugger: marimo_pdb.MarimoPdb) -> None:
    import pdb

    # Patch Pdb so manually instantiated debuggers create our debugger
    pdb.Pdb = marimo_pdb.MarimoPdb  # type: ignore[misc, assignment]
    pdb.set_trace = functools.partial(marimo_pdb.set_trace, debugger=debugger)

#+END_SRC
** Function patch_sys_module
#+BEGIN_SRC python
def patch_sys_module(module: types.ModuleType) -> None:
    sys.modules[module.__name__] = module

#+END_SRC
** Function patch_pyodide_networking
#+BEGIN_SRC python
def patch_pyodide_networking() -> None:
    import pyodide_http  # type: ignore

    pyodide_http.patch_urllib()

#+END_SRC
** Function patch_recursion_limit
#+BEGIN_SRC python
def patch_recursion_limit(limit: int) -> None:
    """Set the recursion limit."""

    # jedi increases the recursion limit as a side effect, upon import ...
    import jedi  # type: ignore # noqa: F401

    sys.setrecursionlimit(limit)

#+END_SRC
** Function patch_micropip
#+BEGIN_SRC python
def patch_micropip(glbls: dict[Any, Any]) -> None:
    """Mock micropip with no-ops"""

    definitions = textwrap.dedent(
        """\
from importlib.abc import Loader, MetaPathFinder

class _MicropipFinder(MetaPathFinder):


    def find_spec(self, fullname, path, target=None):
        from importlib.util import spec_from_loader

        if fullname == 'micropip':
            return spec_from_loader(fullname, _MicropipLoader())
        return None


class _MicropipLoader(Loader):
    def create_module(self, spec):
        del spec
        # use default spec creation
        return None

    def exec_module(self, module):
        import textwrap

        code = textwrap.dedent(
'''\
def _warn_uninstalled(prefix=""):
    import sys
    sys.stderr.write(prefix + 'micropip is only available in WASM notebooks.')

async def install(
    requirements, keep_going=False, deps=True,
    credentials=None, pre=False, index_urls=None, *,
    verbose=False
):
    _warn_uninstalled(prefix=f'{requirements} was not installed: ')

def list():
    _warn_uninstalled()

def freeze():
    _warn_uninstalled()

def add_mock_package(name, version, *, modules=None, persistent=False):
    _warn_uninstalled()

def list_mock_packages():
    _warn_uninstalled()

def remove_mock_package(name):
    _warn_uninstalled()

def uninstall(packages, *, verbose=False):
    _warn_uninstalled()

def set_index_urls(urls):
    _warn_uninstalled()
'''
    )
        exec(code, vars(module))

del Loader; del MetaPathFinder
"""
    )

    exec(definitions, glbls)

    # append the finder to the end of meta_path, in case the user
    # already has a package called micropip
    exec(
        "import sys; sys.meta_path.append(_MicropipFinder()); del sys",
        glbls,
    )

#+END_SRC
** Function create_main_module
#+BEGIN_SRC python
def create_main_module(
    file: str | None, input_override: Callable[[Any], str] | None
) -> types.ModuleType:
    # Every kernel gets its own main module, whose __dict__ attribute
    # serves as the global namespace
    _module = types.ModuleType(
        "__main__", doc="Created for the marimo kernel."
    )
    _module.__dict__.setdefault("__builtin__", globals()["__builtins__"])
    _module.__dict__.setdefault("__builtins__", globals()["__builtins__"])

    if input_override is not None:
        _module.__dict__.setdefault("input", input_override)

    if file is not None:
        _module.__dict__.setdefault("__file__", file)
    elif hasattr(sys.modules["__main__"], "__file__"):
        _module.__dict__.setdefault(
            "__file__", sys.modules["__main__"].__file__
        )
    else:
        # Windows seems to have this edgecase where __file__ is not set
        # so default to None, per the intended behavior in #668.
        _module.__dict__.setdefault("__file__", None)

    return _module

#+END_SRC
** Function patch_main_module
#+BEGIN_SRC python
def patch_main_module(
    file: str | None, input_override: Callable[[Any], str] | None
) -> types.ModuleType:
    """Patches __main__ module

    - Makes functions pickleable
    - Loads some overrides and mocks into globals
    """
    _module = create_main_module(file, input_override)

    # TODO(akshayka): In run mode, this can introduce races between different
    # kernel threads, since they each share sys.modules. Unfortunately, Python
    # doesn't provide a way for different threads to have their own sys.modules
    # (replacing the dict with a new one isn't guaranteed to have the intended
    # effect, since CPython C code has a reference to the original dict).
    # In practice, as far as I can tell, this only causes problems when using
    # Python pickle, but there may be other subtle issues.
    #
    # As a workaround, the runtime can re-patch sys.modules() on each run,
    # but the issue will still persist as a race condition. Streamlit suffers
    # from the same issue.
    patch_sys_module(_module)
    return _module

#+END_SRC
** @contextlib.contextmanager: Function patch_main_module_context
#+BEGIN_SRC python
@contextlib.contextmanager
def patch_main_module_context(
    module: types.ModuleType,
) -> Iterator[types.ModuleType]:
    main = sys.modules["__main__"]
    try:
        sys.modules["__main__"] = module
        yield module
    finally:
        sys.modules["__main__"] = main

#+END_SRC
* primitives
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.primitives
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/primitives.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import inspect
import numbers
import weakref
from typing import TYPE_CHECKING, Any, Callable, Optional, Union

from marimo._ast.visitor import Name, VariableData

#+END_SRC
** Assignment PRIMITIVES: tuple[type, ...] = (bytes, str, numbers.Number, type(None))
#+BEGIN_SRC python
if TYPE_CHECKING:
    from marimo._runtime.dataflow import DirectedGraph

PRIMITIVES: tuple[type, ...] = (bytes, str, numbers.Number, type(None))

#+END_SRC
** Assignment CLONE_PRIMITIVES = (weakref.ref,) + PRIMITIVES
#+BEGIN_SRC python
# Weakref instances should be disassociated from related references, as should
# other "primitives" as they are results and hopefully not hiding some scoped
# reference.
CLONE_PRIMITIVES = (weakref.ref,) + PRIMITIVES

#+END_SRC
** Assignment FN_CACHE_TYPE = Optional[dict[Union[Callable[..., Any], type], bool]]
#+BEGIN_SRC python
FN_CACHE_TYPE = Optional[dict[Union[Callable[..., Any], type], bool]]

#+END_SRC
** Assignment UNCLONABLE_TYPES
#+BEGIN_SRC python
UNCLONABLE_TYPES = [
    "marimo._runtime.state.State",
    "marimo._runtime.state.SetFunctor",
]

#+END_SRC
** Assignment UNCLONABLE_MODULES
#+BEGIN_SRC python
UNCLONABLE_MODULES = set(
    [
        "_asyncio",
        "_io",
        "marimo._ast",
        "marimo._plugins.ui",
        "numpy.lib.npyio",
    ]
)

#+END_SRC
** Function is_external
#+BEGIN_SRC python
def is_external(value: Any) -> bool:
    return "_marimo__cell_" not in inspect.getfile(value)

#+END_SRC
** Function is_primitive
#+BEGIN_SRC python
def is_primitive(value: Any) -> bool:
    # Tuples don't allow for write access
    if isinstance(value, tuple):
        return all(map(is_primitive, value))
    return isinstance(value, PRIMITIVES)

#+END_SRC
** Function is_primitive_type
#+BEGIN_SRC python
def is_primitive_type(value: type) -> bool:
    return any(issubclass(value, primitive) for primitive in PRIMITIVES)

#+END_SRC
** Function is_clone_primitive
#+BEGIN_SRC python
def is_clone_primitive(value: Any) -> bool:
    return isinstance(value, CLONE_PRIMITIVES)

#+END_SRC
** Function is_data_primitive
#+BEGIN_SRC python
def is_data_primitive(value: Any) -> bool:
    if is_primitive(value):
        return True

    if not (
        hasattr(value, "__array__")
        or hasattr(value, "toarray")
        or hasattr(value, "__array_interface__")
    ):
        return False

    # Handle cross device tensors particular to torch
    # Transfer may be expensive, so non-cpu tensors are considered
    # unhashable.
    if is_instance_by_name(value, "torch.Tensor"):
        return str(value.device) == "cpu"

    # If a numpy like array, ensure that it's not an object array.
    if hasattr(value, "dtype"):
        return not (
            value.dtype is None
            or (hasattr(value.dtype, "hasobject") and value.dtype.hasobject)
        )
    elif hasattr(value, "dtypes"):
        for dtype in value.dtypes:
            # Capture pandas cases
            if getattr(dtype, "hasobject", None):
                return False
            # Capture polars cases
            if hasattr(dtype, "is_numeric") and not dtype.is_numeric:
                return False
    # Otherwise may be a closely related array object
    return True

#+END_SRC
** Function _is_primitive_container
#+BEGIN_SRC python
def _is_primitive_container(
    value: Any, predicate: Callable[[Any], bool]
) -> bool:
    visited = set()

    def recurse_container(value: Any) -> bool:
        if is_primitive(value):
            return True

        if id(value) in visited:
            return True

        if isinstance(value, dict):
            visited.add(id(value))
            return all(map(predicate, value.items()))
        # Tuple has to be considered too, since a tuple can contain containers.
        if isinstance(value, (set, list, tuple)):
            visited.add(id(value))
            return all(map(predicate, value))

        return False

    return recurse_container(value)

#+END_SRC
** Function is_data_primitive_container
#+BEGIN_SRC python
def is_data_primitive_container(value: Any) -> bool:
    return _is_primitive_container(value, is_data_primitive)

#+END_SRC
** Function is_primitive_container
#+BEGIN_SRC python
def is_primitive_container(value: Any) -> bool:
    return _is_primitive_container(value, is_primitive)

#+END_SRC
** Function is_instance_by_name
#+BEGIN_SRC python
def is_instance_by_name(obj: object, name: str) -> bool:
    if not (hasattr(obj, "__module__") and hasattr(obj, "__class__")):
        return False
    obj_name = f"{obj.__module__}.{obj.__class__.__name__}"
    return obj_name == name

#+END_SRC
** Function is_unclonable_type
#+BEGIN_SRC python
def is_unclonable_type(obj: object) -> bool:
    return any([is_instance_by_name(obj, name) for name in UNCLONABLE_TYPES])

#+END_SRC
** Function from_unclonable_module
#+BEGIN_SRC python
def from_unclonable_module(obj: object) -> bool:
    obj = obj if hasattr(obj, "__module__") else obj.__class__
    return hasattr(obj, "__module__") and any(
        [obj.__module__.startswith(name) for name in UNCLONABLE_MODULES]
    )

#+END_SRC
** Function is_pure_scope
#+BEGIN_SRC python
def is_pure_scope(
    ref: Name,
    defs: dict[str, Any],
    cache: FN_CACHE_TYPE = None,
) -> bool:
    return inspect.ismodule(defs[ref]) or is_pure_function(
        ref, defs[ref], defs, cache
    )

#+END_SRC
** Function is_pure_function
#+BEGIN_SRC python
def is_pure_function(
    ref: Name,
    value: Any,
    defs: dict[str, Any],
    cache: FN_CACHE_TYPE = None,
    graph: Optional[DirectedGraph] = None,
) -> bool:
    if cache is None:
        cache = {}
    # Explicit removal of __hash__ indicates this is potentially mutable.
    # (e.g. list)
    if getattr(value, "__hash__", None) is None:
        return False
    if value in cache:
        return cache[value]
    # Trivial enough not to cache.
    if inspect.isclass(value) or not callable(value):
        return False
    # builtin_function_or_method are C functions, which we assume to be pure
    if inspect.isbuiltin(value):
        return True

    # Note: isfunction still covers lambdas, coroutines, etc.
    if not inspect.isfunction(value):
        return False

    # We assume all external module function references to be pure. Cache can
    # still be be invalidated by pin_modules attribute. Note this also captures
    # cases like functors from an external module.
    # TODO: Investigate embedded notebook values.
    if getattr(value, "__module__", None) != "__main__":
        return True

    cache[value] = True  # Prevent recursion

    def cancel_predicate(ref: Name, _data: VariableData) -> bool:
        if not cache[value]:
            return False

        # A pure function can only refer to other functions, classes, or
        # modules.
        # External variable reference makes it inherently impure.
        if ref in defs:
            # Recursion allows for effective DFS
            if not (
                inspect.ismodule(defs[ref])
                or is_pure_function(ref, defs[ref], defs, cache, graph)
            ):
                cache[value] = False
                return False
        return True

    if graph is not None:
        graph.get_transitive_references(
            {ref}, inclusive=False, predicate=cancel_predicate
        )

    return cache[value]

#+END_SRC
** Function build_ref_predicate_for_primitives
#+BEGIN_SRC python
def build_ref_predicate_for_primitives(
    glbls: dict[str, Any],
    primitives: Optional[tuple[type, ...]] = None,
) -> Callable[[Name, VariableData], bool]:
    """
    Builds a predicate function to determine if a reference should be included

    Args:
        glbls: The global variables dictionary to base the predicate on
        primitives: A tuple of types that should be considered as base types
    Returns:
        A function that takes a variable name and associated data and
        returns True if its reference should be included in a reference search.

    All declared variables are tied together under the graph of required_refs.
    Strict execution gets the minimum graph of definitions for execution.
    Certain definitions, like lambdas, functions, and classes contain an
    executable body and require their `required_refs` to be scope (included in
    this graph). This function determines if a potential reference should be
    included in the graph based on its computed type. Consider:

    >>> def foo():
    ...     return bar()

    here `foo` is a function with `bar` as a reference in the execution body,
    so if `foo` is a reference, both `bar` and `foo` should be included in the
    graph, otherwise we'll get a NameError on `bar` if `foo` is called.
    Compare that to:

    >>> x = foo()

    if `x` is the only reference, should `foo` be included in the graph? It
    depends on the context, so we defer to the type of `x` which has already
    been computed at this point. If `x` is a known 'primitive' type, and thus
    does not have an executable body, we can exclude `foo` from the graph.
    However, `foo` may return a object or another function, which in turn may
    have references; so if x doesn't match the very low bar 'primitive', its
    `required_refs` are included in the graph.

    NB: The builtin `inspect.getclosurevars` exists, but it fails on some of
    these edgecases.

    NB: lambdas, as anonymous functions, do not have a name to refer to them-
    so visitor injects the dummy variable `_lambda` into the `required_refs` to
    denote their presence.
    """

    if primitives is None:
        primitives = PRIMITIVES

    def check_ref(ref: Name) -> bool:
        return ref in glbls and (
            inspect.isfunction(glbls[ref])
            or inspect.ismodule(glbls[ref])
            or inspect.isclass(glbls[ref])
            or callable(glbls[ref])
        )

    def only_scoped_refs(ref: Name, data: VariableData) -> bool:
        # TODO: Other common types could be added here, like numpy arrays that
        # are not dtype=object, etc.. that are known not to be dependent on the
        # functions that created them.

        # This errs on the side of including too much, but that's a better user
        # experience than not having definitions available.
        return (
            ref in glbls
            and not isinstance(glbls[ref], primitives)
            and (
                "_lambda" in data.required_refs
                or any(map(check_ref, data.required_refs | {ref}))
            )
        )

    return only_scoped_refs

#+END_SRC
* redirect_streams
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.redirect_streams
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/redirect_streams.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import contextlib
import os
import sys
from typing import Iterator

from marimo._ast.cell import CellId_t
from marimo._messaging.streams import (
    redirect,
)
from marimo._messaging.types import Stderr, Stdin, Stdout, Stream

#+END_SRC
** Function forward_os_stream
#+BEGIN_SRC python
def forward_os_stream(stream_object: Stdout | Stderr, fd: int) -> None:
    while True:
        data = os.read(fd, 1024)
        if not data:
            break
        stream_object.write(data.decode())

#+END_SRC
** Function dup2newfd
#+BEGIN_SRC python
def dup2newfd(fd: int) -> tuple[int, int, int]:
    """Create a pipe, with `fd` at the write end of it.

    Returns
    - duplicate (os.dup) of `fd`
    - read end of pipe
    - fd (which now points to the file referenced by the write end of the pipe)

    When done with the pipe, the write-end of the pipe should be closed
    and remapped to point to the saved duplicate. The read end should
    also be closed, as should the saved duplicate.
    """
    # fd_dup keeps a pointer to `fd`'s original location
    fd_dup = os.dup(fd)
    # create a pipe, with `fd` as the write end of it
    read_fd, write_fd = os.pipe()
    # repurpose fd to point to the write-end of the pipe
    os.dup2(write_fd, fd)
    os.close(write_fd)
    return fd_dup, read_fd, fd

#+END_SRC
** @contextlib.contextmanager: Function redirect_streams
#+BEGIN_SRC python
# Redirect output stream and stdout/stderr/stdin (if they have been installed)
@contextlib.contextmanager
def redirect_streams(
    cell_id: CellId_t,
    stream: Stream,
    stdout: Stdout | None,
    stderr: Stderr | None,
    stdin: Stdin | None,
) -> Iterator[None]:
    cell_id_old = stream.cell_id

    # In a nested context; NOOP so messages still reach the top-level cell.
    if cell_id_old is not None:
        try:
            yield
        finally:
            ...
        return

    stream.cell_id = cell_id
    if stdout is None or stderr is None:
        try:
            yield
        finally:
            stream.cell_id = cell_id_old
        return

    # NB: Python doesn't allow monkey patching methods builtins, so
    # we replace these streams outright
    py_stdout = sys.stdout
    py_stderr = sys.stderr
    py_stdin = sys.stdin
    sys.stdout = stdout  # type: ignore
    sys.stderr = stderr  # type: ignore
    sys.stdin = stdin  # type: ignore

    try:
        with redirect(stdout), redirect(stderr):
            yield
    finally:
        # The redirect context manager relies on these being installed;
        # restore them after the context manager quits
        sys.stdout = py_stdout
        sys.stderr = py_stderr
        sys.stdin = py_stdin
        stream.cell_id = cell_id_old

#+END_SRC
* requests
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.requests
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/requests.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union
from uuid import uuid4

from marimo._ast.cell import CellId_t
from marimo._config.config import MarimoConfig
from marimo._data.models import DataTableSource

#+END_SRC
** Assignment UIElementId = str
#+BEGIN_SRC python
UIElementId = str

#+END_SRC
** Assignment CompletionRequestId = str
#+BEGIN_SRC python
CompletionRequestId = str

#+END_SRC
** Assignment FunctionCallId = str
#+BEGIN_SRC python
FunctionCallId = str

#+END_SRC
** Assignment T = TypeVar("T")
#+BEGIN_SRC python
T = TypeVar("T")

#+END_SRC
** Assignment ListOrValue = Union[T, List[T]]
#+BEGIN_SRC python
ListOrValue = Union[T, List[T]]

#+END_SRC
** Assignment SerializedQueryParams = Dict[str, ListOrValue[str]]
#+BEGIN_SRC python
SerializedQueryParams = Dict[str, ListOrValue[str]]

#+END_SRC
** Assignment Primitive = Union[str, bool, int, float]
#+BEGIN_SRC python
Primitive = Union[str, bool, int, float]

#+END_SRC
** Assignment SerializedCLIArgs = Dict[str, ListOrValue[Primitive]]
#+BEGIN_SRC python
SerializedCLIArgs = Dict[str, ListOrValue[Primitive]]

#+END_SRC
** @dataclass: Class ExecutionRequest
#+BEGIN_SRC python
@dataclass
class ExecutionRequest:
    cell_id: CellId_t
    code: str
    timestamp: float = field(default_factory=time.time)

#+END_SRC
** @dataclass: Class ExecuteStaleRequest
#+BEGIN_SRC python
@dataclass
class ExecuteStaleRequest: ...

#+END_SRC
** @dataclass: Class ExecuteMultipleRequest
#+BEGIN_SRC python
@dataclass
class ExecuteMultipleRequest:
    # ids of cells to run
    cell_ids: List[CellId_t]
    # code to register/run for each cell
    codes: List[str]
    # time at which the request was received
    timestamp: float = field(default_factory=time.time)

    @property
    def execution_requests(self) -> List[ExecutionRequest]:
        return [
            ExecutionRequest(
                cell_id=cell_id, code=code, timestamp=self.timestamp
            )
            for cell_id, code in zip(self.cell_ids, self.codes)
        ]

    def __post_init__(self) -> None:
        assert len(self.cell_ids) == len(
            self.codes
        ), "Mismatched cell_ids and codes"

#+END_SRC
** @dataclass: Class ExecuteScratchpadRequest
#+BEGIN_SRC python
@dataclass
class ExecuteScratchpadRequest:
    code: str

#+END_SRC
** @dataclass: Class RenameRequest
#+BEGIN_SRC python
@dataclass
class RenameRequest:
    filename: str

#+END_SRC
** @dataclass: Class SetUIElementValueRequest
#+BEGIN_SRC python
@dataclass
class SetUIElementValueRequest:
    object_ids: List[UIElementId]
    values: List[Any]
    # uniquely identifies the request
    token: str = field(default_factory=lambda: str(uuid4()))

    def __post_init__(self) -> None:
        assert len(self.object_ids) == len(
            self.values
        ), "Mismatched object_ids and values"

    @staticmethod
    def from_ids_and_values(
        ids_and_values: List[Tuple[UIElementId, Any]],
    ) -> SetUIElementValueRequest:
        if not ids_and_values:
            return SetUIElementValueRequest(object_ids=[], values=[])
        object_ids, values = zip(*ids_and_values)
        return SetUIElementValueRequest(
            object_ids=list(object_ids), values=list(values)
        )

    @property
    def ids_and_values(self) -> List[Tuple[UIElementId, Any]]:
        return list(zip(self.object_ids, self.values))

#+END_SRC
** @dataclass: Class FunctionCallRequest
#+BEGIN_SRC python
@dataclass
class FunctionCallRequest:
    function_call_id: FunctionCallId
    namespace: str
    function_name: str
    args: Dict[str, Any]

#+END_SRC
** @dataclass: Class AppMetadata
#+BEGIN_SRC python
@dataclass
class AppMetadata:
    """Hold metadata about the app, like its filename."""

    query_params: SerializedQueryParams
    cli_args: SerializedCLIArgs

    filename: Optional[str] = None

#+END_SRC
** @dataclass: Class SetCellConfigRequest
#+BEGIN_SRC python
@dataclass
class SetCellConfigRequest:
    # Map from Cell ID to (possibly partial) CellConfig
    configs: Dict[CellId_t, Dict[str, Any]]

#+END_SRC
** @dataclass: Class SetUserConfigRequest
#+BEGIN_SRC python
@dataclass
class SetUserConfigRequest:
    # MarimoConfig TypedDict
    config: MarimoConfig

#+END_SRC
** @dataclass: Class CreationRequest
#+BEGIN_SRC python
@dataclass
class CreationRequest:
    execution_requests: Tuple[ExecutionRequest, ...]
    set_ui_element_value_request: SetUIElementValueRequest

#+END_SRC
** @dataclass: Class DeleteCellRequest
#+BEGIN_SRC python
@dataclass
class DeleteCellRequest:
    cell_id: CellId_t

#+END_SRC
** @dataclass: Class StopRequest
#+BEGIN_SRC python
@dataclass
class StopRequest:
    pass

#+END_SRC
** @dataclass: Class CodeCompletionRequest
#+BEGIN_SRC python
@dataclass
class CodeCompletionRequest:
    id: CompletionRequestId
    document: str
    cell_id: CellId_t

#+END_SRC
** @dataclass: Class InstallMissingPackagesRequest
#+BEGIN_SRC python
@dataclass
class InstallMissingPackagesRequest:
    # TODO: index URL (index/channel/...)
    manager: str

    # Map from package name to desired version
    # If the package name is not in the map, the latest version
    # will be installed
    versions: Dict[str, str]

#+END_SRC
** @dataclass: Class PreviewDatasetColumnRequest
#+BEGIN_SRC python
@dataclass
class PreviewDatasetColumnRequest:
    # The source type of the dataset
    source_type: DataTableSource
    # The source of the dataset
    source: str
    # The name of the dataset
    # This currently corresponds to the variable name
    table_name: str
    # The name of the column
    column_name: str

#+END_SRC
** Assignment ControlRequest
#+BEGIN_SRC python
ControlRequest = Union[
    ExecuteMultipleRequest,
    ExecuteScratchpadRequest,
    ExecuteStaleRequest,
    CreationRequest,
    DeleteCellRequest,
    FunctionCallRequest,
    RenameRequest,
    SetCellConfigRequest,
    SetUserConfigRequest,
    SetUIElementValueRequest,
    StopRequest,
    InstallMissingPackagesRequest,
    PreviewDatasetColumnRequest,
]

#+END_SRC
* runtime
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.runtime
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/runtime.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import asyncio
import builtins
import contextlib
import dataclasses
import io
import itertools
import os
import pathlib
import signal
import sys
import threading
import time
import traceback
from copy import copy
from multiprocessing import connection
from typing import TYPE_CHECKING, Any, Callable, Iterator, List, Optional, cast
from uuid import uuid4

from marimo import _loggers
from marimo._ast.cell import CellConfig, CellId_t, CellImpl
from marimo._ast.compiler import compile_cell
from marimo._ast.visitor import ImportData, Name, VariableData
from marimo._config.config import ExecutionType, MarimoConfig, OnCellChangeType
from marimo._config.settings import GLOBAL_SETTINGS
from marimo._data.preview_column import (
    get_column_preview_dataframe,
    get_column_preview_for_sql,
)
from marimo._dependencies.dependencies import DependencyManager
from marimo._messaging.cell_output import CellChannel
from marimo._messaging.errors import (
    Error,
    MarimoInterruptionError,
    MarimoStrictExecutionError,
    MarimoSyntaxError,
    UnknownError,
)
from marimo._messaging.ops import (
    CellOp,
    CompletedRun,
    DataColumnPreview,
    FunctionCallResult,
    HumanReadableStatus,
    InstallingPackageAlert,
    MissingPackageAlert,
    PackageStatusType,
    RemoveUIElements,
    VariableDeclaration,
    Variables,
    VariableValue,
    VariableValues,
)
from marimo._messaging.streams import (
    QueuePipe,
    ThreadSafeStderr,
    ThreadSafeStdin,
    ThreadSafeStdout,
    ThreadSafeStream,
)
from marimo._messaging.tracebacks import write_traceback
from marimo._messaging.types import (
    KernelMessage,
    Stderr,
    Stdin,
    Stdout,
    Stream,
)
from marimo._output.rich_help import mddoc
from marimo._plugins.core.web_component import JSONType
from marimo._plugins.ui._core.ui_element import MarimoConvertValueException
from marimo._runtime import dataflow, handlers, marimo_pdb, patches
from marimo._runtime.app_meta import AppMeta
from marimo._runtime.context import (
    ContextNotInitializedError,
    ExecutionContext,
    get_context,
)
from marimo._runtime.context.kernel_context import initialize_kernel_context
from marimo._runtime.control_flow import MarimoInterrupt
from marimo._runtime.input_override import input_override
from marimo._runtime.packages.module_registry import ModuleRegistry
from marimo._runtime.packages.package_manager import PackageManager
from marimo._runtime.packages.package_managers import create_package_manager
from marimo._runtime.packages.utils import is_python_isolated
from marimo._runtime.params import CLIArgs, QueryParams
from marimo._runtime.redirect_streams import redirect_streams
from marimo._runtime.reload.autoreload import ModuleReloader
from marimo._runtime.reload.module_watcher import ModuleWatcher
from marimo._runtime.requests import (
    AppMetadata,
    CodeCompletionRequest,
    ControlRequest,
    CreationRequest,
    DeleteCellRequest,
    ExecuteMultipleRequest,
    ExecuteScratchpadRequest,
    ExecuteStaleRequest,
    ExecutionRequest,
    FunctionCallRequest,
    InstallMissingPackagesRequest,
    PreviewDatasetColumnRequest,
    RenameRequest,
    SetCellConfigRequest,
    SetUIElementValueRequest,
    SetUserConfigRequest,
    StopRequest,
)
from marimo._runtime.runner import cell_runner
from marimo._runtime.runner.hooks import (
    ON_FINISH_HOOKS,
    POST_EXECUTION_HOOKS,
    PRE_EXECUTION_HOOKS,
    PREPARATION_HOOKS,
)
from marimo._runtime.runner.hooks_on_finish import OnFinishHookType
from marimo._runtime.runner.hooks_post_execution import PostExecutionHookType
from marimo._runtime.runner.hooks_pre_execution import PreExecutionHookType
from marimo._runtime.runner.hooks_preparation import PreparationHookType
from marimo._runtime.scratch import SCRATCH_CELL_ID
from marimo._runtime.state import State
from marimo._runtime.utils.set_ui_element_request_manager import (
    SetUIElementRequestManager,
)
from marimo._runtime.validate_graph import check_for_errors
from marimo._runtime.win32_interrupt_handler import Win32InterruptHandler
from marimo._server.model import SessionMode
from marimo._server.types import QueueType
from marimo._tracer import kernel_tracer
from marimo._utils.assert_never import assert_never
from marimo._utils.platform import is_pyodide
from marimo._utils.signals import restore_signals
from marimo._utils.typed_connection import TypedConnection
from marimo._utils.variables import is_local

#+END_SRC
** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
if TYPE_CHECKING:
    import queue
    from collections.abc import Sequence
    from types import ModuleType

    from marimo._plugins.ui._core.ui_element import UIElement

LOGGER = _loggers.marimo_logger()

#+END_SRC
** @mddoc: Function defs
#+BEGIN_SRC python
@mddoc
def defs() -> tuple[str, ...]:
    """Get the definitions of the currently executing cell.

    **Returns**:

    - tuple of the currently executing cell's defs.
    """
    try:
        ctx = get_context()
    except ContextNotInitializedError:
        return tuple()

    if ctx.execution_context is not None:
        return tuple(
            sorted(
                defn
                for defn in ctx.graph.cells[ctx.execution_context.cell_id].defs
            )
        )
    return tuple()

#+END_SRC
** @mddoc: Function refs
#+BEGIN_SRC python
@mddoc
def refs() -> tuple[str, ...]:
    """Get the references of the currently executing cell.

    **Returns**:

    - tuple of the currently executing cell's refs.
    """
    try:
        ctx = get_context()
    except ContextNotInitializedError:
        return tuple()

    # builtins that have not been shadowed by the user
    unshadowed_builtins = set(builtins.__dict__.keys()).difference(
        set(ctx.graph.definitions.keys())
    )

    if ctx.execution_context is not None:
        return tuple(
            sorted(
                defn
                for defn in ctx.graph.cells[ctx.execution_context.cell_id].refs
                # exclude builtins that have not been shadowed
                if defn not in unshadowed_builtins
            )
        )
    return tuple()

#+END_SRC
** @mddoc: Function query_params
#+BEGIN_SRC python
@mddoc
def query_params() -> QueryParams:
    """Get the query parameters of a marimo app.

    **Examples**:

    Keep the text input in sync with the URL query parameters.

    ```python3
    # In it's own cell
    query_params = mo.query_params()

    # In another cell
    search = mo.ui.text(
        value=query_params["search"] or "",
        on_change=lambda value: query_params.set("search", value),
    )
    search
    ```

    You can also set the query parameters reactively:

    ```python3
    toggle = mo.ui.switch(label="Toggle me")
    toggle

    # In another cell
    query_params["is_enabled"] = toggle.value
    ```

    **Returns**:

    - A `QueryParams` object containing the query parameters.
      You can directly interact with this object like a dictionary.
      If you mutate this object, changes will be persisted to the frontend
      query parameters and any other cells referencing the query parameters
      will automatically re-run.
    """
    return get_context().query_params

#+END_SRC
** @mddoc: Function app_meta
#+BEGIN_SRC python
@mddoc
def app_meta() -> AppMeta:
    """Get the metadata of a marimo app.

    The `AppMeta` class provides access to runtime metadata about a marimo app,
    such as its display theme and execution mode.

    **Examples**:

    Get the current theme and conditionally set a plotting library's theme:

    ```python
    import altair as alt

    # Enable dark theme for Altair when marimo is in dark mode
    alt.themes.enable("dark" if mo.app_meta().theme == "dark" else "default")
    ```

    Show content only in edit mode:

    ```python
    # Only show this content when editing the notebook
    mo.md("# Developer Notes") if mo.app_meta().mode == "edit" else None
    ```

    **Returns**:

    - An `AppMeta` object containing the app's metadata.
    """
    return AppMeta()

#+END_SRC
** @mddoc: Function cli_args
#+BEGIN_SRC python
@mddoc
def cli_args() -> CLIArgs:
    """Get the command line arguments of a marimo notebook.

        **Examples**:

    `marimo edit notebook.py -- -size 10`

        ```python3
        # Access the command line arguments
        size = mo.cli_args().get("size") or 100

        for i in range(size):
            print(i)
        ```

        **Returns**:

        - A dictionary containing the command line arguments.
          This dictionary is read-only and cannot be mutated.
    """
    return get_context().cli_args

#+END_SRC
** @mddoc: Function notebook_dir
#+BEGIN_SRC python
@mddoc
def notebook_dir() -> pathlib.Path | None:
    """Get the directory of the currently executing notebook.

    **Returns**:

    - A `pathlib.Path` object representing the directory of the current
      notebook, or `None` if the notebook's directory cannot be determined.

    **Examples**:

    ```python
    data_file = mo.notebook_dir() / "data" / "example.csv"
    # Use the directory to read a file
    if data_file.exists():
        print(f"Found data file: {data_file}")
    else:
        print("No data file found")
    ```
    """
    try:
        ctx = get_context()
    except ContextNotInitializedError:
        return None

    filename = ctx.filename
    if filename is not None:
        return pathlib.Path(filename).parent.absolute()
    return None

#+END_SRC
** @dataclasses.dataclass: Class CellMetadata
#+BEGIN_SRC python
@dataclasses.dataclass
class CellMetadata:
    """CellMetadata

    Metadata the kernel needs to persist, even when a cell is removed
    from the graph or when a cell can't be formed from user code due to syntax
    errors.
    """

    config: CellConfig = dataclasses.field(default_factory=CellConfig)

#+END_SRC
** Class Kernel
#+BEGIN_SRC python
class Kernel:
    """Kernel that manages the dependency graph and its execution.

    Args:
    - cell_configs: initial configuration for each cell
    - app_metadata: metadata about the notebook
    - user_config: the initial user configuration
    - stream: object used to communicate with the server/outside world
    - stdout: replacement for sys.stdout
    - stderr: replacement for sys.stderr
    - stdin: replacement for sys.stdin
    - module: module in which to execute code
    - enqueue_control_request: callback to enqueue control requests
    - debugger_override: a replacement for the built-in Pdb
    """

    def __init__(
        self,
        cell_configs: dict[CellId_t, CellConfig],
        app_metadata: AppMetadata,
        user_config: MarimoConfig,
        stream: Stream,
        stdout: Stdout | None,
        stderr: Stderr | None,
        stdin: Stdin | None,
        module: ModuleType,
        enqueue_control_request: Callable[[ControlRequest], None],
        preparation_hooks: list[PreparationHookType] | None = None,
        pre_execution_hooks: list[PreExecutionHookType] | None = None,
        post_execution_hooks: list[PostExecutionHookType] | None = None,
        on_finish_hooks: list[OnFinishHookType] | None = None,
        debugger_override: marimo_pdb.MarimoPdb | None = None,
    ) -> None:
        self.app_metadata = app_metadata
        self.query_params = QueryParams(app_metadata.query_params)
        self.cli_args = CLIArgs(app_metadata.cli_args)
        self.stream = stream
        self.stdout = stdout
        self.stderr = stderr
        self.stdin = stdin
        self.enqueue_control_request = enqueue_control_request
        # timestamp at which most recently processed interrupt was seen;
        # the kernel rejects run requests that were issued before that
        # timestamp, to save the user from having to spam the interrupt button
        self.last_interrupt_timestamp: Optional[float] = None

        self._preparation_hooks = (
            preparation_hooks
            if preparation_hooks is not None
            else PREPARATION_HOOKS
        )
        self._pre_execution_hooks = (
            pre_execution_hooks
            if pre_execution_hooks is not None
            else PRE_EXECUTION_HOOKS
        )
        self._post_execution_hooks = (
            post_execution_hooks
            if post_execution_hooks is not None
            else POST_EXECUTION_HOOKS
        )
        self._on_finish_hooks = (
            on_finish_hooks if on_finish_hooks is not None else ON_FINISH_HOOKS
        )

        self._globals_lock = threading.RLock()
        self._completion_worker_started = False

        self.debugger = debugger_override
        if self.debugger is not None:
            patches.patch_pdb(self.debugger)

        self._module = module
        if self.app_metadata.filename is not None:
            # TODO(akshayka): When a file is renamed / moved to another folder,
            # we need to update sys.path.
            try:
                notebook_directory = str(
                    pathlib.Path(self.app_metadata.filename).parent.absolute()
                )
                if notebook_directory not in sys.path:
                    sys.path.insert(0, notebook_directory)
            except Exception as e:
                LOGGER.warning(
                    "Failed to add directory to path (error %e)", str(e)
                )
        elif "" not in sys.path:
            # an empty string represents ...
            #   the current directory, when using
            #      marimo edit filename.py / marimo run
            #   the marimo home directory, when using
            #      marimo edit (ie homepage)
            sys.path.insert(0, "")

        self.graph = dataflow.DirectedGraph()
        self.cell_metadata: dict[CellId_t, CellMetadata] = {
            cell_id: CellMetadata(config=config)
            for cell_id, config in cell_configs.items()
        }
        self.module_registry = ModuleRegistry(
            self.graph, excluded_modules=set()
        )
        self.package_manager: PackageManager | None = None
        self.module_reloader: ModuleReloader | None = None
        self.module_watcher: ModuleWatcher | None = None

        # Load runtime settings from user config
        self.user_config = user_config
        self.reactive_execution_mode: OnCellChangeType = user_config[
            "runtime"
        ]["on_cell_change"]
        self.execution_type: ExecutionType = user_config.get(
            "experimental", {}
        ).get("execution_type", "relaxed")
        self._update_runtime_from_user_config(user_config)

        # Set up the execution context
        self.execution_context: Optional[ExecutionContext] = None
        # initializers to override construction of ui elements
        self.ui_initializers: dict[str, Any] = {}
        # errored cells
        self.errors: dict[CellId_t, tuple[Error, ...]] = {}
        # Mapping from state to the cell when its setter
        # was invoked. New state updates evict older ones.
        self.state_updates: dict[State[Any], CellId_t] = {}

        if not is_pyodide():
            patches.patch_micropip(self.globals)
        exec("import marimo as __marimo__", self.globals)

    def lazy(self) -> bool:
        return self.reactive_execution_mode == "lazy"

    def _execute_stale_cells_callback(self) -> None:
        return self.enqueue_control_request(ExecuteStaleRequest())

    def _execute_install_missing_packages_callback(
        self, package_manager: str
    ) -> None:
        return self.enqueue_control_request(
            InstallMissingPackagesRequest(manager=package_manager, versions={})
        )

    def _update_runtime_from_user_config(self, config: MarimoConfig) -> None:
        package_manager = config["package_management"]["manager"]
        autoreload_mode = config["runtime"]["auto_reload"]
        self.reactive_execution_mode = config["runtime"]["on_cell_change"]
        self.user_config = config

        if (
            self.package_manager is None
            or package_manager != self.package_manager.name
        ):
            self.package_manager = create_package_manager(package_manager)

        if (
            autoreload_mode == "lazy" or autoreload_mode == "autorun"
            # Pyodide doesn't support hot module reloading
        ) and not is_pyodide():
            if self.module_reloader is None:
                self.module_reloader = ModuleReloader()

            if (
                self.module_watcher is not None
                and self.module_watcher.mode != autoreload_mode
            ):
                self.module_watcher.stop()
                self.module_watcher = None

            if self.module_watcher is None:
                self.module_watcher = ModuleWatcher(
                    self.graph,
                    reloader=self.module_reloader,
                    enqueue_run_stale_cells=self._execute_stale_cells_callback,
                    mode=autoreload_mode,
                    stream=self.stream,
                )
        else:
            self.module_reloader = None
            if self.module_watcher is not None:
                self.module_watcher.stop()
                self.module_watcher = None

    @property
    def globals(self) -> dict[Any, Any]:
        return self._module.__dict__

    @contextlib.contextmanager
    def lock_globals(self) -> Iterator[None]:
        # The only other thread accessing globals is the completion worker. If
        # we haven't started a completion worker, there's no need to lock
        # globals.
        if self._completion_worker_started:
            with self._globals_lock:
                yield
        else:
            yield

    def start_completion_worker(
        self, completion_queue: QueueType[CodeCompletionRequest]
    ) -> None:
        """Must be called after context is initialized"""
        from marimo._runtime.complete import completion_worker

        threading.Thread(
            target=completion_worker,
            args=(
                completion_queue,
                self.graph,
                self.globals,
                self._globals_lock,
                get_context().stream,
            ),
            daemon=True,
        ).start()
        self._completion_worker_started = True

    @kernel_tracer.start_as_current_span("code_completion")
    def code_completion(
        self, request: CodeCompletionRequest, docstrings_limit: int
    ) -> None:
        from marimo._runtime.complete import complete

        complete(
            request,
            self.graph,
            self.globals,
            self._globals_lock,
            get_context().stream,
            docstrings_limit,
        )

    @contextlib.contextmanager
    def _install_execution_context(
        self, cell_id: CellId_t, setting_element_value: bool = False
    ) -> Iterator[ExecutionContext]:
        self.execution_context = ExecutionContext(
            cell_id, setting_element_value
        )
        with (
            get_context().provide_ui_ids(str(cell_id)),
            redirect_streams(
                cell_id,
                stream=self.stream,
                stdout=self.stdout,
                stderr=self.stderr,
                stdin=self.stdin,
            ),
        ):
            modules = None
            try:
                if self.module_reloader is not None:
                    # Reload modules if they have changed
                    modules = set(sys.modules)
                    self.module_reloader.check(
                        modules=sys.modules, reload=True
                    )
                yield self.execution_context
            finally:
                self.execution_context = None
                if self.module_reloader is not None and modules is not None:
                    # Note timestamps for newly loaded modules
                    new_modules = set(sys.modules) - modules
                    self.module_reloader.check(
                        modules={m: sys.modules[m] for m in new_modules},
                        reload=False,
                    )

    def _register_cell(self, cell_id: CellId_t, cell: CellImpl) -> None:
        if cell_id in self.cell_metadata:
            # If we already have a config for this cell id, restore it
            # This can happen when a cell was previously deactivated (due to a
            # syntax error or multiple definition error, for example) and then
            # re-registered
            cell.configure(self.cell_metadata[cell_id].config)
        elif cell_id not in self.cell_metadata:
            self.cell_metadata[cell_id] = CellMetadata()

        self.graph.register_cell(cell_id, cell)
        # leaky abstraction: the graph doesn't know about stale modules, so
        # we have to check for them here.
        module_reloader = self.module_reloader
        if (
            module_reloader is not None
            and module_reloader.cell_uses_stale_modules(cell)
        ):
            self.graph.set_stale(set([cell.cell_id]), prune_imports=True)
        LOGGER.debug("registered cell %s", cell_id)
        LOGGER.debug("parents: %s", self.graph.parents[cell_id])
        LOGGER.debug("children: %s", self.graph.children[cell_id])

    def _try_compiling_cell(
        self, cell_id: CellId_t, code: str, carried_imports: list[ImportData]
    ) -> tuple[Optional[CellImpl], Optional[Error]]:
        error: Optional[Error] = None
        try:
            cell = compile_cell(
                code, cell_id=cell_id, carried_imports=carried_imports
            )
        except Exception as e:
            cell = None
            if isinstance(e, SyntaxError):
                tmpio = io.StringIO()
                traceback.print_exc(file=tmpio, limit=0)
                tmpio.seek(0)
                syntax_error = tmpio.read().split("\n")
                # first line has the form File XXX, line XXX
                syntax_error[0] = syntax_error[0][
                    syntax_error[0].find("line") :
                ]
                error = MarimoSyntaxError(msg="\n".join(syntax_error))
            else:
                tmpio = io.StringIO()
                traceback.print_exc(file=tmpio)
                tmpio.seek(0)
                error = UnknownError(msg=tmpio.read())
        return cell, error

    def _try_registering_cell(
        self, cell_id: CellId_t, code: str, carried_imports: list[ImportData]
    ) -> Optional[Error]:
        """Attempt to register a cell with given id and code.

        Precondition: a cell with the supplied id must not already exist in the
        graph.

        If cell was unable to be registered, returns an Error object.
        """
        cell, error = self._try_compiling_cell(cell_id, code, carried_imports)

        if cell is not None:
            self._register_cell(cell_id, cell)

        return error

    def _maybe_register_cell(
        self, cell_id: CellId_t, code: str
    ) -> tuple[set[CellId_t], Optional[Error]]:
        """Register a cell (given by id, code) if not already registered.

        If a cell with id `cell_id` is already registered but with different
        code, that cell is deleted from the graph and a new cell with the
        same id but different code is registered.

        Returns:
        - a set of ids for cells that were previously children of `cell_id`
          but are no longer children of `cell_id` after registration;
          only non-empty when `cell-id` was already registered but with
          different code.
        - an `Error` if the cell couldn't be registered, `None` otherwise
        """
        previous_children: set[CellId_t] = set()
        error = None
        if not self.graph.is_cell_cached(cell_id, code):
            previous_cell = self.graph.cells.get(cell_id, None)

            if (
                previous_cell is not None
                and previous_cell.import_workspace.is_import_block
            ):
                # If the previous is being replaced by another import block,
                # then the new cell should try to carry over the previous
                # cell's imports to prevent unnecessary re-runs.
                carried_imports = [
                    import_data
                    for import_data in previous_cell.imports
                    if import_data.definition in self.globals
                    and import_data.definition
                    in previous_cell.import_workspace.imported_defs
                ]
            else:
                carried_imports = []

            if previous_cell is not None:
                LOGGER.debug("Deleting cell %s", cell_id)
                previous_children = self._deactivate_cell(cell_id)

            error = self._try_registering_cell(
                cell_id, code, carried_imports=carried_imports
            )
            if error is not None and previous_cell is not None:
                # The frontend keeps the cell around in the case of a
                # registration error; let the FE know the cell is no longer
                # stale.
                previous_cell.set_stale(False)

            # For any newly imported namespaces, add them to the metadata
            #
            # TODO(akshayka): Consider using the module watcher to discover
            # packages used by a notebook; that would have the benefit of
            # discovering transitive dependencies, ie if a notebook used a
            # local module that in turn used packages available on PyPI.
            if self._should_update_script_metadata():
                cell = self.graph.cells.get(cell_id, None)
                if cell:
                    prev_imports: set[Name] = (
                        set([im.namespace for im in previous_cell.imports])
                        if previous_cell
                        else set()
                    )
                    to_add = cell.imported_namespaces - prev_imports
                    self._update_script_metadata(
                        import_namespaces_to_add=list(to_add)
                    )

        LOGGER.debug(
            "graph:\n\tcell id %s\n\tparents %s\n\tchildren %s\n\tsiblings %s",
            cell_id,
            self.graph.parents,
            self.graph.children,
            self.graph.siblings,
        )

        # We only return cells that were previously children of cell_id
        # but are no longer children of the newly registered cell; these
        # returned cells are stale.
        children = self.graph.children.get(cell_id, set())
        return previous_children - children, error

    def _delete_variables(
        self,
        variables: dict[Name, list[VariableData]],
        exclude_defs: set[Name],
    ) -> None:
        """Delete `names` from kernel, except for `exclude_defs`"""
        for name, variable_data in variables.items():
            # Take the last definition of the variable
            variable = variable_data[-1]
            if name in exclude_defs:
                continue

            if variable.kind == "table" and DependencyManager.duckdb.has():
                import duckdb

                # We only drop in-memory tables: we don't want to drop tables
                # on databases!
                try:
                    duckdb.execute(f"DROP TABLE IF EXISTS memory.main.{name}")
                except Exception as e:
                    LOGGER.warning("Failed to drop table %s: %s", name, str(e))
            elif variable.kind == "view" and DependencyManager.duckdb.has():
                import duckdb

                # We only drop in-memory views for the same reason.
                try:
                    duckdb.execute(f"DROP VIEW IF EXISTS memory.main.{name}")
                except Exception as e:
                    LOGGER.warning("Failed to drop view %s: %s", name, str(e))
            elif variable.kind == "catalog" and DependencyManager.duckdb.has():
                import duckdb

                try:
                    duckdb.execute(f"DETACH DATABASE IF EXISTS {name}")
                except Exception as e:
                    LOGGER.warning(
                        "Failed to detach catalog %s: %s", name, str(e)
                    )
            else:
                if name in self.globals:
                    del self.globals[name]

                if (
                    "__annotations__" in self.globals
                    and name in self.globals["__annotations__"]
                ):
                    del self.globals["__annotations__"][name]

    def _invalidate_cell_state(
        self,
        cell_id: CellId_t,
        exclude_defs: Optional[set[Name]] = None,
        deletion: bool = False,
    ) -> None:
        """Cleanup state associated with this cell.

        Deletes a cell's defs from the kernel state, except for the names in
        `exclude_defs`, and instructs the frontend to invalidate its UI
        elements.
        """
        cell = self.graph.cells[cell_id]
        cell.import_workspace.imported_defs = set()
        missing_modules_before_deletion = (
            self.module_registry.missing_modules()
        )

        temporaries = {
            name: [VariableData(kind="variable")] for name in cell.temporaries
        }
        self._delete_variables(
            {**cell.variable_data, **temporaries},
            exclude_defs if exclude_defs is not None else set(),
        )

        missing_modules_after_deletion = (
            missing_modules_before_deletion & self.module_registry.modules()
        )
        if (
            self.package_manager is not None
            and missing_modules_after_deletion
            != missing_modules_before_deletion
        ):
            if self.package_manager.should_auto_install():
                self._execute_install_missing_packages_callback(
                    self.package_manager.name
                )
            else:
                # Deleting a cell can make the set of missing packages smaller
                MissingPackageAlert(
                    packages=list(
                        sorted(
                            pkg
                            for mod in missing_modules_after_deletion
                            if not self.package_manager.attempted_to_install(
                                pkg := self.package_manager.module_to_package(
                                    mod
                                )
                            )
                        )
                    ),
                    isolated=is_python_isolated(),
                ).broadcast()

        cell.set_output(None)
        get_context().cell_lifecycle_registry.dispose(
            cell_id, deletion=deletion
        )
        for descendent in self.graph.descendants(cell_id):
            get_context().cell_lifecycle_registry.dispose(
                descendent, deletion=deletion
            )
        RemoveUIElements(cell_id=cell_id).broadcast()

    def _deactivate_cell(self, cell_id: CellId_t) -> set[CellId_t]:
        """Deactivate: remove from graph, invalidate state, but keep metadata

        Keeps the cell's config, in case we see the same cell again.

        In contrast to deleting a cell, which fully scrubs the cell
        from the kernel and graph.
        """
        if cell_id not in self.errors:
            self._invalidate_cell_state(cell_id, deletion=True)
            return self.graph.delete_cell(cell_id)
        else:
            # An errored cell can be thought of as a cell that's in the graph
            # but that has no state in the kernel (because it was never run).
            # Its defs may overlap with defs of a non-errored cell, so we MUST
            # NOT delete/cleanup its defs from the kernel (i.e., an errored
            # cell shouldn't invalidate state of another cell).
            self.graph.delete_cell(cell_id)
            return set()

    def _delete_cell(self, cell_id: CellId_t) -> set[CellId_t]:
        """Delete a cell from the kernel and the graph.

        Deletion from the kernel involves removing cell's defs and
        de-registering its UI Elements.

        Deletion from graph is forwarded to graph object.
        """
        del self.cell_metadata[cell_id]
        cell = self.graph.cells[cell_id]
        cell.import_workspace.imported_defs = set()
        if self._should_update_script_metadata():
            self._update_script_metadata(
                import_namespaces_to_add=[],
            )

        return self._deactivate_cell(cell_id)

    def mutate_graph(
        self,
        execution_requests: Sequence[ExecutionRequest],
        deletion_requests: Sequence[DeleteCellRequest],
    ) -> set[CellId_t]:
        """Add and remove cells to/from the graph.

        This method adds the cells in `execution_requests` to the kernel's
        graph (deleting old versions of these cells, if any), and removes the
        cells in `deletion_requests` from the kernel's graph.

        The mutations that this method makes to the graph renders the
        kernel inconsistent (stale).

        This method does not register errors for cells that were previously
        valid and are not descendants of any of the newly registered cells.
        This is important for multiple definition errors, since a user may
        absent-mindedly redefine an existing name when creating a new cell:
        such a mistake shouldn't invalidate the program state.

        Returns
        - set of cells that must be run to return kernel to consistent state
        """
        LOGGER.debug("Mutating graph.")
        LOGGER.debug("Current set of errors: %s", self.errors)
        cells_before_mutation = set(self.graph.cells.keys())
        cells_with_errors_before_mutation = set(self.errors.keys())

        # The set of cells that were successfully registered
        registered_cell_ids: set[CellId_t] = set()

        # The set of cells that need to be re-run due to cells being
        # deleted/re-registered.
        cells_that_were_children_of_mutated_cells: set[CellId_t] = set()

        # Cells that were unable to be added to the graph due to syntax errors
        syntax_errors: dict[CellId_t, Error] = {}

        # Register and delete cells
        for er in execution_requests:
            old_children, error = self._maybe_register_cell(
                er.cell_id, er.code
            )
            cells_that_were_children_of_mutated_cells |= old_children
            if error is None:
                registered_cell_ids.add(er.cell_id)
            else:
                syntax_errors[er.cell_id] = error

        for dr in deletion_requests:
            if dr.cell_id not in cells_before_mutation:
                continue
            cells_that_were_children_of_mutated_cells |= self._delete_cell(
                dr.cell_id
            )
        cells_in_graph = set(self.graph.cells.keys())

        # Check for semantic errors, like multiple definition errors, cycle
        # errors, and delete nonlocal errors.
        semantic_errors = check_for_errors(self.graph)
        LOGGER.debug("After mutation, syntax errors %s", syntax_errors)
        LOGGER.debug("Semantic errors %s", semantic_errors)

        # Prune semantic errors: we won't invalidate cells that were previously
        # valid, except for cells we just tried to register
        #
        # We don't want "action at a distance": running
        # a cell shouldn't invalidate cells that were previously valid
        # and weren't requested for execution
        previously_valid_cell_ids = (
            cells_in_graph
            # cells successfully registered
            - registered_cell_ids
            # cells that already had errors
            - cells_with_errors_before_mutation
        )

        # defs that we shouldn't remove from the graph
        keep_alive_defs: set[Name] = set()
        for cid in list(semantic_errors.keys()):
            # If a cell was previously valid, don't invalidate it unless
            # we have to, ie, unless it is a descendant of a just-registered
            # cell that has an error
            #
            # Handles the introduction of a multiple definition error, eg
            #
            # cell 1: x = 0
            # cell 2 (requested for execution): x = 1
            #
            # cell 1 won't be invalidated because cell 1 was previously valid
            # and there's no path from cell 2 to cell 1
            if cid in previously_valid_cell_ids and not any(
                self.graph.get_path(other_cid, cid)
                for other_cid in registered_cell_ids
            ):
                del semantic_errors[cid]
                keep_alive_defs |= self.graph.cells[cid].defs

        all_errors = {**semantic_errors}
        for cid, error in syntax_errors.items():
            # No chance of collision because cells with syntax errors are not
            # in the graph, so can't be in semantic errors
            assert cid not in all_errors
            all_errors[cid] = (error,)

        LOGGER.debug(
            "Final set of errors, after pruning valid cells: %s", all_errors
        )
        cells_with_errors_after_mutation = set(all_errors.keys())

        # Construct sets of cells that will need to be re-run.

        # Cells that previously had errors (eg, multiple definition or cycle)
        # that no longer have errors need to be refreshed.
        cells_that_no_longer_have_errors = (
            cells_with_errors_before_mutation
            - cells_with_errors_after_mutation
        ) & cells_in_graph

        if self.reactive_execution_mode == "autorun":
            for cid in cells_that_no_longer_have_errors:
                # clear error outputs before running
                CellOp.broadcast_output(
                    channel=CellChannel.OUTPUT,
                    mimetype="text/plain",
                    data="",
                    cell_id=cid,
                    status=None,
                )

        # Cells that were successfully registered need to be run
        cells_registered_without_error = (
            registered_cell_ids - cells_with_errors_after_mutation
        )

        # Cells that didn't have errors associated with them before the
        # run request but now have errors; these cells' descendants
        # will need to be run. Handles the case where a cell was cached (cell's
        # code didn't change), so its previous children were not added to
        # cells_that_were_children_of_mutated_cells
        cells_transitioned_to_error = (
            cells_with_errors_after_mutation
            - cells_with_errors_before_mutation
        ) & cells_before_mutation

        # Invalidate state defined by error-ed cells, with the exception of
        # names that were defined by valid cells (relevant for multiple
        # definition errors)
        for cid in all_errors:
            if cid not in self.graph.cells:
                # error is a registration error
                continue
            self.graph.cells[cid].set_run_result_status("marimo-error")
            self._invalidate_cell_state(cid, exclude_defs=keep_alive_defs)

        self.errors = all_errors
        for cid in self.errors:
            cell = self.graph.cells[cid] if cid in self.graph.cells else None
            if (
                cell is not None
                and not cell.config.disabled
                and self.graph.is_disabled(cid)
            ):
                # this may be the first time we're seeing the cell: set its
                # status
                cell.set_runtime_state("disabled-transitively")

            if cell is not None:
                # The error is up-to-date, since we just processed the graph
                cell.set_stale(False)

            CellOp.broadcast_error(
                data=self.errors[cid],
                clear_console=True,
                cell_id=cid,
            )

        Variables(
            variables=[
                VariableDeclaration(
                    name=variable,
                    declared_by=list(declared_by),
                    used_by=list(
                        self.graph.get_referring_cells(
                            variable, language="python"
                        )
                    ),
                )
                for variable, declared_by in self.graph.definitions.items()
            ]
        ).broadcast()

        stale_cells = (
            set(
                itertools.chain(
                    cells_that_were_children_of_mutated_cells,
                    set().union(
                        *[
                            self.graph.children[cid]
                            for cid in cells_transitioned_to_error
                            if cid in self.graph.children
                        ]
                    )
                    - cells_with_errors_after_mutation,
                    cells_that_no_longer_have_errors,
                )
            )
            - cells_registered_without_error
        ) & cells_in_graph

        if self.reactive_execution_mode == "lazy":
            self.graph.set_stale(stale_cells, prune_imports=True)
            return cells_registered_without_error
        else:
            return cells_registered_without_error.union(stale_cells)

    async def _run_cells(self, cell_ids: set[CellId_t]) -> None:
        """Run cells and any state updates they trigger"""

        # This patch is an attempt to mitigate problems caused by the fact
        # that in run mode, kernels run in threads and share the same
        # sys.modules. Races can still happen, but this should help in most
        # common cases. We could also be more aggressive and run this before
        # every cell, or even before pickle.dump/pickle.dumps()
        with patches.patch_main_module_context(self._module):
            while cell_ids := await self._run_cells_internal(cell_ids):
                LOGGER.debug("Running state updates ...")
                if self.lazy() and cell_ids:
                    self.graph.set_stale(cell_ids, prune_imports=True)
                    break
            LOGGER.debug("Finished run.")

    async def _if_autorun_then_run_cells(
        self, cell_ids: set[CellId_t]
    ) -> None:
        if self.reactive_execution_mode == "autorun":
            await self._run_cells(cell_ids)
        else:
            # We prune imports so that only cells depending on unimported
            # modules are marked as stale
            self.graph.set_stale(cell_ids, prune_imports=True)

    def _broadcast_missing_packages(self, runner: cell_runner.Runner) -> None:
        if (
            any(
                isinstance(e, ModuleNotFoundError)
                for e in runner.exceptions.values()
            )
            and self.package_manager is not None
        ):
            missing_packages = [
                pkg
                for mod in self.module_registry.missing_modules()
                # filter out packages that we already attempted to install
                # to prevent an infinite loop
                if not self.package_manager.attempted_to_install(
                    pkg := self.package_manager.module_to_package(mod)
                )
            ]

            if missing_packages:
                if self.package_manager.should_auto_install():
                    self._execute_install_missing_packages_callback(
                        self.package_manager.name
                    )
                else:
                    MissingPackageAlert(
                        packages=list(sorted(missing_packages)),
                        isolated=is_python_isolated(),
                    ).broadcast()

    def _propagate_kernel_errors(
        self,
        runner: cell_runner.Runner,
    ) -> None:
        for cell_id, error in runner.exceptions.items():
            if isinstance(error, MarimoStrictExecutionError):
                self.errors[cell_id] = (error,)

    async def _run_cells_internal(self, roots: set[CellId_t]) -> set[CellId_t]:
        """Run cells, send outputs to frontends

        Returns set of cells that need to be re-run due to state updates.
        """

        # Some hooks that are leaky and require the kernel
        # Free cell state ahead of running to relieve memory pressure
        #
        # NB: lazy kernels don't invalidate state of cancelled cells
        # descendants (cancelled == cells that raise exceptions), whereas
        # eager kernels do (since we clear all state ahead of time, and
        # have the closure of the roots in cells to run)
        def invalidate_state(runner: cell_runner.Runner) -> None:
            for cid in runner.cells_to_run:
                self._invalidate_cell_state(cid)

        def note_time_of_interruption(
            cell_impl: CellImpl,
            runner: cell_runner.Runner,
            run_result: cell_runner.RunResult,
        ) -> None:
            del cell_impl
            del runner
            if isinstance(run_result.exception, MarimoInterrupt):
                self.last_interrupt_timestamp = time.time()

        runner = cell_runner.Runner(
            roots=roots,
            graph=self.graph,
            glbls=self.globals,
            excluded_cells=set(self.errors.keys()),
            debugger=self.debugger,
            execution_mode=self.reactive_execution_mode,
            execution_type=self.execution_type,
            execution_context=self._install_execution_context,
            preparation_hooks=self._preparation_hooks + [invalidate_state],
            pre_execution_hooks=self._pre_execution_hooks,
            post_execution_hooks=self._post_execution_hooks
            + [note_time_of_interruption],
            on_finish_hooks=(
                self._on_finish_hooks
                + [
                    self._broadcast_missing_packages,
                    self._propagate_kernel_errors,
                ]
            ),
        )

        # I/O
        #
        # TODO(akshayka): when no logger is configured, log output is not
        #                 redirected to frontend (it's printed to console),
        #                 which is incorrect
        await runner.run_all()
        cells_with_stale_state = runner.resolve_state_updates(
            self.state_updates
        )
        self.state_updates.clear()
        return cells_with_stale_state

    def register_state_update(self, state: State[Any]) -> None:
        """Register a state object as having been updated.

        Should be called when a state's setter is called.
        """
        # store the state and the currently executing cell
        assert self.execution_context is not None
        self.state_updates[state] = self.execution_context.cell_id
        # TODO(akshayka): Send VariableValues message for any globals
        # bound to this state object (just like UI elements)

    @kernel_tracer.start_as_current_span("delete_cell")
    async def delete_cell(self, request: DeleteCellRequest) -> None:
        """Delete a cell from kernel and graph."""
        cell_id = request.cell_id
        if cell_id in self.graph.cells:
            await self._run_cells(
                self.mutate_graph(
                    execution_requests=[], deletion_requests=[request]
                )
            )

    @kernel_tracer.start_as_current_span("run")
    async def run(
        self, execution_requests: Sequence[ExecutionRequest]
    ) -> None:
        """Run cells and their descendants.


        The cells may be cells already existing in the graph or new cells.
        Adds the cells in `execution_requests` to the graph before running
        them.

        Cells may use top-level await, which is why this function is async.
        """
        filtered_requests: list[ExecutionRequest] = []
        for request in execution_requests:
            if (
                self.last_interrupt_timestamp is not None
                and request.timestamp < self.last_interrupt_timestamp
            ):
                CellOp.broadcast_error(
                    data=[MarimoInterruptionError()],
                    clear_console=False,
                    cell_id=request.cell_id,
                )

                # TODO(akshayka): This hack is needed because the FE
                # sets status to queued when a cell is manually run; remove
                # once setting status to queued on receipt of request is moved
                # to backend (which will require moving execution requests to
                # a dedicated multiprocessing queue and processing execution
                # requests in a background thread).
                CellOp.broadcast_status(
                    cell_id=request.cell_id,
                    status="idle",
                )

            else:
                filtered_requests.append(request)

        await self._run_cells(
            self.mutate_graph(filtered_requests, deletion_requests=[])
        )

    @kernel_tracer.start_as_current_span("rename_file")
    async def rename_file(self, filename: str) -> None:
        self.globals["__file__"] = filename
        self.app_metadata.filename = filename
        roots = set()
        for cell in self.graph.cells.values():
            if "__file__" in cell.refs:
                roots.add(cell.cell_id)
        await self._if_autorun_then_run_cells(roots)

    @kernel_tracer.start_as_current_span("run_scratchpad")
    async def run_scratchpad(self, code: str) -> None:
        roots = {SCRATCH_CELL_ID}

        # If cannot compile, don't run
        cell, error = self._try_compiling_cell(SCRATCH_CELL_ID, code, [])
        if error:
            CellOp.broadcast_error(
                data=[error],
                clear_console=True,
                cell_id=SCRATCH_CELL_ID,
            )
            return
        elif not cell:
            return
        cell.defs.clear()  # remove definitions
        cell.refs.clear()  # remove references

        # Create graph of just the scratchpad cell
        graph = dataflow.DirectedGraph()
        graph.register_cell(SCRATCH_CELL_ID, cell)

        runner = cell_runner.Runner(
            roots=roots,
            graph=graph,
            glbls=copy(self.globals),
            excluded_cells=set(),
            debugger=self.debugger,
            execution_mode=self.reactive_execution_mode,
            execution_type=self.execution_type,
            execution_context=self._install_execution_context,
            preparation_hooks=self._preparation_hooks,
            pre_execution_hooks=self._pre_execution_hooks,
            post_execution_hooks=self._post_execution_hooks,
            on_finish_hooks=(
                self._on_finish_hooks + [self._broadcast_missing_packages]
            ),
        )

        await runner.run_all()

    @kernel_tracer.start_as_current_span("run_stale_cells")
    async def run_stale_cells(self) -> None:
        cells_to_run: set[CellId_t] = set()
        for cid, cell_impl in self.graph.cells.items():
            if cell_impl.stale and not self.graph.is_disabled(cid):
                cells_to_run.add(cid)
        await self._run_cells(
            dataflow.transitive_closure(
                self.graph,
                cells_to_run,
                relatives=dataflow.import_block_relatives,
            )
        )
        if self.module_watcher is not None:
            self.module_watcher.run_is_processed.set()

    @kernel_tracer.start_as_current_span("set_cell_config")
    async def set_cell_config(self, request: SetCellConfigRequest) -> None:
        """Update cell configs.

        Cells that are enabled (via config) but stale are run as a side-effect.
        """
        # Stale cells that are enabled will need to be run.
        stale_cells: set[CellId_t] = set()
        for cell_id, config in request.configs.items():
            # store the config, regardless of whether we've seen the cell yet
            self.cell_metadata[cell_id] = CellMetadata(
                config=CellConfig.from_dict(config)
            )
            cell = self.graph.cells.get(cell_id)
            if cell is None:
                continue
            cell.configure(config)
            if not cell.config.disabled:
                stale_cells = self.graph.enable_cell(cell_id)
            elif cell.config.disabled:
                self.graph.disable_cell(cell_id)

        if stale_cells and self.reactive_execution_mode == "autorun":
            await self._run_cells(stale_cells)

    @kernel_tracer.start_as_current_span("set_user_config")
    def set_user_config(self, request: SetUserConfigRequest) -> None:
        self._update_runtime_from_user_config(request.config)

    @kernel_tracer.start_as_current_span("set_ui_element_value")
    async def set_ui_element_value(
        self, request: SetUIElementValueRequest
    ) -> bool:
        """Set the value of a UI element bound to a global variable.

        Runs cells that reference the UI element by name.

        Returns True if any ui elements were set, False otherwise
        """
        updated_components: list[UIElement[Any, Any]] = []

        # Resolve lenses on request, if any: any element that is a view
        # of another parent element is resolved to its parent. In particular,
        # interacting with a view triggers reactive execution through the
        # source (parent).
        ctx = get_context()
        resolved_requests: dict[str, Any] = {}
        referring_cells: set[CellId_t] = set()
        ui_element_registry = ctx.ui_element_registry
        for object_id, value in request.ids_and_values:
            try:
                resolved_id, resolved_value = ui_element_registry.resolve_lens(
                    object_id, value
                )
            except (KeyError, RuntimeError):
                # Attempt to set the UI element in a child context (app).
                for child_context in ctx.children:
                    if (
                        child_context.app is not None
                        and await child_context.app.set_ui_element_value(
                            SetUIElementValueRequest(
                                object_ids=[object_id], values=[value]
                            )
                        )
                    ):
                        bindings = [
                            name
                            for name, value in self.globals.items()
                            # child_context.app is an InternalApp object
                            if value is child_context.app._app
                        ]
                        for binding in bindings:
                            referring_cells.update(
                                self.graph.get_referring_cells(
                                    binding, language="python"
                                )
                            )

                # KeyError: Trying to access an unnamed UIElement
                # RuntimeError: UIElement was deleted somehow
                LOGGER.debug(
                    "Could not resolve UIElement with id%s", object_id
                )
                continue
            resolved_requests[resolved_id] = resolved_value
        del request

        for object_id, value in resolved_requests.items():
            try:
                component = ui_element_registry.get_object(object_id)
                LOGGER.debug(
                    "Setting value on UIElement with id %s, value %s",
                    object_id,
                    value,
                )
            except KeyError:
                # KeyError: A UI element may go out of scope if it was not
                # assigned to a global variable
                LOGGER.debug("Could not find UIElement with id %s", object_id)
                continue

            with self._install_execution_context(
                ui_element_registry.get_cell(object_id),
                setting_element_value=True,
            ):
                try:
                    component._update(value)
                except MarimoConvertValueException:
                    # Internal marimo error
                    sys.stderr.write(
                        "An exception was raised when updating a UIElement's "
                        "value. This is a bug in marimo. Please copy "
                        "the below traceback and paste it in an "
                        "issue: https://github.com/marimo-team/marimo/issues\n"
                    )
                    tmpio = io.StringIO()
                    traceback.print_exc(file=tmpio)
                    tmpio.seek(0)
                    write_traceback(tmpio.read())
                    # Don't run referring elements of this UI element
                    continue
                except Exception:
                    # User's on_change handler an exception ...
                    sys.stderr.write(
                        "An exception was raised by a "
                        "UIElement's on_change handler:\n"
                    )

                    tmpio = io.StringIO()
                    traceback.print_exc(file=tmpio)
                    tmpio.seek(0)
                    write_traceback(tmpio.read())
                else:
                    updated_components.append(component)

            bound_names = (
                name
                for name in ctx.ui_element_registry.bound_names(object_id)
                if not is_local(name)
            )

            variable_values: list[VariableValue] = []
            for name in bound_names:
                # TODO update variable values even for namespaces? lenses? etc
                variable_values.append(
                    VariableValue(name=name, value=component)
                )
                try:
                    # subtracting self.graph.definitions[name]: never rerun the
                    # cell that created the name
                    referring_cells.update(
                        self.graph.get_referring_cells(name, language="python")
                        - self.graph.get_defining_cells(name)
                    )
                except Exception:
                    # Internal marimo error
                    sys.stderr.write(
                        "An exception was raised when finding cells that "
                        f"refer to a UIElement value, for bound name {name}. "
                        "This is a bug in marimo. "
                        "Please copy the below traceback and paste it in an "
                        "issue: https://github.com/marimo-team/marimo/issues\n"
                    )
                    tmpio = io.StringIO()
                    traceback.print_exc(file=tmpio)
                    tmpio.seek(0)
                    write_traceback(tmpio.read())
                    # Entering undefined behavior territory ...
                    continue

            if variable_values:
                VariableValues(variables=variable_values).broadcast()

        if self.reactive_execution_mode == "autorun":
            await self._run_cells(referring_cells)
        else:
            # Any cells referring to a UI element cannot be import cells,
            # so not necessary to specify `prune_imports`.
            self.graph.set_stale(referring_cells)
            # Process any state updates that may have been queued by the
            # on_change handlers.
            await self._run_cells(set())

        for component in updated_components:
            try:
                component._on_update_completion()
            except Exception:
                # Internal marimo error
                sys.stderr.write(
                    "An exception was raised when completing a UIElement's"
                    "update. This is a bug in marimo. "
                    "Please copy the below traceback and paste it in an "
                    "issue: https://github.com/marimo-team/marimo/issues\n"
                )
                tmpio = io.StringIO()
                traceback.print_exc(file=tmpio)
                tmpio.seek(0)
                write_traceback(tmpio.read())

        return bool(updated_components) or bool(referring_cells)

    def get_ui_initial_value(self, object_id: str) -> Any:
        """Get an initial value for a UIElement, if any

        Initial values are optionally populated during instantiation

        Args:
        ----
        object_id: ID of UIElement

        Returns:
        -------
        initial value of UI element, if any

        Raises:
        ------
        KeyError if object_id not found
        """
        return self.ui_initializers[object_id]

    def reset_ui_initializers(self) -> None:
        self.ui_initializers = {}

    @kernel_tracer.start_as_current_span("function_call_request")
    async def function_call_request(
        self, request: FunctionCallRequest
    ) -> tuple[HumanReadableStatus, JSONType, bool]:
        """Execute a function call.

        If the function is not found, children contexts are also searched.
        Returns a status, payload, and a bool which is True if the function was
        found, False otherwise.
        """
        ctx = get_context()
        function = ctx.function_registry.get_function(
            request.namespace, request.function_name
        )
        error_title, error_message = "", ""

        def debug(title: str, message: str) -> None:
            LOGGER.debug("%s: %s", title, message)

        if function is None:
            for child_context in ctx.children:
                if child_context.app is not None:
                    (
                        status,
                        response,
                        found,
                    ) = await child_context.app.function_call(request)
                    if found:
                        return status, response, found
            found = False
            error_title = "Function not found"
            error_message = (
                "Could not find function given request: %s" % request
            )
            debug(error_title, error_message)
        elif function.cell_id is None:
            found = True
            error_title = "Function not associated with cell"
            error_message = (
                "Attempted to call a function without a cell id: %s" % request
            )
            debug(error_title, error_message)
        else:
            found = True
            LOGGER.debug("Executing RPC %s", request)
            with (
                self._install_execution_context(cell_id=function.cell_id),
                ctx.provide_ui_ids(str(uuid4())),
            ):
                # Usually UI element IDs are deterministic, based on
                # cell id, so that element values can be matched up
                # with objects on notebook/app re-connection.
                #
                # We're using a non-deterministic ID prefix so that
                # UI elements created in an RPC shouldn't evict UI
                # elements associated with its owning cell. But that
                # means we won't be able to restore their values
                # on reconnection.
                #
                # TODO(akshayka): Do UI elements created in function calls
                # get cleared from the FE registry? This could be a leak.
                try:
                    response = cast(JSONType, function(request.args))
                    if asyncio.iscoroutine(response):
                        response = await response
                        return HumanReadableStatus(code="ok"), response, found
                    return (
                        HumanReadableStatus(code="ok"),
                        response,
                        found,
                    )
                except MarimoInterrupt:
                    error_title = "Interrupted"
                    error_message = (
                        "Function call (%s) was interrupted by the user"
                        % request.function_name
                    )
                    debug(error_title, error_message)
                except Exception as e:
                    error_title = "Exception"
                    error_message = (
                        "Function call (name: %s, args: %s) failed with exception %s"  # noqa: E501
                        % (request.function_name, request.args, str(e))
                    )
                    debug(error_title, error_message)

        # Couldn't call function, or function call failed
        return (
            HumanReadableStatus(
                code="error", title=error_title, message=error_message
            ),
            None,
            found,
        )

    @kernel_tracer.start_as_current_span("instantiate")
    async def instantiate(self, request: CreationRequest) -> None:
        """Instantiate the kernel with cells and UIElement initial values

        During instantiation, UIElements can check for an initial value
        with `get_initial_value`
        """
        if self.graph.cells:
            del request
            LOGGER.debug("App already instantiated.")
        else:
            self.reset_ui_initializers()
            for (
                object_id,
                initial_value,
            ) in request.set_ui_element_value_request.ids_and_values:
                self.ui_initializers[object_id] = initial_value
            await self.run(request.execution_requests)
            self.reset_ui_initializers()

    async def install_missing_packages(
        self, request: InstallMissingPackagesRequest
    ) -> None:
        """Attempts to install packages for modules that cannot be imported

        Runs cells affected by successful installation.
        """
        assert self.package_manager is not None
        if request.manager != self.package_manager.name:
            # Swap out the package manager
            self.package_manager = create_package_manager(request.manager)

        if not self.package_manager.is_manager_installed():
            self.package_manager.alert_not_installed()
            return

        # Package manager operates on module names
        missing_modules = list(sorted(self.module_registry.missing_modules()))

        # Frontend shows package names, not module names
        package_statuses: PackageStatusType = {
            self.package_manager.module_to_package(mod): "queued"
            for mod in missing_modules
        }
        InstallingPackageAlert(packages=package_statuses).broadcast()

        for mod in missing_modules:
            pkg = self.package_manager.module_to_package(mod)
            if self.package_manager.attempted_to_install(package=pkg):
                # Already attempted an installation; it must have failed.
                # Skip the installation.
                continue
            package_statuses[pkg] = "installing"
            InstallingPackageAlert(packages=package_statuses).broadcast()
            version = request.versions.get(pkg)
            if await self.package_manager.install(pkg, version=version):
                package_statuses[pkg] = "installed"
                InstallingPackageAlert(packages=package_statuses).broadcast()
            else:
                package_statuses[pkg] = "failed"
                self.module_registry.excluded_modules.add(mod)
                InstallingPackageAlert(packages=package_statuses).broadcast()

        installed_modules = [
            self.package_manager.package_to_module(pkg)
            for pkg in package_statuses
            if package_statuses[pkg] == "installed"
        ]

        # If a package was not installed at cell registration time, it won't
        # yet be in the script metadata.
        if self._should_update_script_metadata():
            self._update_script_metadata(installed_modules)

        cells_to_run = set(
            cid
            for module in installed_modules
            if (cid := self.module_registry.defining_cell(module)) is not None
        )
        if cells_to_run:
            await self._if_autorun_then_run_cells(cells_to_run)

    def _should_update_script_metadata(self) -> bool:
        return (
            GLOBAL_SETTINGS.MANAGE_SCRIPT_METADATA is True
            and self.app_metadata.filename is not None
            and self.package_manager is not None
        )

    def _update_script_metadata(
        self, import_namespaces_to_add: List[str]
    ) -> None:
        filename = self.app_metadata.filename

        if not filename or not self.package_manager:
            return

        try:
            LOGGER.debug(
                "Updating script metadata: %s. Adding namespaces: %s.",
                filename,
                import_namespaces_to_add,
            )
            self.package_manager.update_notebook_script_metadata(
                filepath=filename,
                import_namespaces_to_add=import_namespaces_to_add,
            )
        except Exception as e:
            LOGGER.error("Failed to add script metadata to notebook: %s", e)

    @kernel_tracer.start_as_current_span("preview_dataset_column")
    async def preview_dataset_column(
        self, request: PreviewDatasetColumnRequest
    ) -> None:
        """Preview a column of a dataset.

        The dataset is loaded, and the column is displayed in the frontend.
        """
        table_name = request.table_name
        column_name = request.column_name
        source_type = request.source_type

        try:
            if source_type == "duckdb":
                column_preview = get_column_preview_for_sql(
                    table_name=table_name,
                    column_name=column_name,
                )
            elif source_type == "local":
                dataset = self.globals[table_name]
                column_preview = get_column_preview_dataframe(dataset, request)
            else:
                assert_never(source_type)

            if column_preview is None:
                DataColumnPreview(
                    error=f"Column {column_name} not found",
                    column_name=column_name,
                    table_name=table_name,
                ).broadcast()
            else:
                column_preview.broadcast()
        except Exception as e:
            LOGGER.warning(
                "Failed to get preview for column %s in table %s",
                column_name,
                table_name,
                exc_info=e,
            )
            DataColumnPreview(
                error=str(e),
                column_name=column_name,
                table_name=table_name,
            ).broadcast()
        return

    async def handle_message(self, request: ControlRequest) -> None:
        """Handle a message from the client.

        The message is dispatched to the appropriate method based on its type.

        Coarsely locks globals to avoid race conditions with code completion.
        """
        # acquiring and releasing an RLock takes ~100ns; the overhead is
        # negligible because the lock is coarse.
        LOGGER.debug("Acquiring globals lock to handle request %s", request)
        with self.lock_globals():
            LOGGER.debug("Handling control request: %s", request)
            if isinstance(request, CreationRequest):
                await self.instantiate(request)
                CompletedRun().broadcast()
            elif isinstance(request, ExecuteMultipleRequest):
                await self.run(request.execution_requests)
                CompletedRun().broadcast()
            elif isinstance(request, ExecuteScratchpadRequest):
                await self.run_scratchpad(request.code)
            elif isinstance(request, ExecuteStaleRequest):
                await self.run_stale_cells()
            elif isinstance(request, RenameRequest):
                await self.rename_file(request.filename)
            elif isinstance(request, SetCellConfigRequest):
                await self.set_cell_config(request)
            elif isinstance(request, SetUserConfigRequest):
                self.set_user_config(request)
            elif isinstance(request, SetUIElementValueRequest):
                await self.set_ui_element_value(request)
                CompletedRun().broadcast()
            elif isinstance(request, FunctionCallRequest):
                status, ret, _ = await self.function_call_request(request)
                LOGGER.debug("Function returned with status %s", status)
                FunctionCallResult(
                    function_call_id=request.function_call_id,
                    return_value=ret,
                    status=status,
                ).broadcast()
                CompletedRun().broadcast()
            elif isinstance(request, DeleteCellRequest):
                await self.delete_cell(request)
            elif isinstance(request, InstallMissingPackagesRequest):
                await self.install_missing_packages(request)
                CompletedRun().broadcast()
            elif isinstance(request, PreviewDatasetColumnRequest):
                await self.preview_dataset_column(request)
            elif isinstance(request, StopRequest):
                return None
            else:
                raise ValueError(f"Unknown request {request}")
            LOGGER.debug("Handled control request: %s", request)

#+END_SRC
** Function launch_kernel
#+BEGIN_SRC python
def launch_kernel(
    control_queue: QueueType[ControlRequest],
    set_ui_element_queue: QueueType[SetUIElementValueRequest],
    completion_queue: QueueType[CodeCompletionRequest],
    input_queue: QueueType[str],
    stream_queue: queue.Queue[KernelMessage] | None,
    socket_addr: tuple[str, int] | None,
    is_edit_mode: bool,
    configs: dict[CellId_t, CellConfig],
    app_metadata: AppMetadata,
    user_config: MarimoConfig,
    virtual_files_supported: bool,
    redirect_console_to_browser: bool,
    interrupt_queue: QueueType[bool] | None = None,
    profile_path: Optional[str] = None,
    log_level: int | None = None,
) -> None:
    if log_level is not None:
        _loggers.set_level(log_level)
    LOGGER.debug("Launching kernel")
    if is_edit_mode:
        restore_signals()

    profiler = None
    if profile_path is not None:
        import cProfile

        profiler = cProfile.Profile()
        profiler.enable()

    # Create communication channels
    if socket_addr is not None:
        n_tries = 0
        pipe: Optional[TypedConnection[KernelMessage]] = None
        while n_tries < 100:
            try:
                pipe = TypedConnection[KernelMessage].of(
                    connection.Client(socket_addr)
                )
                break
            except Exception:
                n_tries += 1
                time.sleep(0.01)

        if n_tries == 100 or pipe is None:
            LOGGER.debug("Failed to connect to socket.")
            return

        stream = ThreadSafeStream(pipe=pipe, input_queue=input_queue)
    elif stream_queue is not None:
        stream = ThreadSafeStream(
            pipe=QueuePipe(stream_queue), input_queue=input_queue
        )
    else:
        raise RuntimeError(
            "One of queue_pipe and socket_addr must be non None"
        )
    # Console output is hidden in run mode, so no need to redirect
    # (redirection of console outputs is not thread-safe anyway)
    stdout = (
        ThreadSafeStdout(stream)
        if is_edit_mode or redirect_console_to_browser
        else None
    )
    stderr = (
        ThreadSafeStderr(stream)
        if is_edit_mode or redirect_console_to_browser
        else None
    )
    # TODO(akshayka): stdin in run mode? input(prompt) uses stdout, which
    # isn't currently available in run mode.
    stdin = ThreadSafeStdin(stream) if is_edit_mode else None
    debugger = (
        marimo_pdb.MarimoPdb(stdout=stdout, stdin=stdin)
        if is_edit_mode
        else None
    )

    # In run mode, the kernel should always be in autorun
    if not is_edit_mode:
        user_config = user_config.copy()
        user_config["runtime"]["on_cell_change"] = "autorun"

    def _enqueue_control_request(req: ControlRequest) -> None:
        control_queue.put_nowait(req)
        if isinstance(req, SetUIElementValueRequest):
            set_ui_element_queue.put_nowait(req)

    kernel = Kernel(
        cell_configs=configs,
        app_metadata=app_metadata,
        stream=stream,
        stdout=stdout,
        stderr=stderr,
        stdin=stdin,
        module=patches.patch_main_module(
            file=app_metadata.filename, input_override=input_override
        ),
        debugger_override=debugger,
        user_config=user_config,
        enqueue_control_request=_enqueue_control_request,
    )
    initialize_kernel_context(
        kernel=kernel,
        stream=stream,
        stdout=stdout,
        stderr=stderr,
        virtual_files_supported=virtual_files_supported,
        mode=SessionMode.EDIT if is_edit_mode else SessionMode.RUN,
    )

    if is_edit_mode:
        # completions only provided in edit mode
        kernel.start_completion_worker(completion_queue)

        # In edit mode, kernel runs in its own process so it's interruptible.
        from marimo._output.formatters.formatters import register_formatters

        # TODO: Windows workaround -- find a way to make the process
        # its group leader
        if sys.platform != "win32":
            # Make this process group leader to prevent it from receiving
            # signals intended for the parent (server) process,
            # Ctrl+C in particular.
            os.setsid()

        # kernels are processes in edit mode, and each process needs to
        # install the formatter import hooks
        register_formatters(theme=user_config["display"]["theme"])

        signal.signal(
            signal.SIGINT, handlers.construct_interrupt_handler(kernel)
        )

        if sys.platform == "win32":
            if interrupt_queue is not None:
                Win32InterruptHandler(interrupt_queue).start()
            # windows doesn't handle SIGTERM
            signal.signal(
                signal.SIGBREAK, handlers.construct_sigterm_handler(kernel)
            )
        else:
            signal.signal(
                signal.SIGTERM, handlers.construct_sigterm_handler(kernel)
            )

    ui_element_request_mgr = SetUIElementRequestManager(set_ui_element_queue)

    async def control_loop() -> None:
        while True:
            try:
                request: ControlRequest | None = control_queue.get()
            except Exception as e:
                # triggered on Windows when quit with Ctrl+C
                LOGGER.debug("kernel queue.get() failed %s", e)
                break
            LOGGER.debug("Received control request: %s", request)
            if isinstance(request, StopRequest):
                break
            elif isinstance(request, SetUIElementValueRequest):
                request = ui_element_request_mgr.process_request(request)

            if request is not None:
                await kernel.handle_message(request)

    # The control loop is asynchronous only because we allow user code to use
    # top-level await; nothing else is awaited. Don't introduce async
    # primitives anywhere else in the runtime unless there is a *very* good
    # reason; prefer using threads (for performance and clarity).
    asyncio.run(control_loop())

    if stdout is not None:
        stdout._watcher.stop()
    if stderr is not None:
        stderr._watcher.stop()
    get_context().virtual_file_registry.shutdown()

    if profiler is not None and profile_path is not None:
        profiler.disable()
        profiler.dump_stats(profile_path)

#+END_SRC
* scratch
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.scratch
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/scratch.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from marimo._ast.cell import CellId_t

#+END_SRC
** Assignment SCRATCH_CELL_ID: CellId_t = "__scratch__"
#+BEGIN_SRC python
SCRATCH_CELL_ID: CellId_t = "__scratch__"

#+END_SRC
* state
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.state
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/state.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import types
import weakref
from dataclasses import dataclass
from typing import Any, Callable, Generic, Optional, TypeVar
from uuid import uuid4

from marimo._output.rich_help import mddoc
from marimo._runtime.context import ContextNotInitializedError, get_context

#+END_SRC
** Assignment T = TypeVar("T")
#+BEGIN_SRC python
T = TypeVar("T")

#+END_SRC
** Assignment Id = int
#+BEGIN_SRC python
Id = int

#+END_SRC
** @dataclass: Class StateItem
#+BEGIN_SRC python
@dataclass
class StateItem(Generic[T]):
    id: Id
    ref: weakref.ref[State[T]]

#+END_SRC
** Function extract_name
#+BEGIN_SRC python
def extract_name(key: str) -> str:
    # Some variables may use a state internally, as such the lookup needs a
    # context qualifier. We delimit the context and name with a colon, which is
    # not a valid python variable name character.
    return key.split(":")[-1]

#+END_SRC
** Class StateRegistry
#+BEGIN_SRC python
class StateRegistry:
    def __init__(self) -> None:
        # variable name -> state
        # State registry is pruned based on the variable definitions in scope.
        self._states: dict[str, StateItem[Any]] = {}
        # id -> variable name for state
        # NB. python reuses IDs, but an active pruning of the registry should
        # help protect against this.
        self._inv_states: dict[Id, set[str]] = {}

    def register(
        self,
        state: State[T],
        name: Optional[str] = None,
        context: Optional[str] = None,
    ) -> None:
        if name is None:
            name = str(uuid4())
        if context is not None:
            name = f"{context}:{name}"

        if id(state) in self._inv_states:
            ref = next(iter(self._inv_states[id(state)]))
            # Check for duplicate state ids and clean up accordingly
            if ref not in self._states or id(self._states[ref].ref()) != id(
                state
            ):
                for ref in self._inv_states[id(state)]:
                    self._states.pop(ref, None)
                self._inv_states[id(state)].clear()
        state_item = StateItem(id(state), weakref.ref(state))
        self._states[name] = state_item
        id_to_ref = self._inv_states.get(id(state), set())
        id_to_ref.add(name)
        self._inv_states[id(state)] = id_to_ref
        finalizer = weakref.finalize(state, self._delete, name, state_item)
        # No need to clean up the registry at program teardown
        finalizer.atexit = False

    def register_scope(
        self, glbls: dict[str, Any], defs: Optional[set[str]] = None
    ) -> None:
        """Finds instances of state and scope, and adds them to registry if not
        already present."""
        if defs is None:
            defs = set(glbls.keys())
        for variable in defs:
            lookup = glbls.get(variable, None)
            if isinstance(lookup, State):
                self.register(lookup, variable)

    def _delete(self, name: str, state_item: StateItem[T]) -> None:
        self._states.pop(name, None)
        self._inv_states.pop(state_item.id, None)

    def retain_active_states(self, active_variables: set[str]) -> None:
        """Retains only the active states in the registry."""
        # Remove all non-active states by name
        active_state_ids = set()
        for state_key in list(self._states.keys()):
            if extract_name(state_key) not in active_variables:
                id_key = id(self._states[state_key])
                lookup = self._inv_states.get(id_key, None)
                if lookup is not None:
                    if state_key in lookup:
                        lookup.remove(state_key)
                    if not lookup:
                        del self._inv_states[id_key]
                del self._states[state_key]
            else:
                active_state_ids.add(id(self._states[state_key]))

        # Remove all non-active states by id
        for state_id in list(self._inv_states.keys()):
            if state_id not in active_state_ids:
                del self._inv_states[state_id]

    def lookup(
        self, name: str, context: Optional[str] = None
    ) -> Optional[State[T]]:
        if context is not None:
            name = f"{context}:{name}"
        if name in self._states:
            return self._states[name].ref()
        return None

    def bound_names(self, state: State[T]) -> set[str]:
        if id(state) in self._inv_states:
            return self._inv_states[id(state)]
        return set()

#+END_SRC
** Class State
#+BEGIN_SRC python
class State(Generic[T]):
    """Mutable reactive state"""

    def __init__(
        self,
        value: T,
        allow_self_loops: bool = False,
        _registry: Optional[StateRegistry] = None,
        _name: Optional[str] = None,
        _context: Optional[str] = None,
    ) -> None:
        self._value = value
        self.allow_self_loops = allow_self_loops
        self._set_value = SetFunctor(self)

        try:
            if _registry is None:
                _registry = get_context().state_registry
            _registry.register(self, _name, _context)
        except ContextNotInitializedError:
            # Registration may be picked up later, but there is nothing to do
            # at this point.
            pass

    def __call__(self) -> T:
        return self._value

#+END_SRC
** Class SetFunctor
#+BEGIN_SRC python
class SetFunctor(Generic[T]):
    """Typed function tied to a state instance"""

    def __init__(self, state: State[T]):
        self._state = state

    def __call__(self, update: T | Callable[[T], T]) -> None:
        self._state._value = (
            update(self._state._value)
            if isinstance(update, (types.MethodType, types.FunctionType))
            else update
        )
        try:
            ctx = get_context()
        except ContextNotInitializedError:
            return
        ctx.register_state_update(self._state)

#+END_SRC
** @mddoc: Function state
#+BEGIN_SRC python
@mddoc
def state(
    value: T, allow_self_loops: bool = False
) -> tuple[State[T], Callable[[T], None]]:
    """Mutable reactive state

    This function takes an initial value and returns:

    - a getter function that reads the state value
    - a setter function to set the state's value

    When you call the setter function and update the state value in one cell,
    all *other* cells that read any global variables assigned to the getter
    will automatically run. By default, the cell that called the setter
    function won't be re-run, even if it references the getter; to allow a
    state setter to possibly run the caller cell, use the keyword argument
    `allow_self_loops=True`.

    You can use this function in conjunction with `UIElement` `on_change`
    handlers to trigger side-effects when an element's value is updated. For
    example, you can tie multiple UI elements to derive their values from
    shared state.

    **Basic Usage.**


    Create state:

    ```python
    get_count, set_count = mo.state(0)
    ```

    Read the value:

    ```python
    get_count()
    ```

    Update the state:

    ```
    set_count(1)
    ```

    Update the state based on the current value:

    ```
    set_count(lambda value: value + 1)
    ```

    *Note: Never mutate the state directly. You should only change its
    value through its setter.*

    **Synchronizing multiple UI elements.**

    ```python
    get_state, set_state = mo.state(0)
    ```

    ```python
    # updating the state through the slider will recreate the number (below)
    slider = mo.ui.slider(0, 100, value=get_state(), on_change=set_state)
    ```

    ```python
    # updating the state through the number will recreate the slider (above)
    number = mo.ui.number(0, 100, value=get_state(), on_change=set_state)
    ```

    ```python
    # slider and number are synchronized to have the same value (try it!)
    [slider, number]
    ```

    **Warning.** Do not store `marimo.ui` elements in state; doing so can
    lead to hard-to-diagnose bugs.

    **Args**:

    - `value`: initial value of the state
    - `allow_self_loops`: if True, if a cell calls a state setter
      and also references its getter, the caller cell will be re-run;
      defaults to `False`.



    **Returns**:

    - getter function that retrieves the state value
    - setter function that takes a new value, or a function taking the current
      value as its argument and returning a new value
    """
    state_instance = State(value, allow_self_loops=allow_self_loops)
    return state_instance, state_instance._set_value

#+END_SRC
* threads
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.threads
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/threads.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import threading
from typing import Any

from marimo._runtime.context.types import (
    RuntimeContext,
    get_context,
    initialize_context,
    runtime_context_installed,
)

#+END_SRC
** Class Thread
#+BEGIN_SRC python
class Thread(threading.Thread):
    """A Thread subclass that is aware of marimo internals.

    `mo.Thread` has the same API as threading.Thread,
    but `mo.Thread`s are able to communicate with the marimo
    frontend, whereas `threading.Thread` can't.
    """

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        super().__init__(*args, **kwargs)

        self._marimo_ctx: RuntimeContext | None = None

        if runtime_context_installed():
            self._marimo_ctx = get_context()

    def run(self) -> None:
        if self._marimo_ctx is not None:
            initialize_context(self._marimo_ctx)
        super().run()

#+END_SRC
* validate_graph
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.validate_graph
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/validate_graph.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import itertools
from collections import defaultdict

from marimo._ast.cell import CellId_t
from marimo._messaging.errors import (
    CycleError,
    DeleteNonlocalError,
    Error,
    MultipleDefinitionError,
)
from marimo._runtime.dataflow import DirectedGraph

#+END_SRC
** Function check_for_multiple_definitions
#+BEGIN_SRC python
def check_for_multiple_definitions(
    graph: DirectedGraph,
) -> dict[CellId_t, list[MultipleDefinitionError]]:
    """Check whether multiple cells define the same global name."""
    errors = defaultdict(list)
    defs = sorted(
        list(set().union(*(cell.defs for _, cell in graph.cells.items())))
    )
    for name in defs:
        defining_cells = graph.definitions[name]
        if len(defining_cells) > 1:
            for cid in defining_cells:
                errors[cid].append(
                    MultipleDefinitionError(
                        name=str(name),
                        cells=tuple(sorted(defining_cells - set([cid]))),
                    )
                )
    return errors

#+END_SRC
** Function check_for_delete_nonlocal
#+BEGIN_SRC python
def check_for_delete_nonlocal(
    graph: DirectedGraph,
) -> dict[CellId_t, list[DeleteNonlocalError]]:
    """Check whether cells delete their refs."""
    errors = defaultdict(list)
    for cid in graph.cells.keys():
        for name in graph.cells[cid].deleted_refs:
            if name in graph.definitions:
                errors[cid].append(
                    DeleteNonlocalError(
                        name=str(name),
                        cells=tuple(graph.definitions[name]),
                    )
                )
    return errors

#+END_SRC
** Function check_for_cycles
#+BEGIN_SRC python
def check_for_cycles(graph: DirectedGraph) -> dict[CellId_t, list[CycleError]]:
    """Return cycle errors, if any."""
    errors = defaultdict(list)
    for cycle in graph.cycles:
        nodes_in_cycle: set[CellId_t] = set(sum(cycle, ()))
        # before reporting the cells in the cycle to the user,
        # we first annotate the cycle with the variable names
        # that link its cells
        cycle_with_vars = tuple(
            (
                edge[0],
                sorted(graph.cells[edge[0]].defs & graph.cells[edge[1]].refs),
                edge[1],
            )
            for edge in cycle
        )
        for cid in nodes_in_cycle:
            errors[cid].append(CycleError(edges_with_vars=cycle_with_vars))
    return errors

#+END_SRC
** Function check_for_errors
#+BEGIN_SRC python
def check_for_errors(
    graph: DirectedGraph,
) -> dict[CellId_t, tuple[Error, ...]]:
    """
    Check graph for violations of marimo semantics.

    Return a dict of errors in the graph, with an entry for each cell
    that is involved in an error.
    """
    multiple_definition_errors = check_for_multiple_definitions(graph)
    delete_nonlocal_errors = check_for_delete_nonlocal(graph)
    cycle_errors = check_for_cycles(graph)

    errors: dict[CellId_t, tuple[Error, ...]] = {}
    for cid in set(
        itertools.chain(
            multiple_definition_errors.keys(),
            delete_nonlocal_errors.keys(),
            cycle_errors.keys(),
        )
    ):
        errors[cid] = tuple(
            itertools.chain(
                multiple_definition_errors[cid],
                cycle_errors[cid],
                delete_nonlocal_errors[cid],
            )
        )
    return errors

#+END_SRC
* virtual_file
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.virtual_file
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/virtual_file.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import base64
import dataclasses
import mimetypes
import random
import string
import sys
import threading
from typing import TYPE_CHECKING, Optional, cast

from marimo import _loggers
from marimo._messaging.mimetypes import KnownMimeType
from marimo._output.utils import build_data_url
from marimo._runtime.cell_lifecycle_item import CellLifecycleItem
from marimo._runtime.context import ContextNotInitializedError
from marimo._server.api.status import HTTPException, HTTPStatus
from marimo._utils.platform import is_pyodide

#+END_SRC
** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
if TYPE_CHECKING:
    from collections.abc import Iterable

    from marimo._runtime.context.types import RuntimeContext

LOGGER = _loggers.marimo_logger()

#+END_SRC
** Assignment _ALPHABET = string.ascii_letters + string.digits
#+BEGIN_SRC python
if not is_pyodide():
    # the shared_memory module is not supported in the Pyodide distribution
    from multiprocessing import shared_memory


_ALPHABET = string.ascii_letters + string.digits

#+END_SRC
** Function random_filename
#+BEGIN_SRC python
def random_filename(ext: str) -> str:
    # adapted from: https://stackoverflow.com/questions/13484726/safe-enough-8-character-short-unique-random-string  # noqa: E501
    # TODO(akshayka): should callers redraw if they get a collision?
    try:
        tid = str(threading.get_native_id())
    except AttributeError:
        # get_native_id() not implemented in pyodide/WASM
        tid = "0"
    basename = tid + "-" + "".join(random.choices(_ALPHABET, k=8))
    return f"{basename}.{ext}"

#+END_SRC
** @dataclasses.dataclass: Class VirtualFile
#+BEGIN_SRC python
@dataclasses.dataclass
class VirtualFile:
    url: str
    filename: str
    buffer: bytes

    def __init__(
        self,
        filename: str,
        buffer: bytes,
        url: Optional[str] = None,
        as_data_url: bool = False,
    ) -> None:
        self.filename = filename
        self.buffer = buffer
        # Create a file URL with the buffer size
        # This is a hack so when we pull from shared memory we know how
        # many bytes to read.
        # Also, URL is intentionally relative, so it can be resolved with
        # different base URLs.
        if not as_data_url:
            self.url = url or f"./@file/{len(buffer)}-{filename}"
        else:
            mimetype = mimetypes.guess_type(self.filename)[0] or "text/plain"
            self.url = url or build_data_url(
                mimetype=cast(KnownMimeType, mimetype),
                data=base64.b64encode(buffer),
            )

    @staticmethod
    def from_external_url(url: str) -> VirtualFile:
        return VirtualFile(
            filename=url,
            buffer=b"",
            url=url,
        )

#+END_SRC
** Assignment EMPTY_VIRTUAL_FILE
#+BEGIN_SRC python
EMPTY_VIRTUAL_FILE = VirtualFile(
    filename="empty.txt",
    # URL is intentionally relative, so it can be resolved with
    # different base URLs.
    url="@file/0-empty.txt",
    buffer=b"",
)

#+END_SRC
** Class VirtualFileLifecycleItem
#+BEGIN_SRC python
class VirtualFileLifecycleItem(CellLifecycleItem):
    def __init__(self, ext: str, buffer: bytes) -> None:
        self.ext = _without_leading_dot(ext)
        self.buffer = buffer
        # Not resolved until added to registry
        self._virtual_file: Optional[VirtualFile] = None

    def add_to_cell_lifecycle_registry(self) -> None:
        from marimo._runtime.context import get_context

        try:
            ctx = get_context()
        except ContextNotInitializedError:
            ctx = None

        if ctx is not None:
            ctx.cell_lifecycle_registry.add(self)
        else:
            self.create(context=None)

    @property
    def virtual_file(self) -> VirtualFile:
        assert self._virtual_file is not None
        return self._virtual_file

    def create(self, context: "RuntimeContext" | None) -> None:
        """Create the virtual file

        Every virtual file gets a unique random name. Uniqueness is
        required for reference counting.
        """
        filename = random_filename(self.ext)
        if context is None or not context.virtual_files_supported:
            self._virtual_file = VirtualFile(
                filename=filename, buffer=self.buffer, as_data_url=True
            )
            return

        registry = context.virtual_file_registry
        # create a unique filename for the virtual file
        tries = 0
        max_tries = 100
        while registry.has(filename) and tries < max_tries:
            filename = random_filename(self.ext)
            tries += 1
        if tries > max_tries:
            raise RuntimeError(
                "Failed to add virtual file to registry. "
                "This is a bug in marimo. Please file an issue."
            )
        self._virtual_file = VirtualFile(filename, self.buffer)
        context.virtual_file_registry.add(self._virtual_file, context)

    def dispose(self, context: "RuntimeContext", deletion: bool) -> bool:
        # Remove the file if the refcount is 0, or if the cell is being
        # deleted. (We can't rely on when the refcount will be decremented, so
        # we need to check for deletion explicitly to prevent leaks.)
        if deletion or (
            context.virtual_file_registry.refcount(self.virtual_file.filename)
            <= 0
        ):
            context.virtual_file_registry.remove(self.virtual_file)
            return True
        # refcount > 0, so need to keep this disposal hook around
        return False

#+END_SRC
** @dataclasses.dataclass: Class VirtualFileRegistryItem
#+BEGIN_SRC python
@dataclasses.dataclass
class VirtualFileRegistryItem:
    # contents of the file
    shm: shared_memory.SharedMemory
    # number of HTML objects that are referencing this virtual file
    refcount: int

#+END_SRC
** @dataclasses.dataclass: Class VirtualFileRegistry
#+BEGIN_SRC python
@dataclasses.dataclass
class VirtualFileRegistry:
    """Registry of virtual files

    The registry maps virtual file filenames to their contents. Each
    registry item is reference counted: refcount > 0 means that an object
    exists somewhere that uses the virtual file.

    The registry itself doesn't maintain the reference counts, it only
    exposes methods for incrementing, decrementing, and getting the counts.
    """

    registry: dict[str, VirtualFileRegistryItem] = dataclasses.field(
        default_factory=dict
    )
    shutting_down = False

    def __del__(self) -> None:
        self.shutdown()

    def has(self, filename: str) -> bool:
        return filename in self.registry

    def filenames(self) -> Iterable[str]:
        return self.registry.keys()

    def reference(self, filename: str) -> None:
        """Increment the reference count"""
        if filename in self.registry:
            self.registry[filename].refcount += 1

    def dereference(self, filename: str) -> None:
        """Decrement the reference count"""
        if filename in self.registry:
            self.registry[filename].refcount -= 1

    def refcount(self, filename: str) -> int:
        """Get the reference count"""
        if filename in self.registry:
            return self.registry[filename].refcount
        return 0

    def add(
        self, virtual_file: VirtualFile, context: "RuntimeContext"
    ) -> None:
        if not context.virtual_files_supported:
            return

        key = virtual_file.filename
        if key in self.registry:
            LOGGER.debug(
                "Virtual file (key=%s) already registered", virtual_file
            )
            return

        buffer = virtual_file.buffer
        # Immediately writes the contents of the file to an in-memory
        # buffer; not lazy.
        #
        # To retrieve the buffer from another process, use:
        #
        # ```
        # try:
        #   shm = shared_memory.SharedMemory(name=key)
        #   buffer_contents = bytes(shm.buf)
        # except FileNotFoundError:
        #   # virtual file was removed
        # ```
        shm = shared_memory.SharedMemory(
            name=key,
            create=True,
            size=len(buffer),
        )
        shm.buf[: len(buffer)] = buffer
        # we can safely close this shm, since we don't need to access its
        # buffer; we do need to keep it around so we can unlink it later
        if sys.platform != "win32":
            # don't call close() on Windows, due to a bug in the Windows
            # Python implementation. On Windows, close() actually unlinks
            # (destroys) the shared_memory:
            # https://stackoverflow.com/questions/63713241/segmentation-fault-using-python-shared-memory/63717188#63717188
            shm.close()
        # We have to keep a reference to the shared memory to prevent it from
        # being destroyed on Windows
        self.registry[key] = VirtualFileRegistryItem(shm=shm, refcount=0)

    def remove(self, virtual_file: VirtualFile) -> None:
        key = virtual_file.filename
        if key in self.registry:
            if sys.platform == "win32":
                self.registry[key].shm.close()
            # destroy the shared memory
            self.registry[key].shm.unlink()
            del self.registry[key]

    def shutdown(self) -> None:
        # Try to make this method re-entrant since it's called in the
        # sigterm handler
        #
        # https://www.gnu.org/software/libc/manual/html_node/Nonreentrancy.html
        if self.shutting_down:
            return
        try:
            self.shutting_down = True
            for _, item in self.registry.items():
                if sys.platform == "win32":
                    item.shm.close()
                item.shm.unlink()
            self.registry.clear()
        finally:
            self.shutting_down = False

#+END_SRC
** Function _without_leading_dot
#+BEGIN_SRC python
def _without_leading_dot(ext: str) -> str:
    return ext[1:] if ext.startswith(".") else ext

#+END_SRC
** Function read_virtual_file
#+BEGIN_SRC python
def read_virtual_file(filename: str, byte_length: int) -> bytes:
    if not shared_memory:
        raise RuntimeError("Shared memory is not supported on this platform")

    key = filename
    shm = None
    try:
        # NB: this can't be collapsed into a one-liner!
        # doing it in one line yields a 'released memoryview ...'
        # because shared_memory has built in ref-tracking + GC
        shm = shared_memory.SharedMemory(name=key)
        buffer_contents = bytes(shm.buf)[: int(byte_length)]
    except FileNotFoundError as err:
        LOGGER.debug(
            "Error retrieving shared memory for virtual file: %s", err
        )
        raise HTTPException(
            HTTPStatus.NOT_FOUND,
            detail="File not found",
        ) from err
    finally:
        if shm is not None:
            shm.close()

    return buffer_contents

#+END_SRC
* win32_interrupt_handler
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.win32_interrupt_handler
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/win32_interrupt_handler.py
:END:
** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
import queue
import signal
import threading
from _thread import interrupt_main
from typing import TYPE_CHECKING

#+END_SRC
** Class Win32InterruptHandler
#+BEGIN_SRC python
if TYPE_CHECKING:
    from multiprocessing import Queue


class Win32InterruptHandler(threading.Thread):
    def __init__(self, interrupt_queue: "Queue[bool]") -> None:
        super(Win32InterruptHandler, self).__init__()
        self.daemon = True
        self.interrupt_queue = interrupt_queue

    def run(self) -> None:
        while True:
            self.interrupt_queue.get()
            try:
                while self.interrupt_queue.get_nowait():
                    pass
            except queue.Empty:
                pass
            if callable(signal.getsignal(signal.SIGINT)):
                interrupt_main()

#+END_SRC
* app
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.app
:END:
** common
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.app.common
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/app/common.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import Any, Dict, Tuple

from marimo._ast.cell import CellId_t

#+END_SRC
*** Assignment OutputsType = Dict[CellId_t, Any]
#+BEGIN_SRC python
OutputsType = Dict[CellId_t, Any]

#+END_SRC
*** Assignment DefsType = Dict[str, Any]
#+BEGIN_SRC python
DefsType = Dict[str, Any]

#+END_SRC
*** Assignment RunOutput = Tuple[OutputsType, DefsType]
#+BEGIN_SRC python
RunOutput = Tuple[OutputsType, DefsType]

#+END_SRC
** kernel_runner
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.app.kernel_runner
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/app/kernel_runner.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import weakref
from typing import TYPE_CHECKING, Any

from marimo._ast.cell import CellId_t, CellImpl
from marimo._config.config import DEFAULT_CONFIG
from marimo._runtime.app.common import RunOutput
from marimo._runtime.context.types import get_context
from marimo._runtime.patches import create_main_module
from marimo._runtime.requests import (
    AppMetadata,
    ExecutionRequest,
    FunctionCallRequest,
    SetUIElementValueRequest,
)
from marimo._runtime.runner import cell_runner

#+END_SRC
*** Class AppKernelRunner
#+BEGIN_SRC python
if TYPE_CHECKING:
    from marimo._ast.app import InternalApp
    from marimo._messaging.ops import HumanReadableStatus
    from marimo._plugins.core.web_component import JSONType


class AppKernelRunner:
    """Runs an app in a kernel context; used for composition."""

    def __init__(self, app: InternalApp) -> None:
        from marimo._runtime.context.kernel_context import (
            KernelRuntimeContext,
            create_kernel_context,
        )
        from marimo._runtime.runner.hooks_post_execution import (
            _reset_matplotlib_context,
        )
        from marimo._runtime.runtime import Kernel

        self.app = app
        self._outputs: dict[str, Any] = {}

        ctx = get_context()
        if not isinstance(ctx, KernelRuntimeContext):
            raise RuntimeError("AppKernelRunner requires a kernel context.")

        def cache_output(
            cell: CellImpl,
            runner: cell_runner.Runner,
            run_result: cell_runner.RunResult,
        ) -> None:
            """Update the app's cached outputs."""
            from marimo._plugins.stateless.flex import vstack

            del runner
            if (
                run_result.output is None
                and run_result.accumulated_output is not None
            ):
                self.outputs[cell.cell_id] = vstack(
                    run_result.accumulated_output
                )
            else:
                self.outputs[cell.cell_id] = run_result.output

        filename = "<unknown>"
        self._kernel = Kernel(
            cell_configs={},
            app_metadata=AppMetadata({}, {}, filename),
            stream=ctx.stream,
            stdout=None,
            stderr=None,
            stdin=None,
            module=create_main_module(filename, None),
            user_config=DEFAULT_CONFIG,
            enqueue_control_request=lambda _: None,
            post_execution_hooks=[cache_output, _reset_matplotlib_context],
        )

        # We push a new runtime context onto the "stack", corresponding to this
        # app. The context is removed when the app object is destroyed.
        self._runtime_context = create_kernel_context(
            kernel=self._kernel,
            app=app,
            stream=ctx.stream,
            stdout=None,
            stderr=None,
            virtual_files_supported=True,
            parent=ctx,
        )
        ctx.add_child(self._runtime_context)
        finalizer = weakref.finalize(
            self, ctx.remove_child, self._runtime_context
        )
        finalizer.atexit = False

        # Register cells through the kernel runner, so that compilation only
        # occurs once.
        for cell_id, cell in app.cell_manager.valid_cells():
            self._kernel._register_cell(cell_id, cell._cell)

    @property
    def outputs(self) -> dict[CellId_t, Any]:
        return self._outputs

    @property
    def globals(self) -> dict[CellId_t, Any]:
        return self._kernel.globals

    async def run(self, cells_to_run: set[CellId_t]) -> RunOutput:
        execution_requests = [
            ExecutionRequest(cell_id=cid, code=cell._cell.code)
            for cid in cells_to_run
            if (cell := self.app.cell_manager.cell_data_at(cid).cell)
            is not None
        ]

        with self._runtime_context.install():
            await self._kernel.run(execution_requests)
        return self.outputs, self._kernel.globals

    async def set_ui_element_value(
        self, request: SetUIElementValueRequest
    ) -> bool:
        with self._runtime_context.install():
            return await self._kernel.set_ui_element_value(request)

    async def function_call(
        self, request: FunctionCallRequest
    ) -> tuple[HumanReadableStatus, JSONType, bool]:
        with self._runtime_context.install():
            return await self._kernel.function_call_request(request)

#+END_SRC
** script_runner
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.app.script_runner
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/app/script_runner.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import asyncio
from typing import TYPE_CHECKING, Any, Callable, Iterator

from marimo._ast.cell import CellId_t, CellImpl
from marimo._dependencies.dependencies import DependencyManager
from marimo._messaging.types import NoopStream
from marimo._runtime.app.common import RunOutput
from marimo._runtime.context.types import (
    get_context,
    runtime_context_installed,
    teardown_context,
)
from marimo._runtime.executor import (
    MarimoMissingRefError,
    MarimoRuntimeException,
    execute_cell,
    execute_cell_async,
)
from marimo._runtime.patches import (
    create_main_module,
    patch_main_module_context,
)

#+END_SRC
*** Class AppScriptRunner
#+BEGIN_SRC python
if TYPE_CHECKING:
    from marimo._ast.app import InternalApp


class AppScriptRunner:
    """Runs an app in a script context."""

    def __init__(self, app: InternalApp, filename: str | None) -> None:
        self.app = app
        self.filename = filename

    def run(self) -> RunOutput:
        from marimo._runtime.context.script_context import (
            initialize_script_context,
        )

        app = self.app

        is_async = False
        for cell in app.cell_manager.cells():
            if cell is None:
                raise RuntimeError(
                    "Unparsable cell encountered. This is a bug in marimo, "
                    "please raise an issue."
                )

            if cell._is_coroutine():
                is_async = True
                break

        installed_script_context = False
        try:
            if not runtime_context_installed():
                # script context is ephemeral, only installed while the app is
                # running
                initialize_script_context(
                    app=app, stream=NoopStream(), filename=self.filename
                )
                installed_script_context = True

            # formatters aren't automatically registered when running as a
            # script
            from marimo._output.formatters.formatters import (
                register_formatters,
            )
            from marimo._output.formatting import FORMATTERS

            if not FORMATTERS:
                register_formatters()

            post_execute_hooks = []
            if DependencyManager.matplotlib.has():
                from marimo._output.mpl import close_figures

                post_execute_hooks.append(close_figures)

            if is_async:
                outputs, defs = asyncio.run(
                    self._run_asynchronous(
                        post_execute_hooks=post_execute_hooks,
                    )
                )
            else:
                outputs, defs = self._run_synchronous(
                    post_execute_hooks=post_execute_hooks,
                )
            return outputs, defs

        # Cell runner manages the exception handling for kernel
        # runner, but script runner should raise the wrapped
        # exception if invoked directly.
        except MarimoRuntimeException as e:
            # MarimoMissingRefError, wraps the under lying NameError
            # for context, so we raise the NameError directly.
            if isinstance(e.__cause__, MarimoMissingRefError):
                # For type checking + sanity check
                if not isinstance(e.__cause__.name_error, NameError):
                    raise MarimoRuntimeException(
                        "Unexpected error occurred while running the app. "
                        "Improperly wrapped MarimoMissingRefError exception. "
                        "Please report this issue to "
                        "https://github.com/marimo-team/marimo/issues"
                    ) from e.__cause__
                raise e.__cause__.name_error from e.__cause__
            # For all other exceptions, we raise the wrapped exception
            # from "None" to indicate this is an Error propagation, and to not
            # muddy the stacktrace from the failing cells themselves.
            raise e.__cause__ from None  # type: ignore
        finally:
            if installed_script_context:
                teardown_context()

    def _cell_iterator(self) -> Iterator[CellImpl]:
        app = self.app
        for cid in app.execution_order:
            cell = app.cell_manager.cell_data_at(cid).cell
            if cell is None:
                continue

            if cell is not None and not app.graph.is_disabled(cid):
                yield cell._cell

    def _run_synchronous(
        self,
        post_execute_hooks: list[Callable[[], Any]],
    ) -> RunOutput:
        with patch_main_module_context(
            create_main_module(file=self.filename, input_override=None)
        ) as module:
            glbls = module.__dict__
            outputs: dict[CellId_t, Any] = {}
            for cell in self._cell_iterator():
                with get_context().with_cell_id(cell.cell_id):
                    output = execute_cell(cell, glbls, self.app.graph)
                    for hook in post_execute_hooks:
                        hook()
                outputs[cell.cell_id] = output
        return outputs, glbls

    async def _run_asynchronous(
        self,
        post_execute_hooks: list[Callable[[], Any]],
    ) -> RunOutput:
        with patch_main_module_context(
            create_main_module(file=self.filename, input_override=None)
        ) as module:
            glbls = module.__dict__
            outputs: dict[CellId_t, Any] = {}
            for cell in self._cell_iterator():
                with get_context().with_cell_id(cell.cell_id):
                    output = await execute_cell_async(
                        cell, glbls, self.app.graph
                    )
                    for hook in post_execute_hooks:
                        hook()
                outputs[cell.cell_id] = output
        return outputs, glbls

#+END_SRC
* context
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.context
:END:
** __init__
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.context.__init__
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/context/__init__.py
:END:
*** Assignment __all__
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
__all__ = [
    "get_context",
    "get_global_context",
    "ContextNotInitializedError",
    "ExecutionContext",
    "RuntimeContext",
    "runtime_context_installed",
    "teardown_context",
]

#+END_SRC
*** Import
#+BEGIN_SRC python
from marimo._runtime.context.types import (
    ContextNotInitializedError,
    ExecutionContext,
    RuntimeContext,
    get_context,
    get_global_context,
    runtime_context_installed,
    teardown_context,
)

#+END_SRC
** kernel_context
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.context.kernel_context
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/context/kernel_context.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from contextlib import contextmanager
from dataclasses import dataclass
from typing import TYPE_CHECKING, Any, Iterator, Optional

from marimo._config.config import MarimoConfig
from marimo._messaging.types import Stderr, Stdout
from marimo._plugins.ui._core.ids import IDProvider, NoIDProviderException
from marimo._runtime.cell_lifecycle_registry import CellLifecycleRegistry
from marimo._runtime.context.types import (
    ExecutionContext,
    RuntimeContext,
    initialize_context,
)
from marimo._runtime.dataflow import DirectedGraph
from marimo._runtime.functions import FunctionRegistry
from marimo._runtime.params import CLIArgs, QueryParams
from marimo._server.model import SessionMode

#+END_SRC
*** @dataclass: Class KernelRuntimeContext
#+BEGIN_SRC python
if TYPE_CHECKING:
    from marimo._ast.app import InternalApp
    from marimo._ast.cell import CellId_t
    from marimo._messaging.types import Stream
    from marimo._runtime.runtime import Kernel
    from marimo._runtime.state import State


@dataclass
class KernelRuntimeContext(RuntimeContext):
    """Encapsulates runtime state for a session."""

    _kernel: Kernel
    _session_mode: SessionMode
    # app that owns this context; None for top-level contexts
    _app: Optional[InternalApp] = None
    _id_provider: Optional[IDProvider] = None

    @property
    def graph(self) -> DirectedGraph:
        return self._kernel.graph

    @property
    def globals(self) -> dict[str, Any]:
        return self._kernel.globals

    @property
    def execution_context(self) -> ExecutionContext | None:
        return self._kernel.execution_context

    @property
    def user_config(self) -> MarimoConfig:
        return self._kernel.user_config

    @property
    def lazy(self) -> bool:
        return self._kernel.lazy()

    @property
    def cell_id(self) -> Optional[CellId_t]:
        """Get the cell id of the currently executing cell, if any."""
        if self._kernel.execution_context is not None:
            return self._kernel.execution_context.cell_id
        return None

    @property
    def cli_args(self) -> CLIArgs:
        """Get the CLI args."""
        return self._kernel.cli_args

    @property
    def query_params(self) -> QueryParams:
        """Get the query params."""
        return self._kernel.query_params

    @property
    def session_mode(self) -> SessionMode:
        """Get the session mode."""
        return self._session_mode

    @contextmanager
    def provide_ui_ids(self, prefix: str) -> Iterator[None]:
        old_id_provider = self._id_provider
        try:
            self._id_provider = IDProvider(prefix)
            yield
        finally:
            self._id_provider = old_id_provider

    def take_id(self) -> str:
        if self._id_provider is None:
            raise NoIDProviderException
        return self._id_provider.take_id()

    def get_ui_initial_value(self, object_id: str) -> Any:
        return self._kernel.get_ui_initial_value(object_id)

    def register_state_update(self, state: State[Any]) -> None:
        return self._kernel.register_state_update(state)

    @contextmanager
    def with_cell_id(self, cell_id: CellId_t) -> Iterator[None]:
        old = self.execution_context
        try:
            if old is not None:
                setting_element_value = old.setting_element_value
            else:
                setting_element_value = False
            self._kernel.execution_context = ExecutionContext(
                cell_id=cell_id,
                setting_element_value=setting_element_value,
            )
            yield
        finally:
            self._kernel.execution_context = old

    @property
    def app(self) -> InternalApp:
        assert self._app is not None
        return self._app

#+END_SRC
*** Function create_kernel_context
#+BEGIN_SRC python
def create_kernel_context(
    kernel: Kernel,
    stream: Stream,
    stdout: Stdout | None,
    stderr: Stderr | None,
    virtual_files_supported: bool = True,
    mode: SessionMode = SessionMode.EDIT,
    app: InternalApp | None = None,
    parent: KernelRuntimeContext | None = None,
) -> KernelRuntimeContext:
    from marimo._plugins.ui._core.registry import UIElementRegistry
    from marimo._runtime.state import StateRegistry
    from marimo._runtime.virtual_file import VirtualFileRegistry

    return KernelRuntimeContext(
        _kernel=kernel,
        _session_mode=mode,
        _app=app,
        ui_element_registry=UIElementRegistry(),
        state_registry=StateRegistry(),
        function_registry=FunctionRegistry(),
        cell_lifecycle_registry=CellLifecycleRegistry(),
        virtual_file_registry=VirtualFileRegistry(),
        virtual_files_supported=virtual_files_supported,
        stream=stream,
        stdout=stdout,
        stderr=stderr,
        children=[],
        parent=parent,
        filename=kernel.app_metadata.filename,
    )

#+END_SRC
*** Function initialize_kernel_context
#+BEGIN_SRC python
def initialize_kernel_context(
    kernel: Kernel,
    stream: Stream,
    stdout: Stdout | None,
    stderr: Stderr | None,
    virtual_files_supported: bool = True,
    mode: SessionMode = SessionMode.EDIT,
) -> None:
    """Initializes thread-local/session-specific context.

    Must be called exactly once for each client thread.
    """
    initialize_context(
        runtime_context=create_kernel_context(
            kernel,
            stream,
            stdout,
            stderr,
            virtual_files_supported,
            mode,
        )
    )

#+END_SRC
** script_context
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.context.script_context
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/context/script_context.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import sys
from contextlib import contextmanager
from dataclasses import dataclass
from typing import TYPE_CHECKING, Any, Iterator, Optional

from marimo._cli.parse_args import args_from_argv
from marimo._config.config import MarimoConfig
from marimo._plugins.ui._core.ids import NoIDProviderException
from marimo._plugins.ui._core.registry import UIElementRegistry
from marimo._runtime.cell_lifecycle_registry import CellLifecycleRegistry
from marimo._runtime.context.types import (
    ExecutionContext,
    RuntimeContext,
    initialize_context,
)
from marimo._runtime.dataflow import DirectedGraph
from marimo._runtime.functions import FunctionRegistry
from marimo._runtime.params import CLIArgs, QueryParams
from marimo._runtime.patches import (
    create_main_module,
    patch_main_module_context,
)
from marimo._runtime.state import State, StateRegistry

#+END_SRC
*** @dataclass: Class ScriptRuntimeContext
#+BEGIN_SRC python
if TYPE_CHECKING:
    from marimo._ast.app import InternalApp
    from marimo._ast.cell import CellId_t
    from marimo._messaging.types import Stream


@dataclass
class ScriptRuntimeContext(RuntimeContext):
    """Encapsulates runtime state when running as a script."""

    _app: InternalApp

    def __post_init__(self) -> None:
        self._cli_args: CLIArgs | None = None
        self._query_params = QueryParams({}, _registry=self.state_registry)

    @property
    def graph(self) -> DirectedGraph:
        return self._app.graph

    @property
    def globals(self) -> dict[str, Any]:
        with patch_main_module_context(
            create_main_module(file=None, input_override=None)
        ) as module:
            glbls = module.__dict__
        glbls.update(sys.modules["__main__"].__dict__)
        return glbls

    @property
    def execution_context(self) -> ExecutionContext | None:
        return self._app.execution_context

    @property
    def user_config(self) -> MarimoConfig:
        return self._app.user_config

    @property
    def cell_id(self) -> Optional[CellId_t]:
        """Get the cell id of the currently executing cell, if any."""
        if self.execution_context is not None:
            return self.execution_context.cell_id
        return None

    @property
    def cli_args(self) -> CLIArgs:
        """Get the CLI args."""
        if self._cli_args is None:
            self._cli_args = CLIArgs(args_from_argv())
        return self._cli_args

    @property
    def query_params(self) -> QueryParams:
        """Get the query params."""
        return self._query_params

    def get_ui_initial_value(self, object_id: str) -> Any:
        del object_id
        raise KeyError

    @contextmanager
    def provide_ui_ids(self, prefix: str) -> Iterator[None]:
        del prefix
        yield

    def take_id(self) -> str:
        raise NoIDProviderException

    def register_state_update(self, state: State[Any]) -> None:
        del state
        return

    @contextmanager
    def with_cell_id(self, cell_id: CellId_t) -> Iterator[None]:
        old = self.execution_context
        try:
            if old is not None:
                setting_element_value = old.setting_element_value
            else:
                setting_element_value = False
            self._app.set_execution_context(
                ExecutionContext(
                    cell_id=cell_id,
                    setting_element_value=setting_element_value,
                )
            )
            yield
        finally:
            self._app.set_execution_context(old)

    @property
    def app(self) -> InternalApp:
        return self._app

#+END_SRC
*** Function initialize_script_context
#+BEGIN_SRC python
def initialize_script_context(
    app: InternalApp, stream: Stream, filename: str | None
) -> None:
    """Initializes thread-local/session-specific context.

    Must be called exactly once for each client thread.
    """
    from marimo._runtime.virtual_file import VirtualFileRegistry

    runtime_context = ScriptRuntimeContext(
        _app=app,
        ui_element_registry=UIElementRegistry(),
        state_registry=StateRegistry(),
        function_registry=FunctionRegistry(),
        cell_lifecycle_registry=CellLifecycleRegistry(),
        virtual_file_registry=VirtualFileRegistry(),
        virtual_files_supported=False,
        stream=stream,
        stdout=None,
        stderr=None,
        children=[],
        parent=None,
        filename=filename,
    )
    initialize_context(runtime_context=runtime_context)

#+END_SRC
** Thread-local context for the runtime
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.context.types
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/context/types.py
:END:
*** Docstring
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
"""Thread-local context for the runtime

Each client gets its own context.
"""

#+END_SRC
*** Import statements
#+BEGIN_SRC python
from __future__ import annotations

import abc
import threading
from contextlib import contextmanager
from dataclasses import dataclass
from typing import TYPE_CHECKING, Any, Iterator, Optional

from marimo._config.config import MarimoConfig
from marimo._messaging.types import Stderr, Stdout
from marimo._runtime import dataflow
from marimo._runtime.cell_lifecycle_registry import CellLifecycleRegistry
from marimo._runtime.functions import FunctionRegistry

#+END_SRC
*** Class GlobalContext
#+BEGIN_SRC python
if TYPE_CHECKING:
    from marimo._ast.app import InternalApp
    from marimo._ast.cell import CellId_t
    from marimo._messaging.types import Stream
    from marimo._output.hypertext import Html
    from marimo._plugins.ui._core.registry import UIElementRegistry
    from marimo._runtime.params import CLIArgs, QueryParams
    from marimo._runtime.state import State, StateRegistry
    from marimo._runtime.virtual_file import VirtualFileRegistry


class GlobalContext:
    """Context shared by all sessions."""

    def __init__(self) -> None:
        self._mpl_installed = False

    @property
    def mpl_installed(self) -> bool:
        return self._mpl_installed

    def set_mpl_installed(self, mpl_installed: bool) -> None:
        self._mpl_installed = mpl_installed

#+END_SRC
*** Assignment _GLOBAL_CONTEXT = GlobalContext()
#+BEGIN_SRC python
_GLOBAL_CONTEXT = GlobalContext()

#+END_SRC
*** Function get_global_context
#+BEGIN_SRC python
def get_global_context() -> GlobalContext:
    return _GLOBAL_CONTEXT

#+END_SRC
*** @dataclass: Class ExecutionContext
#+BEGIN_SRC python
@dataclass
class ExecutionContext:
    cell_id: CellId_t
    setting_element_value: bool
    # Cell ID corresponding to local graph object, and not prefixed in script
    # context.
    local_cell_id: Optional[CellId_t] = None
    # output object set imperatively
    output: Optional[list[Html]] = None

#+END_SRC
*** @dataclass: Class RuntimeContext
#+BEGIN_SRC python
@dataclass
class RuntimeContext(abc.ABC):
    ui_element_registry: UIElementRegistry
    state_registry: StateRegistry
    function_registry: FunctionRegistry
    cell_lifecycle_registry: CellLifecycleRegistry
    virtual_file_registry: VirtualFileRegistry
    virtual_files_supported: bool
    stream: Stream
    stdout: Stdout | None
    stderr: Stderr | None
    children: list[RuntimeContext]
    parent: RuntimeContext | None
    filename: str | None

    @property
    @abc.abstractmethod
    def graph(self) -> dataflow.DirectedGraph:
        pass

    @property
    @abc.abstractmethod
    def globals(self) -> dict[str, Any]:
        pass

    @property
    @abc.abstractmethod
    def execution_context(self) -> ExecutionContext | None:
        pass

    @property
    @abc.abstractmethod
    def user_config(self) -> MarimoConfig:
        pass

    @property
    @abc.abstractmethod
    def cell_id(self) -> Optional[CellId_t]:
        """Get the cell id of the currently executing cell, if any."""
        pass

    @property
    @abc.abstractmethod
    def cli_args(self) -> CLIArgs:
        """Get the CLI args."""
        pass

    @property
    @abc.abstractmethod
    def query_params(self) -> QueryParams:
        """Get the query params."""
        pass

    @abc.abstractmethod
    def get_ui_initial_value(self, object_id: str) -> Any:
        pass

    @contextmanager
    @abc.abstractmethod
    def provide_ui_ids(self, prefix: str) -> Iterator[None]:
        pass

    @abc.abstractmethod
    def take_id(self) -> str:
        pass

    @abc.abstractmethod
    def register_state_update(self, state: State[Any]) -> None:
        pass

    @contextmanager
    @abc.abstractmethod
    def with_cell_id(self, cell_id: CellId_t) -> Iterator[None]:
        pass

    def add_child(self, runtime_context: RuntimeContext) -> None:
        if runtime_context not in self.children:
            self.children.append(runtime_context)

    def remove_child(self, runtime_context: RuntimeContext) -> None:
        self.children.remove(runtime_context)
        assert runtime_context not in self.children

    @contextmanager
    def install(self) -> Iterator[None]:
        global _THREAD_LOCAL_CONTEXT
        old_ctx = _THREAD_LOCAL_CONTEXT.runtime_context
        try:
            _THREAD_LOCAL_CONTEXT.runtime_context = self
            yield
        finally:
            _THREAD_LOCAL_CONTEXT.runtime_context = old_ctx

    @property
    @abc.abstractmethod
    def app(self) -> InternalApp:
        pass

#+END_SRC
*** Class _ThreadLocalContext
#+BEGIN_SRC python
class _ThreadLocalContext(threading.local):
    """Thread-local container that holds thread/session-specific state."""

    def __init__(self) -> None:
        self.runtime_context: Optional[RuntimeContext] = None

    def initialize(self, runtime_context: RuntimeContext) -> None:
        self.runtime_context = runtime_context

#+END_SRC
*** Class ContextNotInitializedError
#+BEGIN_SRC python
class ContextNotInitializedError(Exception):
    pass

#+END_SRC
*** Assignment _THREAD_LOCAL_CONTEXT = _ThreadLocalContext()
#+BEGIN_SRC python
# Stores session-specific state, which is thread-local (relevant for run
# mode, in which every session runs in its own thread). Each thread
# must explicitly initialize this object.
_THREAD_LOCAL_CONTEXT = _ThreadLocalContext()

#+END_SRC
*** Function initialize_context
#+BEGIN_SRC python
def initialize_context(runtime_context: RuntimeContext) -> None:
    try:
        get_context()
        raise RuntimeError("RuntimeContext was already initialized.")
    except ContextNotInitializedError:
        global _THREAD_LOCAL_CONTEXT
        _THREAD_LOCAL_CONTEXT.initialize(runtime_context=runtime_context)

#+END_SRC
*** Function teardown_context
#+BEGIN_SRC python
def teardown_context() -> None:
    """Unset the context, for testing."""
    global _THREAD_LOCAL_CONTEXT
    _THREAD_LOCAL_CONTEXT.runtime_context = None

#+END_SRC
*** Function get_context
#+BEGIN_SRC python
def get_context() -> RuntimeContext:
    """Return the runtime context.

    Throws a ContextNotInitializedError if the context has not been
    created.
    """
    if _THREAD_LOCAL_CONTEXT.runtime_context is None:
        raise ContextNotInitializedError
    return _THREAD_LOCAL_CONTEXT.runtime_context

#+END_SRC
*** Function runtime_context_installed
#+BEGIN_SRC python
def runtime_context_installed() -> bool:
    try:
        get_context()
    except ContextNotInitializedError:
        return False
    else:
        return True

#+END_SRC
** utils
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.context.utils
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/context/utils.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import Literal, Optional

from marimo._output.rich_help import mddoc
from marimo._runtime.context import ContextNotInitializedError, get_context
from marimo._runtime.context.kernel_context import KernelRuntimeContext
from marimo._runtime.context.script_context import ScriptRuntimeContext

#+END_SRC
*** @mddoc: Function running_in_notebook
#+BEGIN_SRC python
@mddoc
def running_in_notebook() -> bool:
    """Returns True if running in a marimo notebook, False otherwise"""

    try:
        ctx = get_context()
    except ContextNotInitializedError:
        return False
    else:
        return isinstance(ctx, KernelRuntimeContext)

#+END_SRC
*** Function get_mode
#+BEGIN_SRC python
def get_mode() -> Optional[Literal["run", "edit", "script"]]:
    """Returns the current mode of the marimo app.

    Returns:
        Optional[Literal["run", "edit", "script"]]: The current mode,
        or None if marimo has no context initialized.
    """
    try:
        context = get_context()
        if isinstance(context, KernelRuntimeContext):
            return context.session_mode  # type: ignore
        if isinstance(context, ScriptRuntimeContext):
            return "script"
    except ContextNotInitializedError:
        pass
    return None

#+END_SRC
* layout
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.layout
:END:
** layout
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.layout.layout
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/layout/layout.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from typing import Any, Optional

from marimo import _loggers

#+END_SRC
*** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
LOGGER = _loggers.marimo_logger()

#+END_SRC
*** @dataclass: Class LayoutConfig
#+BEGIN_SRC python
@dataclass
class LayoutConfig:
    # type of layout
    type: str
    # data for layout
    data: dict[str, Any]

#+END_SRC
*** Function save_layout_config
#+BEGIN_SRC python
def save_layout_config(
    directory: str, app_name: str, config: LayoutConfig
) -> str:
    """
    Save the layout configuration to disk
    at the given directory.

    The layout is saved as a JSON file under
        <directory>/layouts/<app_name>.{type}.json
    This allows:
        - all layouts to be saved in the same directory
        - multiple layouts to be saved for the same app
        - multiple apps can live in the same directory

    Returns: the path to the layout file
    """

    # remove py extension
    app_name_without_ext = app_name.replace(".py", "")
    # relative file path
    filepath = f"layouts/{app_name_without_ext}.{config.type}.json"
    # full file path
    full_filepath = os.path.join(directory, filepath)
    # create directory if it doesn't exist
    os.makedirs(os.path.dirname(full_filepath), exist_ok=True)
    with open(full_filepath, "w") as f:
        json.dump(config.__dict__, f, indent=2)
    return filepath

#+END_SRC
*** Function read_layout_config
#+BEGIN_SRC python
def read_layout_config(
    directory: str, filename: str
) -> Optional[LayoutConfig]:
    """
    Read the layout configuration from disk.

    Returns: the layout configuration
    """
    filepath = os.path.join(directory, filename)
    if not os.path.exists(filepath):
        LOGGER.warning("Layout file %s does not exist", filepath)
        return None
    if not filepath.endswith(".json"):
        LOGGER.warning("Layout file %s is not a JSON file", filepath)
        return None
    with open(filepath) as f:
        data = json.load(f)
    return LayoutConfig(type=data["type"], data=data["data"])

#+END_SRC
* output
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.output
:END:
** Write to a cell's output area.
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.output.__init__
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/output/__init__.py
:END:
*** Docstring
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
"""Write to a cell's output area."""

#+END_SRC
*** Assignment __all__ = [     "append",     "clear",     "replace",     "replace_at_index", ]
#+BEGIN_SRC python
__all__ = [
    "append",
    "clear",
    "replace",
    "replace_at_index",
]

#+END_SRC
*** Import
#+BEGIN_SRC python
from marimo._runtime.output._output import (
    append,
    clear,
    replace,
    replace_at_index,
)

#+END_SRC
** _output
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.output._output
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/output/_output.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from marimo._ast.cell import CellId_t
from marimo._messaging.cell_output import CellChannel
from marimo._messaging.ops import CellOp
from marimo._messaging.tracebacks import write_traceback
from marimo._output import formatting
from marimo._output.rich_help import mddoc
from marimo._plugins.stateless.flex import vstack
from marimo._runtime.context import get_context
from marimo._runtime.context.types import ContextNotInitializedError

#+END_SRC
*** Function write_internal
#+BEGIN_SRC python
def write_internal(cell_id: CellId_t, value: object) -> None:
    output = formatting.try_format(value)
    if output.traceback is not None:
        write_traceback(output.traceback)
    CellOp.broadcast_output(
        channel=CellChannel.OUTPUT,
        mimetype=output.mimetype,
        data=output.data,
        cell_id=cell_id,
        status=None,
    )

#+END_SRC
*** @mddoc: Function replace
#+BEGIN_SRC python
@mddoc
def replace(value: object) -> None:
    """Replace a cell's output with a new one.

    Call `mo.output.replace()` to write to a cell's output area, replacing
    the existing output, if any.

    **Args:**

    - `value`: object to output
    """
    try:
        ctx = get_context()
    except ContextNotInitializedError:
        return

    if ctx.execution_context is None:
        return
    elif value is None:
        ctx.execution_context.output = None
    else:
        ctx.execution_context.output = [formatting.as_html(value)]
    write_internal(cell_id=ctx.execution_context.cell_id, value=value)

#+END_SRC
*** @mddoc: Function replace_at_index
#+BEGIN_SRC python
@mddoc
def replace_at_index(value: object, idx: int) -> None:
    """Replace a cell's output at the given index with value.

    Call this function to replace an existing object in a cell's output. If idx
    is equal to the length of the output, this is equivalent to an append.

    **Args:**

    - `value`: new object to replace an existing object
    - `idx`: index of output to replace
    """

    try:
        ctx = get_context()
    except ContextNotInitializedError:
        return

    if ctx.execution_context is None or ctx.execution_context.output is None:
        return
    elif idx > len(ctx.execution_context.output):
        raise IndexError(
            f"idx is {idx}, must be <= {len(ctx.execution_context.output)}"
        )
    elif idx == len(ctx.execution_context.output):
        ctx.execution_context.output.append(formatting.as_html(value))
    else:
        ctx.execution_context.output[idx] = formatting.as_html(value)
    write_internal(
        cell_id=ctx.execution_context.cell_id,
        value=vstack(ctx.execution_context.output),
    )

#+END_SRC
*** @mddoc: Function append
#+BEGIN_SRC python
@mddoc
def append(value: object) -> None:
    """Append a new object to a cell's output.

    Call this function to incrementally build a cell's output. Appended
    outputs are stacked vertically.

    **Args:**

    - `value`: object to output
    """
    try:
        ctx = get_context()
    except ContextNotInitializedError:
        return

    if ctx.execution_context is None:
        return

    if ctx.execution_context.output is None:
        ctx.execution_context.output = [formatting.as_html(value)]
    else:
        ctx.execution_context.output.append(formatting.as_html(value))
    write_internal(
        cell_id=ctx.execution_context.cell_id,
        value=vstack(ctx.execution_context.output),
    )

#+END_SRC
*** @mddoc: Function clear
#+BEGIN_SRC python
@mddoc
def clear() -> None:
    """Clear a cell's output."""
    return replace(None)

#+END_SRC
*** Function flush
#+BEGIN_SRC python
def flush() -> None:
    """Internal function to re-render the cell's output."""
    try:
        ctx = get_context()
    except ContextNotInitializedError:
        return

    if ctx.execution_context is None:
        return

    if ctx.execution_context.output is not None:
        value = vstack(ctx.execution_context.output)
    else:
        value = None
    write_internal(cell_id=ctx.execution_context.cell_id, value=value)

#+END_SRC
*** Function remove
#+BEGIN_SRC python
def remove(value: object) -> None:
    """Internal function to remove an object from a cell's output."""
    try:
        ctx = get_context()
    except ContextNotInitializedError:
        return

    if ctx.execution_context is None or ctx.execution_context.output is None:
        return
    output = [
        item for item in ctx.execution_context.output if item is not value
    ]
    ctx.execution_context.output = output if output else None
    flush()

#+END_SRC
* packages
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.packages
:END:
** conda_package_manager
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.packages.conda_package_manager
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/packages/conda_package_manager.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import List

from marimo._runtime.packages.module_name_to_conda_name import (
    module_name_to_conda_name,
)
from marimo._runtime.packages.package_manager import (
    CanonicalizingPackageManager,
    PackageDescription,
)
from marimo._runtime.packages.utils import split_packages

#+END_SRC
*** Class CondaPackageManager
#+BEGIN_SRC python
class CondaPackageManager(CanonicalizingPackageManager):
    name = "conda"
    docs_url = "https://docs.conda.io/projects/conda/"

    def _construct_module_name_mapping(self) -> dict[str, str]:
        return module_name_to_conda_name()

#+END_SRC
*** Class PixiPackageManager
#+BEGIN_SRC python
class PixiPackageManager(CondaPackageManager):
    name = "pixi"

    async def _install(self, package: str) -> bool:
        return self.run(["pixi", "add", *split_packages(package)])

    async def uninstall(self, package: str) -> bool:
        return self.run(["pixi", "remove", *split_packages(package)])

    def list_packages(self) -> List[PackageDescription]:
        import json
        import subprocess

        if not self.is_manager_installed():
            return []

        try:
            proc = subprocess.run(
                ["pixi", "list", "--json"],
                capture_output=True,
                text=True,
                check=True,
            )
            packages = json.loads(proc.stdout)
            return [
                PackageDescription(name=pkg["name"], version=pkg["version"])
                for pkg in packages
            ]
        except (subprocess.CalledProcessError, json.JSONDecodeError):
            return []

#+END_SRC
** module_name_to_conda_name
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.packages.module_name_to_conda_name
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/packages/module_name_to_conda_name.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from marimo._runtime.packages.module_name_to_pypi_name import (
    module_name_to_pypi_name,
)

#+END_SRC
*** Function module_name_to_conda_name
#+BEGIN_SRC python
def module_name_to_conda_name() -> dict[str, str]:
    # as a heuristic, start with pypi mapping and sub out things
    # that known to be incorrect; this doesn't handle channels ...
    mapping = module_name_to_pypi_name()
    mapping["cv2"] = "opencv"
    mapping["ibis"] = "ibis-duckdb"
    return mapping

#+END_SRC
** module_name_to_pypi_name
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.packages.module_name_to_pypi_name
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/packages/module_name_to_pypi_name.py
:END:
*** Function module_name_to_pypi_name
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations


# Mapping from a module name to the corresponding package name
# on PyPI
def module_name_to_pypi_name() -> dict[str, str]:
    return {
        "cv2": "opencv-python",
        "shopify": "ShopifyAPI",
        "bigquery": "google-cloud-bigquery",
        "carbon3d": "carbon3d-client",
        "telegram": "python-telegram-bot",
        "AFQ": "pyAFQ",
        "AG_fft_tools": "agpy",
        "screen": "pexpect",
        "Adafruit": "Adafruit-Libraries",
        "webdav": "Zope2",
        "Asterisk": "py-Asterisk",
        "BB_jekyll_hook": "bitbucket-jekyll-hook",
        "Banzai": "Banzai-NGS",
        "BeautifulSoupTests": "BeautifulSoup",
        "BioSQL": "biopython",
        "BuildbotStatusShields": "BuildbotEightStatusShields",
        "MethodObject": "ExtensionClass",
        "Crypto": "pycryptodome",
        "Cryptodome": "pycryptodomex",
        "FiftyOneDegrees": "51degrees-mobile-detector-v3-wrapper",
        "functional": "pyfunctional",
        "GeoBases": "GeoBasesDev",
        "IPython": "ipython",
        "Kittens": "astro-kittens",
        "Levenshtein": "python-Levenshtein",
        "MySQLdb": "MySQL-python",
        "OpenGL": "PyOpenGL",
        "OpenSSL": "pyOpenSSL",
        "PIL": "Pillow",
        "PyWCSTools": "astLib",
        "Pyxides": "astro-pyxis",
        "pysideuic": "PySide",
        "S3": "s3cmd",
        "SCons": "pystick",
        "Stemmer": "PyStemmer",
        "TopZooTools": "topzootools",
        "TreeDisplay": "DocumentTemplate",
        "WorkingWithDocumentConversion": "aspose-pdf-java-for-python",
        "aadb": "auto-adjust-display-brightness",
        "abakaffe": "abakaffe-cli",
        "abiosgaming": "abiosgaming.py",
        "abiquo": "abiquo-api",
        "abl": "abl.vpath",
        "abo": "abo-generator",
        "abris_transform": "abris",
        "abstract": "abstract.jwrotator",
        "abu": "abu.admin",
        "ac_flask": "AC-Flask-HipChat",
        "acg": "anikom15",
        "acme": "acme.hello",
        "acted": "acted.projects",
        "action": "ActionServer",
        "actionbar": "actionbar.panel",
        "activehomed": "afn",
        "activepapers": "ActivePapers.Py",
        "address_book": "address-book-lansry",
        "adi": "adi.trash",
        "adict": "aDict2",
        "aditam": "aditam.core",
        "adiumsh": "adium-sh",
        "adjector": "AdjectorTracPlugin",
        "adkit": "Banner-Ad-Toolkit",
        "admin_tools": "django-admin-tools",
        "adminishcategories": "adminish-categories",
        "adminsortable": "django-admin-sortable",
        "adspygoogle": "adspygoogle.adwords",
        "advancedcaching": "agtl",
        "adytum": "Adytum-PyMonitor",
        "affinitic": "affinitic.zamqp",
        "afpy": "afpy.xap",
        "agatesql": "agate-sql",
        "ageliaco": "ageliaco.recipe.csvconfig",
        "agent_http": "agent.http",
        "agora": "Agora-Service-Provider",
        "agoraplex": "agoraplex.themes.sphinx",
        "agsci": "agsci.blognewsletter",
        "agx": "agx.transform.xmi2uml",
        "aimes": "aimes.skeleton",
        "aio": "aio.signals",
        "aiohs2": "aio-hs2",
        "aioroutes": "aio-routes",
        "aios3": "aio-s3",
        "airbrake": "airbrake-flask",
        "airship": "airship-steamcloud",
        "akamai": "edgegrid-python",
        "alation": "alation-api",
        "alba_client": "alba-client-python",
        "alburnum": "alburnum-maas-client",
        "alchemist": "alchemist.ui",
        "alchemyapi": "alchemyapi-python",
        "alerta": "alerta-server",
        "alexandria_upload": "Alexandria-Upload-Utils",
        "alibaba": "alibaba-python-sdk",
        "aliyun": "aliyun-python-sdk",
        "aliyuncli": "alicloudcli",
        "aliyunsdkacs": "aliyun-python-sdk-acs",
        "aliyunsdkbatchcompute": "aliyun-python-sdk-batchcompute",
        "aliyunsdkbsn": "aliyun-python-sdk-bsn",
        "aliyunsdkbss": "aliyun-python-sdk-bss",
        "aliyunsdkcdn": "aliyun-python-sdk-cdn",
        "aliyunsdkcms": "aliyun-python-sdk-cms",
        "aliyunsdkcore": "aliyun-python-sdk-core",
        "aliyunsdkcrm": "aliyun-python-sdk-crm",
        "aliyunsdkcs": "aliyun-python-sdk-cs",
        "aliyunsdkdrds": "aliyun-python-sdk-drds",
        "aliyunsdkecs": "aliyun-python-sdk-ecs",
        "aliyunsdkess": "aliyun-python-sdk-ess",
        "aliyunsdkft": "aliyun-python-sdk-ft",
        "aliyunsdkmts": "aliyun-python-sdk-mts",
        "aliyunsdkocs": "aliyun-python-sdk-ocs",
        "aliyunsdkoms": "aliyun-python-sdk-oms",
        "aliyunsdkossadmin": "aliyun-python-sdk-ossadmin",
        "aliyunsdkr-kvstore": "aliyun-python-sdk-r-kvstore",
        "aliyunsdkram": "aliyun-python-sdk-ram",
        "aliyunsdkrds": "aliyun-python-sdk-rds",
        "aliyunsdkrisk": "aliyun-python-sdk-risk",
        "aliyunsdkros": "aliyun-python-sdk-ros",
        "aliyunsdkslb": "aliyun-python-sdk-slb",
        "aliyunsdksts": "aliyun-python-sdk-sts",
        "aliyunsdkubsms": "aliyun-python-sdk-ubsms",
        "aliyunsdkyundun": "aliyun-python-sdk-yundun",
        "allattachments": "AllAttachmentsMacro",
        "allocine": "allocine-wrapper",
        "allowedsites": "django-allowedsites",
        "alm": "alm.solrindex",
        "aloft": "aloft.py",
        "alpacalib": "alpaca",
        "alphabetic": "alphabetic-simple",
        "alphasms": "alphasms-client",
        "altered": "altered.states",
        "alterootheme": "alterootheme.lazydays",
        "alurinium": "alurinium-image-processing",
        "alxlib": "alx",
        "amara3": "amara3-xml",
        "amazon": "python-amazon-simple-product-api",
        "ambikesh1349-1": "ambikesh1349-1",
        "ambilight": "AmbilightParty",
        "amifs": "amifs-core",
        "amiorganizer": "ami-organizer",
        "amitu": "amitu-zutils",
        "amltlearn": "AMLT-learn",
        "amocrm": "amocrm-api",
        "amqpdispatcher": "amqp-dispatcher",
        "amqpstorm": "AMQP-Storm",
        "analytics": "analytics-python",
        "analyzedir": "AnalyzeDirectory",
        "ancientsolutions": "ancientsolutions-crypttools",
        "anderson_paginator": "anderson.paginator",
        "android_clean_app": "android-resource-remover",
        "anel_power_control": "AnelPowerControl",
        "angus": "angus-sdk-python",
        "annalist_root": "Annalist",
        "annogesiclib": "ANNOgesic",
        "ansible-role-apply": "ansible-role-apply",
        "ansibledebugger": "ansible-playbook-debugger",
        "ansibledocgen": "ansible-docgen",
        "ansibleflow": "ansible-flow",
        "ansibleinventorygrapher": "ansible-inventory-grapher",
        "ansiblelint": "ansible-lint",
        "ansiblerolesgraph": "ansible-roles-graph",
        "ansibletools": "ansible-tools",
        "anthill": "anthill.tal.macrorenderer",
        "anthrax": "AnthraxImage",
        "antisphinx": "antiweb",
        "antispoofing": "antispoofing.evaluation",
        "antlr4": "antlr4-python-alt",
        "anybox": "anybox.scripts.odoo",
        "googleapiclient": "google-api-python-client",
        "apitools": "google-apitools",
        "apm": "arpm",
        "app_data": "django-appdata",
        "appconf": "django-appconf",
        "appd": "AppDynamicsREST",
        "appdynamics_bindeps": "appdynamics-bindeps-osx-x64",
        "appdynamics_proxysupport": "appdynamics-proxysupport-osx-x64",
        "appium": "Appium-Python-Client",
        "appliapps": "applibase",
        "appserver": "broadwick",
        "archetypes": "archetypes.schemaextender",
        "arm": "ansible-role-manager",
        "armor": "armor-api",
        "armstrong": "armstrong.utils.celery",
        "arstecnica": "arstecnica.sqlalchemy.async",
        "article-downloader": "article-downloader",
        "artifactcli": "artifact-cli",
        "arvados": "arvados-python-client",
        "arvados_cwl": "arvados-cwl-runner",
        "arvnodeman": "arvados-node-manager",
        "asana_to_github": "AsanaToGithub",
        "asciibinary": "AsciiBinaryConverter",
        "asd": "AdvancedSearchDiscovery",
        "askbot": "askbot-tuanpa",
        "asnhistory": "asnhistory-redis",
        "aspen_jinja2_renderer": "aspen-jinja2",
        "aspen_tornado_engine": "aspen-tornado",
        "asprise_ocr_api": "asprise-ocr-sdk-python-api",
        "aspy": "aspy.yaml",
        "asterisk": "asterisk-ami",
        "asts": "add-asts",
        "asymmetricbase": "asymmetricbase.utils",
        "asyncirc": "asyncio-irc",
        "asyncmongoorm": "asyncmongoorm-je",
        "asyncssh": "asyncssh-unofficial",
        "athletelist": "athletelistyy",
        "atm": "automium",
        "atmosphere": "atmosphere-python-client",
        "atom": "gdata",
        "atomic": "AtomicWrite",
        "atomisator": "atomisator.readers",
        "atreal": "atreal.usersinout",
        "atsim": "atsim.potentials",
        "attractsdk": "attract-sdk",
        "audio": "audio.wave",
        "aufrefer": "auf-refer",
        "auslfe": "auslfe.formonline.content",
        "auspost": "auspost-apis",
        "auth0": "auth0-python",
        "auth_server_client": "AuthServerClient",
        "authorize": "AuthorizeSauce",
        "authzpolicy": "AuthzPolicyPlugin",
        "autobahn": "autobahn-rce",
        "avatar": "geonode-avatar",
        "awebview": "android-webview",
        "azure": "azure-storage",
        "b2gcommands": "b2g-commands",
        "b2gperf": "b2gperf-v2.2",
        "b2gpopulate": "b2gpopulate-v2.2",
        "b3j0f": "b3j0f.utils",
        "babel": "Babel",
        "babelglade": "BabelGladeExtractor",
        "backplane": "backplane2-pyclient",
        "backport_abcoll": "backport-collections",
        "backports": "backports.statistics",
        "badgekit": "badgekit-api-client",
        "badlinks": "BadLinksPlugin",
        "bael": "bael.project",
        "baidu": "baidupy",
        "balrog": "buildtools",
        "baluhn": "baluhn-redux",
        "bamboo": "bamboo-server",
        "bambu": "bambu-sites",
        "banana": "banana.maya",
        "bang": "bangtext",
        "barcode": "barcode-generator",
        "bark": "bark-ssg",
        "barking_owl": "BarkingOwl",
        "bart": "bart-py",
        "basalt": "basalt-tasks",
        "base62": "base-62",
        "basemap": "basemap-Jim",
        "bash": "bash-toolbelt",
        "bashutils": "Python-Bash-Utils",
        "basic_http": "BasicHttp",
        "basil": "basil-daq",
        "batchapps": "azure-batch-apps",
        "bcrypt": "python-bcrypt",
        "beaker": "Beaker",
        "beetsplug": "beets",
        "begin": "begins",
        "benchit": "bench-it",
        "beproud": "beproud.utils",
        "bfillings": "burrito-fillings",
        "pilot": "BigJob",
        "billboard": "billboard.py",
        "binstar_build_client": "anaconda-build",
        "binstar_client": "anaconda-client",
        "biocommons": "biocommons.dev",
        "birdhousebuilder": "birdhousebuilder.recipe.supervisor",
        "blender26-meshio": "pymeshio",
        "borg": "borg.localrole",
        "bow": "bagofwords",
        "bpdb": "bpython",
        "bqapi": "bisque-api",
        "braces": "django-braces",
        "briefscaster": "briefs-caster",
        "brisa_media_server/plugins": "brisa-media-server-plugins",
        "brkt_requests": "brkt-sdk",
        "broadcastlogging": "broadcast-logging",
        "brocadetool": "brocade-tool",
        "bronto": "bronto-python",
        "brownie": "Brownie",
        "browsermobproxy": "browsermob-proxy",
        "brubeckmysql": "brubeck-mysql",
        "brubeckoauth": "brubeck-oauth",
        "brubeckservice": "brubeck-service",
        "brubeckuploader": "brubeck-uploader",
        "bs4": "beautifulsoup4",
        "gridfs": "pymongo",
        "bst": "bst.pygasus.wsgi",
        "btable": "btable-py",
        "btapi": "bananatag-api",
        "btceapi": "btce-api",
        "btcebot": "btce-bot",
        "btsync": "btsync.py",
        "buck": "buck.pprint",
        "bud": "bud.nospam",
        "budy": "budy-api",
        "buffer": "buffer-alpaca",
        "buggd": "bug.gd",
        "bugle": "bugle-sites",
        "bugspots": "bug-spots",
        "bugzilla": "python-bugzilla",
        "bugzscout": "bugzscout-py",
        "buildTools": "ajk-ios-buildTools",
        "buildnotifylib": "BuildNotify",
        "buildout": "buildout.variables",
        "buildslave": "buildbot-slave",
        "xmlrpc": "pies2overrides",
        "bumper": "bumper-lib",
        "bumple": "bumple-downloader",
        "bundesliga": "bundesliga-cli",
        "bundlemaker": "bundlemanager",
        "burpui": "burp-ui",
        "busyflow": "busyflow.pivotal",
        "buttercms-django": "buttercms-django",
        "buzz": "buzz-python-client",
        "bvc": "buildout-versions-checker",
        "bvggrabber": "bvg-grabber",
        "byond": "BYONDTools",
        "bzETL": "Bugzilla-ETL",
        "bzlib": "bugzillatools",
        "bzrlib": "bzr-pqm",
        "c2c": "c2c.versions",
        "c2c_recipe_facts": "c2c.recipe.facts",
        "cabalgata": "cabalgata-zookeeper",
        "cache_utils": "django-cache-utils",
        "captcha": "django-recaptcha",
        "cartridge": "Cartridge",
        "cassandra": "cassandra-driver",
        "cassandralauncher": "CassandraLauncher",
        "cc42": "42qucc",
        "cerberus": "Cerberus",
        "cfnlint": "cfn-lint",
        "chameleon": "Chameleon",
        "charmtools": "charm-tools",
        "chef": "PyChef",
        "chip8": "c8d",
        "cjson": "python-cjson",
        "classytags": "django-classy-tags",
        "cloghandler": "ConcurrentLogHandler",
        "clonevirtualenv": "virtualenv-clone",
        "cloud-insight": "al-cloudinsight",
        "cloud_admin": "adminapi",
        "cloudservers": "python-cloudservers",
        "tasksitter": "cerebrod",
        "cms": "django-cms",
        "colander": "ba-colander",
        "colors": "ansicolors",
        "compile": "bf-lc3",
        "compose": "docker-compose",
        "compressor": "django-compressor",
        "concurrent": "futures",
        "configargparse": "ConfigArgParse",
        "contracts": "PyContracts",
        "weblogolib": "weblogo",
        "couchapp": "Couchapp",
        "couchdb": "CouchDB",
        "couchdbcurl": "couchdb-python-curl",
        "courseradownloader": "coursera-dl",
        "cow": "cow-framework",
        "creole": "python-creole",
        "creoleparser": "Creoleparser",
        "crispy_forms": "django-crispy-forms",
        "crontab": "python-crontab",
        "ctff": "tff",
        "cups": "pycups",
        "curator": "elasticsearch-curator",
        "curl": "pycurl",
        "daemon": "python-daemon",
        "dagger": "dagger-io",
        "dare": "DARE",
        "dateutil": "python-dateutil",
        "dawg": "DAWG",
        "debian": "python-debian",
        "decouple": "python-decouple",
        "demo": "webunit",
        "pysynth_samp": "PySynth",
        "deployer": "juju-deployer",
        "depot": "filedepot",
        "dgis": "2gis",
        "dhtmlparser": "pyDHTMLParser",
        "digitalocean": "python-digitalocean",
        "discord": "discord.py",
        "distribute_setup": "ez-setup",
        "distutils2": "Distutils2",
        "django": "Django",
        "django_hstore": "amitu-hstore",
        "djangobower": "django-bower",
        "djcelery": "django-celery",
        "djkombu": "django-kombu",
        "djorm_pgarray": "djorm-ext-pgarray",
        "dns": "dnspython",
        "docgen": "ansible-docgenerator",
        "docker": "docker-py",
        "dogpile": "dogpile.core",
        "dogshell": "dogapi",
        "dot_parser": "pydot3k",
        "dotenv": "python-dotenv",
        "dpkt": "dpkt-fix",
        "ldif": "python-ldap",
        "durationfield": "django-durationfield",
        "dzclient": "datazilla",
        "easybuild": "easybuild-framework",
        "editor": "python-editor",
        "elasticluster": "azure-elasticluster-current",
        "elftools": "pyelftools",
        "elixir": "Elixir",
        "ell": "ell-ai",
        "emlib": "empy",
        "enchant": "pyenchant",
        "encutils": "cssutils",
        "engineio": "python-engineio",
        "enum": "enum34",
        "ephem": "pyephem",
        "errorreporter": "abl.errorreporter",
        "esplot": "beaker-es-plot",
        "example": "adrest",
        "examples": "tweepy",
        "ez_setup": "pycassa",
        "fabric": "Fabric",
        "faker": "Faker",
        "fedora": "python-fedora",
        "fias": "ailove-django-fias",
        "fiftyone_degrees": "51degrees-mobile-detector",
        "five": "five.pt",
        "flasher": "android-flasher",
        "flask": "Flask",
        "flask_frozen": "Frozen-Flask",
        "flask_redis": "Flask-And-Redis",
        "flaskext": "Flask-Bcrypt",
        "flvscreen": "vnc2flv",
        "followit": "django-followit",
        "forge": "pyforge",
        "formencode": "FormEncode",
        "formtools": "django-formtools",
        "fourch": "4ch",
        "franz": "allegrordf",
        "freetype": "freetype-py",
        "frontmatter": "python-frontmatter",
        "ftpcloudfs": "ftp-cloudfs",
        "funtests": "librabbitmq",
        "fuse": "fusepy",
        "fuzzy": "Fuzzy",
        "gabbi": "tiddlyweb",
        "gen_3dwallet": "3d-wallet-generator",
        "gendimen": "android-gendimen",
        "genshi": "Genshi",
        "quadtree": "python-geohash",
        "geonode": "GeoNode",
        "geoserver": "gsconfig",
        "geraldo": "Geraldo",
        "getenv": "django-getenv",
        "geventwebsocket": "gevent-websocket",
        "gflags": "python-gflags",
        "git": "GitPython",
        "github": "PyGithub",
        "github3": "github3.py",
        "gitpy": "git-py",
        "globusonline": "globusonline-transfer-api-client",
        "google": "protobuf",
        "grace-dizmo": "grace-dizmo",
        "grammar": "anovelmous-grammar",
        "grapheneapi": "graphenelib",
        "greplin": "scales",
        "grokcore": "grokcore.component",
        "gslib": "gsutil",
        "hamcrest": "PyHamcrest",
        "harpy": "HARPy",
        "hawk": "PyHawk-with-a-single-extra-commit",
        "haystack": "django-haystack",
        "hgext": "mercurial",
        "hggit": "hg-git",
        "hglib": "python-hglib",
        "sx": "pisa",
        "hola": "amarokHola",
        "hoover": "Hoover",
        "hostlist": "python-hostlist",
        "htmloutput": "nosehtmloutput",
        "hvad": "django-hvad",
        "hydra": "hydra-core",
        "ibis": "ibis-framework[duckdb]",
        "i99fix": "199Fix",
        "igraph": "python-igraph",
        "imdb": "IMDbPY",
        "impala": "impyla",
        "inmemorystorage": "ambition-inmemorystorage",
        "ipaddress": "backport-ipaddress",
        "jaraco": "jaraco.util",
        "jinja2": "Jinja2",
        "jiracli": "jira-cli",
        "johnny": "johnny-cache",
        "jpypex": "JPype1",
        "jsonfield": "django-jsonfield",
        "jstools": "aino-jstools",
        "jupyterpip": "jupyter-pip",
        "jwt": "PyJWT",
        "kazoo": "asana-kazoo",
        "kernprof": "line-profiler",
        "keyczar": "python-keyczar",
        "keyedcache": "django-keyedcache",
        "keystoneclient": "python-keystoneclient",
        "kickstarter": "kickstart",
        "krbv": "krbV",
        "kss": "kss.core",
        "kuyruk": "Kuyruk",
        "langconv": "AdvancedLangConv",
        "lava": "lava-utils-interface",
        "lazr": "lazr.uri",
        "ldaplib": "adpasswd",
        "lib2or3": "2or3",
        "lib3to2": "3to2",
        "libaito": "Aito",
        "libbe": "bugs-everywhere",
        "libbucket": "bucket",
        "libcloud": "apache-libcloud",
        "winreg": "future",
        "libgenerateDS": "generateDS",
        "libmproxy": "mitmproxy",
        "libsvm": "7lk-ocr-deploy",
        "lisa": "lisa-server",
        "loadingandsaving": "aspose-words-java-for-python",
        "locust": "locustio",
        "logbook": "Logbook",
        "logentries": "buildbot-status-logentries",
        "logilab": "logilab-mtconverter",
        "magic": "python-magic",
        "mako": "Mako",
        "manifestparser": "ManifestDestiny",
        "marionette": "marionette-client",
        "markdown": "Markdown",
        "marks": "pytest-marks",
        "markupsafe": "MarkupSafe",
        "mavnative": "pymavlink",
        "memcache": "python-memcached",
        "metacomm": "AllPairs",
        "metaphone": "Metafone",
        "metlog": "metlog-py",
        "mezzanine": "Mezzanine",
        "migrate": "sqlalchemy-migrate",
        "mimeparse": "python-mimeparse",
        "minitage": "minitage.recipe.common",
        "missingdrawables": "android-missingdrawables",
        "mkrst_themes": "2lazy2rest",
        "mockredis": "mockredispy",
        "modargs": "python-modargs",
        "model_utils": "django-model-utils",
        "models": "asposestorage",
        "moksha": "moksha.wsgi",
        "moneyed": "py-moneyed",
        "mongoalchemy": "MongoAlchemy",
        "monthdelta": "MonthDelta",
        "mopidy": "Mopidy",
        "mopytools": "MoPyTools",
        "mptt": "django-mptt",
        "mpv": "python-mpv",
        "mrbob": "mr.bob",
        "msgpack": "msgpack-python",
        "mutations": "aino-mutations",
        "mws": "amazon-mws",
        "mysql": "mysql-connector-repackaged",
        "native_tags": "django-native-tags",
        "ndg": "ndg-httpsclient",
        "nereid": "trytond-nereid",
        "nested": "baojinhuan",
        "nester": "bssm-pythonSig",
        "novaclient": "python-novaclient",
        "oauth2_provider": "alauda-django-oauth",
        "oauth2client": "oauth2client",
        "odf": "odfpy",
        "ometa": "Parsley",
        "openid": "python-openid",
        "opensearchsdk": "ali-opensearch",
        "oslo_i18n": "oslo.i18n",
        "oslo_serialization": "oslo.serialization",
        "oslo_utils": "oslo.utils",
        "oss": "aliyunoss",
        "output": "cashew",
        "owslib": "OWSLib",
        "rackdiag": "nwdiag",
        "paho": "paho-mqtt",
        "paintstore": "django-paintstore",
        "parler": "django-parler",
        "paste": "PasteScript",
        "path": "path.py",
        "patricia": "patricia-trie",
        "paver": "Paver",
        "peak": "ProxyTypes",
        "picasso": "anderson.picasso",
        "picklefield": "django-picklefield",
        "pivotal": "pivotal-py",
        "pwiz": "peewee",
        "plivoxml": "plivo",
        "plone": "plone.z3cform",
        "plonetheme": "plonetheme.barceloneta",
        "png": "pypng",
        "polymorphic": "django-polymorphic",
        "postmark": "python-postmark",
        "powerprompt": "bash-powerprompt",
        "prefetch": "django-prefetch",
        "printList": "AndrewList",
        "progressbar": "progressbar33",
        "provider": "django-oauth2-provider",
        "puresasl": "pure-sasl",
        "py7zlib": "pylzma",
        "pyAMI": "pyAMI-core",
        "pyarsespyder": "arsespyder",
        "pyasdf": "asdf",
        "pyaspell": "aspell-python-ctypes",
        "pybb": "pybbm",
        "pybloomfilter": "pybloomfiltermmap",
        "pyccuracy": "Pyccuracy",
        "pyck": "PyCK",
        "pycrfsuite": "python-crfsuite",
        "pydispatch": "PyDispatcher",
        "pygeolib": "pygeocoder",
        "pygments": "Pygments",
        "pygraph": "python-graph-core",
        "pyjon": "pyjon.utils",
        "pyjsonrpc": "python-jsonrpc",
        "pykka": "Pykka",
        "pylogo": "PyLogo",
        "pylons": "adhocracy-Pylons",
        "pymagic": "libmagic",
        "pymycraawler": "Amalwebcrawler",
        "pynma": "AbakaffeNotifier",
        "pyphen": "Pyphen",
        "pyrimaa": "AEI",
        "pysqlite2": "pysqlite",
        "pythongettext": "python-gettext",
        "pythonjsonlogger": "python-json-logger",
        "pyutilib": "PyUtilib",
        "pyximport": "Cython",
        "qs": "qserve",
        "quickapi": "django-quickapi",
        "quickunit": "nose-quickunit",
        "radical": "radical.utils",
        "readability": "readability-lxml",
        "readline": "gnureadline",
        "recaptcha_works": "django-recaptcha-works",
        "relstorage": "RelStorage",
        "reportapi": "django-reportapi",
        "requests": "Requests",
        "requirements": "requirements-parser",
        "rest_framework": "djangorestframework",
        "restclient": "py-restclient",
        "retrial": "async-retrial",
        "reversion": "django-reversion",
        "rhaptos2": "rhaptos2.common",
        "robot": "robotframework",
        "robots": "django-robots",
        "rosdep2": "rosdep",
        "rsbackends": "RSFile",
        "ruamel": "ruamel.base",
        "xmlenc": "pysaml2",
        "saga": "saga-python",
        "samtranslator": "aws-sam-translator",
        "sassutils": "libsass",
        "sayhi": "alex-sayhi",
        "scalrtools": "scalr",
        "scikits": "scikits.talkbox",
        "scratch": "scratchpy",
        "scss": "pyScss",
        "sdict": "dict.sorted",
        "sdk_updater": "android-sdk-updater",
        "sekizai": "django-sekizai",
        "sendfile": "pysendfile",
        "serial": "pyserial",
        "setuputils": "astor",
        "shapefile": "pyshp",
        "shapely": "Shapely",
        "sika": "ahonya-sika",
        "singleton": "pysingleton",
        "skbio": "scikit-bio",
        "skimage": "scikit-image",
        "sklearn": "scikit-learn",
        "skvideo": "scikit-video",
        "slack": "slackclient",
        "slugify": "unicode-slugify",
        "smarkets": "smk-python-sdk",
        "snappy": "ctypes-snappy",
        "snowflake": "snowflake-connector-python",
        "socketio": "gevent-socketio",
        "sockjs": "sockjs-tornado",
        "socks": "SocksiPy-branch",
        "solr": "solrpy",
        "solution": "Solution",
        "sorl": "sorl-thumbnail",
        "south": "South",
        "sphinx": "Sphinx",
        "sphinx_pypi_upload": "ATD-document",
        "sphinxcontrib": "sphinxcontrib-programoutput",
        "sqlalchemy": "SQLAlchemy",
        "src": "auto-mix-prep",
        "stats_toolkit": "bw-stats-toolkit",
        "statsd": "dogstatsd-python",
        "stdnum": "python-stdnum",
        "stoneagehtml": "StoneageHTML",
        "storages": "django-storages",
        "stubout": "mox",
        "suds": "suds-jurko",
        "swiftclient": "python-swiftclient",
        "test": "pytabix",
        "taggit": "django-taggit",
        "tastypie": "django-tastypie",
        "teamcity": "teamcity-messages",
        "telebot": "pyTelegramBotAPI",
        "tempita": "Tempita",
        "tenjin": "Tenjin",
        "termstyle": "python-termstyle",
        "thclient": "treeherder-client",
        "threaded_multihost": "django-threaded-multihost",
        "threecolor": "3color-Press",
        "tidylib": "pytidylib",
        "tlw": "3lwg",
        "toredis": "toredis-fork",
        "tornadoredis": "tornado-redis",
        "tower_cli": "ansible-tower-cli",
        "tracopt": "Trac",
        "translation_helper": "android-localization-helper",
        "treebeard": "django-treebeard",
        "trytond": "trytond-stock",
        "tsuru": "tsuru-circus",
        "tvrage": "python-tvrage",
        "tw2": "tw2.sqla",
        "twisted": "Twisted",
        "twitter": "python-twitter",
        "txclib": "transifex-client",
        "u115": "115wangpan",
        "umap": "umap-learn",
        "unidecode": "Unidecode",
        "universe": "ansible-universe",
        "usb": "pyusb",
        "useless": "useless.pipes",
        "userpass": "auth-userpass",
        "utilities": "automakesetup.py",
        "utkik": "aino-utkik",
        "uwsgidecorators": "uWSGI",
        "valentine": "ab",
        "validate": "configobj",
        "version": "chartio",
        "virtualenvapi": "ar-virtualenv-api",
        "vyatta": "brocade-plugins",
        "webob": "WebOb",
        "websocket": "websocket-client",
        "webtest": "WebTest",
        "werkzeug": "Werkzeug",
        "wheezy": "wheezy.http",
        "wikklytext": "tiddlywebwiki",
        "winrm": "pywinrm",
        "workflow": "Alfred-Workflow",
        "wsmeext": "WSME",
        "wtforms": "WTForms",
        "wtfpeewee": "wtf-peewee",
        "xdg": "pyxdg",
        "xdist": "pytest-xdist",
        "xmpp": "xmpppy",
        "xstatic": "XStatic-jquery-ui",
        "yaml": "PyYAML",
        "z3c": "z3c.zcmlhook",
        "zmq": "pyzmq",
        "zopyx": "zopyx.textindexng3",
    }

#+END_SRC
** module_registry
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.packages.module_registry
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/packages/module_registry.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import importlib.util
import sys

from marimo._ast.cell import CellId_t
from marimo._runtime.dataflow import DirectedGraph

#+END_SRC
*** Function _is_module_installed
#+BEGIN_SRC python
def _is_module_installed(module_name: str) -> bool:
    # importlib.util.find_spec retrieves a module's ModuleSpec, which
    # is typically available as a dunder attribute on the module, i.e.
    # module.__spec__. However, some packages are non-compliant and don't
    # include a __spec__ attr (e.g., manim-slides), which can cause find_spec
    # to throw if the module has already been imported.
    #
    # We don't actually need the spec, we just need to see if a package is
    # available, so we first check if the module is in sys.modules without
    # checking for a __spec__ attr.
    return (
        module_name in sys.modules
        or importlib.util.find_spec(module_name) is not None
    )

#+END_SRC
*** Class ModuleRegistry
#+BEGIN_SRC python
class ModuleRegistry:
    def __init__(
        self, graph: DirectedGraph, excluded_modules: set[str] | None = None
    ) -> None:
        self.graph = graph
        # modules that do not have corresponding packages on package index
        self.excluded_modules = (
            excluded_modules if excluded_modules is not None else set()
        )

    def defining_cell(self, module_name: str) -> CellId_t | None:
        """Get the cell id of the cell importing module_name"""
        for cell_id, cell in self.graph.cells.items():
            if cell.namespace_to_variable(module_name) is not None:
                return cell_id
        return None

    def modules(self) -> set[str]:
        """Modules imported by cells."""
        return set(
            mod
            for cell in self.graph.cells.values()
            for mod in cell.imported_namespaces
        )

    def missing_modules(self) -> set[str]:
        """Modules that will fail to import."""
        return (
            set(mod for mod in self.modules() if not _is_module_installed(mod))
            - self.excluded_modules
        )

#+END_SRC
** package_manager
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.packages.package_manager
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/packages/package_manager.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import abc
import subprocess
from dataclasses import dataclass
from typing import List, Optional

from marimo import _loggers
from marimo._dependencies.dependencies import DependencyManager
from marimo._messaging.ops import Alert
from marimo._runtime.packages.utils import append_version

#+END_SRC
*** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
LOGGER = _loggers.marimo_logger()

#+END_SRC
*** @dataclass: Class PackageDescription
#+BEGIN_SRC python
@dataclass
class PackageDescription:
    name: str
    version: str

#+END_SRC
*** Class PackageManager
#+BEGIN_SRC python
class PackageManager(abc.ABC):
    """Interface for a package manager that can install packages."""

    name: str
    docs_url: str

    def __init__(self) -> None:
        self._attempted_packages: set[str] = set()

    @abc.abstractmethod
    def module_to_package(self, module_name: str) -> str:
        """Canonicalizes a module name to a package name."""
        ...

    @abc.abstractmethod
    def package_to_module(self, package_name: str) -> str:
        """Canonicalizes a package name to a module name."""
        ...

    def is_manager_installed(self) -> bool:
        """Is the package manager is installed on the user machine?"""
        if DependencyManager.which(self.name):
            return True
        LOGGER.error(
            f"{self.name} is not available. "
            f"Check out the docs for installation instructions: {self.docs_url}"  # noqa: E501
        )
        return False

    @abc.abstractmethod
    async def _install(self, package: str) -> bool:
        """Installation logic."""
        ...

    async def install(self, package: str, version: Optional[str]) -> bool:
        """Attempt to install a package that makes this module available.

        Returns True if installation succeeded, else False.
        """
        self._attempted_packages.add(package)
        return await self._install(append_version(package, version))

    @abc.abstractmethod
    async def uninstall(self, package: str) -> bool:
        """Attempt to uninstall a package

        Returns True if the package was uninstalled, else False.
        """
        ...

    def attempted_to_install(self, package: str) -> bool:
        """True iff package installation was previously attempted."""
        return package in self._attempted_packages

    def should_auto_install(self) -> bool:
        """Should this package manager auto-install packages"""
        return False

    def run(self, command: list[str]) -> bool:
        if not self.is_manager_installed():
            return False
        proc = subprocess.run(command)  # noqa: ASYNC101
        return proc.returncode == 0

    def update_notebook_script_metadata(
        self,
        filepath: str,
        *,
        packages_to_add: Optional[List[str]] = None,
        packages_to_remove: Optional[List[str]] = None,
        import_namespaces_to_add: Optional[List[str]] = None,
        import_namespaces_to_remove: Optional[List[str]] = None,
    ) -> None:
        del (
            filepath,
            packages_to_add,
            packages_to_remove,
            import_namespaces_to_add,
            import_namespaces_to_remove,
        )
        """
        Add or remove inline script metadata metadata
        in the marimo notebook.

        For packages_to_add, packages_to_remove, we use the package name as-is.
        For import_namespaces_to_add, import_namespaces_to_remove, we canonicalize
        to the module name based on popular packages on PyPI.

        This follows PEP 723 https://peps.python.org/pep-0723/
        """
        return

    @abc.abstractmethod
    def list_packages(self) -> List[PackageDescription]:
        """List installed packages."""
        ...

    def alert_not_installed(self) -> None:
        """Alert the user that the package manager is not installed."""
        Alert(
            title="Package manager not installed",
            description=(f"{self.name} is not available on your machine."),
            variant="danger",
        ).broadcast()

#+END_SRC
*** Class CanonicalizingPackageManager
#+BEGIN_SRC python
class CanonicalizingPackageManager(PackageManager):
    """Base class for package managers.

    Has a heuristic for mapping from package names to module names and back,
    using a registry of well-known packages and basic rules for package
    names.

    Subclasses needs to implement _construct_module_name_mapping.
    """

    def __init__(self) -> None:
        # Initialized lazily
        self._module_name_to_repo_name: dict[str, str] | None = None
        self._repo_name_to_module_name: dict[str, str] | None = None
        super().__init__()

    @abc.abstractmethod
    def _construct_module_name_mapping(self) -> dict[str, str]: ...

    def _initialize_mappings(self) -> None:
        if self._module_name_to_repo_name is None:
            self._module_name_to_repo_name = (
                self._construct_module_name_mapping()
            )

        if self._repo_name_to_module_name is None:
            self._repo_name_to_module_name = {
                v: k for k, v in self._module_name_to_repo_name.items()
            }

    def module_to_package(self, module_name: str) -> str:
        """Canonicalizes a module name to a package name on PyPI."""
        if self._module_name_to_repo_name is None:
            self._initialize_mappings()
        assert self._module_name_to_repo_name is not None

        if module_name in self._module_name_to_repo_name:
            return self._module_name_to_repo_name[module_name]
        else:
            return module_name.replace("_", "-")

    def package_to_module(self, package_name: str) -> str:
        """Canonicalizes a package name to a module name."""
        if self._repo_name_to_module_name is None:
            self._initialize_mappings()
        assert self._repo_name_to_module_name is not None

        return (
            self._repo_name_to_module_name[package_name]
            if package_name in self._repo_name_to_module_name
            else package_name.replace("-", "_")
        )

#+END_SRC
** package_managers
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.packages.package_managers
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/packages/package_managers.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from marimo._runtime.packages.conda_package_manager import PixiPackageManager
from marimo._runtime.packages.package_manager import PackageManager
from marimo._runtime.packages.pypi_package_manager import (
    MicropipPackageManager,
    PipPackageManager,
    PoetryPackageManager,
    RyePackageManager,
    UvPackageManager,
)
from marimo._utils.platform import is_pyodide

#+END_SRC
*** Assignment PACKAGE_MANAGERS
#+BEGIN_SRC python
PACKAGE_MANAGERS = {
    MicropipPackageManager.name: MicropipPackageManager,
    PipPackageManager.name: PipPackageManager,
    RyePackageManager.name: RyePackageManager,
    UvPackageManager.name: UvPackageManager,
    PoetryPackageManager.name: PoetryPackageManager,
    PixiPackageManager.name: PixiPackageManager,
}

#+END_SRC
*** Function create_package_manager
#+BEGIN_SRC python
def create_package_manager(name: str) -> PackageManager:
    if is_pyodide():
        # user config has name "pip", but micropip's name is "micropip" ...
        return MicropipPackageManager()

    if name in PACKAGE_MANAGERS:
        return PACKAGE_MANAGERS[name]()  # type:ignore[abstract]
    raise RuntimeError(
        f"Unknown package manager {name}. "
        "This is a bug in marimo."
        "Please file an issue: "
        "https://github.com/marimo-team/marimo/issues"
    )

#+END_SRC
** pypi_package_manager
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.packages.pypi_package_manager
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/packages/pypi_package_manager.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import json
import subprocess
import sys
from typing import List, Optional

from marimo._runtime.packages.module_name_to_pypi_name import (
    module_name_to_pypi_name,
)
from marimo._runtime.packages.package_manager import (
    CanonicalizingPackageManager,
    PackageDescription,
)
from marimo._runtime.packages.utils import split_packages
from marimo._utils.platform import is_pyodide

#+END_SRC
*** Assignment PY_EXE = sys.executable
#+BEGIN_SRC python
PY_EXE = sys.executable

#+END_SRC
*** Class PypiPackageManager
#+BEGIN_SRC python
class PypiPackageManager(CanonicalizingPackageManager):
    def _construct_module_name_mapping(self) -> dict[str, str]:
        return module_name_to_pypi_name()

    def _list_packages_from_cmd(
        self, cmd: List[str]
    ) -> List[PackageDescription]:
        if not self.is_manager_installed():
            return []
        proc = subprocess.run(cmd, capture_output=True, text=True)
        if proc.returncode != 0:
            return []
        try:
            packages = json.loads(proc.stdout)
            return [
                PackageDescription(name=pkg["name"], version=pkg["version"])
                for pkg in packages
            ]
        except json.JSONDecodeError:
            return []

#+END_SRC
*** Class PipPackageManager
#+BEGIN_SRC python
class PipPackageManager(PypiPackageManager):
    name = "pip"
    docs_url = "https://pip.pypa.io/"

    async def _install(self, package: str) -> bool:
        return self.run(
            ["pip", "--python", PY_EXE, "install", *split_packages(package)]
        )

    async def uninstall(self, package: str) -> bool:
        return self.run(
            [
                "pip",
                "--python",
                PY_EXE,
                "uninstall",
                "-y",
                *split_packages(package),
            ]
        )

    def list_packages(self) -> List[PackageDescription]:
        cmd = ["pip", "--python", PY_EXE, "list", "--format=json"]
        return self._list_packages_from_cmd(cmd)

#+END_SRC
*** Class MicropipPackageManager
#+BEGIN_SRC python
class MicropipPackageManager(PypiPackageManager):
    name = "micropip"
    docs_url = "https://micropip.pyodide.org/"

    def should_auto_install(self) -> bool:
        return True

    def is_manager_installed(self) -> bool:
        return is_pyodide()

    async def _install(self, package: str) -> bool:
        assert is_pyodide()
        import micropip  # type: ignore

        try:
            await micropip.install(split_packages(package))
            return True
        except ValueError:
            return False

    async def uninstall(self, package: str) -> bool:
        assert is_pyodide()
        import micropip  # type: ignore

        try:
            micropip.uninstall(package)
            return True
        except ValueError:
            return False

    def list_packages(self) -> List[PackageDescription]:
        assert is_pyodide()
        import micropip  # type: ignore

        packages = [
            PackageDescription(name=pkg.name, version=pkg.version)
            for pkg in micropip.list()
        ]
        # micropip doesn't sort the packages
        return sorted(packages, key=lambda pkg: pkg.name)

    def check_available(self) -> bool:
        return is_pyodide()

#+END_SRC
*** Class UvPackageManager
#+BEGIN_SRC python
class UvPackageManager(PypiPackageManager):
    name = "uv"
    docs_url = "https://docs.astral.sh/uv/"

    async def _install(self, package: str) -> bool:
        return self.run(
            ["uv", "pip", "install", *split_packages(package), "-p", PY_EXE]
        )

    def update_notebook_script_metadata(
        self,
        filepath: str,
        *,
        packages_to_add: Optional[List[str]] = None,
        packages_to_remove: Optional[List[str]] = None,
        import_namespaces_to_add: Optional[List[str]] = None,
        import_namespaces_to_remove: Optional[List[str]] = None,
    ) -> None:
        packages_to_add = packages_to_add or []
        packages_to_remove = packages_to_remove or []
        import_namespaces_to_add = import_namespaces_to_add or []
        import_namespaces_to_remove = import_namespaces_to_remove or []

        packages_to_add = packages_to_add + [
            self.module_to_package(im) for im in import_namespaces_to_add
        ]
        packages_to_remove = packages_to_remove + [
            self.module_to_package(im) for im in import_namespaces_to_remove
        ]

        if not packages_to_add and not packages_to_remove:
            return

        version_map = self._get_version_map()

        def _is_installed(package: str) -> bool:
            without_brackets = package.split("[")[0]
            return without_brackets.lower() in version_map

        def _maybe_add_version(package: str) -> str:
            # Skip marimo
            if package == "marimo":
                return package
            without_brackets = package.split("[")[0]
            version = version_map.get(without_brackets.lower())
            if version:
                return f"{package}=={version}"
            return package

        # Filter to packages that are found in "uv pip list"
        packages_to_add = [
            _maybe_add_version(im)
            for im in packages_to_add
            if _is_installed(im)
        ]

        if packages_to_add:
            self.run(
                ["uv", "--quiet", "add", "--script", filepath]
                + packages_to_add
            )
        if packages_to_remove:
            self.run(
                ["uv", "--quiet", "remove", "--script", filepath]
                + packages_to_remove
            )

    def _get_version_map(self) -> dict[str, str]:
        packages = self.list_packages()
        return {pkg.name: pkg.version for pkg in packages}

    async def uninstall(self, package: str) -> bool:
        return self.run(
            ["uv", "pip", "uninstall", *split_packages(package), "-p", PY_EXE]
        )

    def list_packages(self) -> List[PackageDescription]:
        cmd = ["uv", "pip", "list", "--format=json", "-p", PY_EXE]
        return self._list_packages_from_cmd(cmd)

#+END_SRC
*** Class RyePackageManager
#+BEGIN_SRC python
class RyePackageManager(PypiPackageManager):
    name = "rye"
    docs_url = "https://rye.astral.sh/"

    async def _install(self, package: str) -> bool:
        return self.run(["rye", "add", *split_packages(package)])

    async def uninstall(self, package: str) -> bool:
        return self.run(["rye", "remove", *split_packages(package)])

    def list_packages(self) -> List[PackageDescription]:
        cmd = ["rye", "list", "--format=json"]
        return self._list_packages_from_cmd(cmd)

#+END_SRC
*** Class PoetryPackageManager
#+BEGIN_SRC python
class PoetryPackageManager(PypiPackageManager):
    name = "poetry"
    docs_url = "https://python-poetry.org/docs/"

    async def _install(self, package: str) -> bool:
        return self.run(
            ["poetry", "add", "--no-interaction", *split_packages(package)]
        )

    async def uninstall(self, package: str) -> bool:
        return self.run(
            ["poetry", "remove", "--no-interaction", *split_packages(package)]
        )

    def _list_packages_from_cmd(
        self, cmd: List[str]
    ) -> List[PackageDescription]:
        if not self.is_manager_installed():
            return []
        proc = subprocess.run(cmd, capture_output=True, text=True)
        if proc.returncode != 0:
            return []

        # Each line in package_lines is of the form
        # package_name    version_string      some more arbitrary text
        #
        # For each line, extract the package_name and version_string, ignoring
        # the rest of the text.
        package_lines = proc.stdout.splitlines()
        packages = []
        for line in package_lines:
            parts = line.split()
            if len(parts) < 2:
                continue
            packages.append(
                PackageDescription(name=parts[0], version=parts[1])
            )
        return packages

    def list_packages(self) -> List[PackageDescription]:
        cmd = ["poetry", "show", "--no-dev"]
        return self._list_packages_from_cmd(cmd)

#+END_SRC
** utils
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.packages.utils
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/packages/utils.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import os
import sys
from typing import List, Optional

from marimo._utils.platform import is_pyodide

#+END_SRC
*** Function in_virtual_environment
#+BEGIN_SRC python
def in_virtual_environment() -> bool:
    """Returns True if a venv/virtualenv is activated"""
    # https://stackoverflow.com/questions/1871549/how-to-determine-if-python-is-running-inside-a-virtualenv/40099080#40099080  # noqa: E501
    base_prefix = (
        getattr(sys, "base_prefix", None)
        or getattr(sys, "real_prefix", None)
        or sys.prefix
    )
    return sys.prefix != base_prefix

#+END_SRC
*** Function in_conda_env
#+BEGIN_SRC python
def in_conda_env() -> bool:
    return "CONDA_DEFAULT_ENV" in os.environ

#+END_SRC
*** Function is_dockerized
#+BEGIN_SRC python
def is_dockerized() -> bool:
    return os.path.exists("/.dockerenv")

#+END_SRC
*** Function is_python_isolated
#+BEGIN_SRC python
def is_python_isolated() -> bool:
    """Returns True if not using system Python"""
    return (
        in_virtual_environment()
        or in_conda_env()
        or is_pyodide()
        or is_dockerized()
    )

#+END_SRC
*** Function append_version
#+BEGIN_SRC python
def append_version(pkg_name: str, version: Optional[str]) -> str:
    """Qualify a version string with a leading '==' if it doesn't have one"""
    if version is None:
        return pkg_name
    if version == "":
        return pkg_name
    if version == "latest":
        return pkg_name
    return f"{pkg_name}=={version}"

#+END_SRC
*** Function split_packages
#+BEGIN_SRC python
def split_packages(package: str) -> List[str]:
    """
    Splits a package string into a list of packages.

    This can handle editable packages (i.e. local directories)

    e.g.
    "package1[extra1,extra2]==1.0.0" -> ["package1[extra1,extra2]==1.0.0"]
    "package1 package2" -> ["package1", "package2"]
    "package1==1.0.0 package2==2.0.0" -> ["package1==1.0.0", "package2==2.0.0"]
    "package1 -e /path/to/package1" -> ["package1 -e /path/to/package1"]
    "package1 --editable /path/to/package1" -> ["package1 --editable /path/to/package1"]
    "package1 -e /path/to/package1 package2" -> ["package1 -e /path/to/package1", "package2"]
    "package1 @ /path/to/package1" -> ["package1 @ /path/to/package1"]
    "foo==1.0; python_version>'3.6' bar==2.0; sys_platform=='win32'" -> ["foo==1.0; python_version>'3.6'", "bar==2.0; sys_platform=='win32'"]
    """  # noqa: E501
    packages: List[str] = []
    current_package: List[str] = []
    in_environment_marker = False

    for part in package.split():
        if part in ["-e", "--editable", "@"]:
            current_package.append(part)
        elif current_package and current_package[-1] in [
            "-e",
            "--editable",
            "@",
        ]:
            current_package.append(part)
        elif part.endswith(";"):
            if current_package:
                packages.append(" ".join(current_package))
                current_package = []
            in_environment_marker = True
            current_package.append(part)
        elif in_environment_marker:
            current_package.append(part)
            if part.endswith("'") or part.endswith('"'):
                in_environment_marker = False
                packages.append(" ".join(current_package))
                current_package = []
        else:
            if current_package:
                packages.append(" ".join(current_package))
            current_package = [part]

    if current_package:
        packages.append(" ".join(current_package))

    return [pkg.strip() for pkg in packages]

#+END_SRC
* reload
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.reload
:END:
** __init__
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.reload.__init__
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/reload/__init__.py
:END:
*** Comment
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.

#+END_SRC
** Module reloader
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.reload.autoreload
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/reload/autoreload.py
:END:
*** Docstring
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
"""Module reloader

In addition to reloading modules, the reloader also patches instances
of reloaded objects with their code.

Based on the autoreload extension from the IPython project (BSD-3 Clause).
"""

#+END_SRC
*** Import statements
#+BEGIN_SRC python
from __future__ import annotations

import gc
import io
import modulefinder
import os
import sys
import threading
import traceback
import types
import warnings
import weakref
from dataclasses import dataclass
from importlib import reload
from importlib.util import source_from_cache
from typing import Any, Callable, Dict, Generic, List, Tuple, Type, TypeVar

from marimo import _loggers
from marimo._ast.cell import CellImpl
from marimo._messaging.tracebacks import write_traceback

#+END_SRC
*** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
LOGGER = _loggers.marimo_logger()

#+END_SRC
*** Assignment func_attrs
#+BEGIN_SRC python
func_attrs = [
    "__code__",
    "__defaults__",
    "__doc__",
    "__closure__",
    "__globals__",
    "__dict__",
]

#+END_SRC
*** @dataclass: Class ModuleMTime
#+BEGIN_SRC python
@dataclass
class ModuleMTime:
    name: str
    mtime: float

#+END_SRC
*** Assignment OldObjectsMapping
#+BEGIN_SRC python
# (module-name, name) -> weakref, for replacing old code objects
OldObjectsMapping = Dict[
    Tuple[str, str], List[weakref.ref]  # type:ignore[type-arg]
]

#+END_SRC
*** Function modules_imported_by_cell
#+BEGIN_SRC python
def modules_imported_by_cell(
    cell: CellImpl, sys_modules: dict[str, types.ModuleType]
) -> set[str]:
    """Get the modules imported by a cell"""
    modules = set()
    for import_data in cell.imports:
        if import_data.module in sys_modules:
            modules.add(import_data.module)
        if import_data.imported_symbol in sys_modules:
            # The imported symbol may or may not be a module, which
            # is why we check if it's in sys.modules
            #
            # e.g., from a import b
            #
            # a.b could be a module, but it could also be a function, ...
            modules.add(import_data.imported_symbol)
    return modules

#+END_SRC
*** Class ModuleDependencyFinder
#+BEGIN_SRC python
class ModuleDependencyFinder:
    def __init__(self) -> None:
        # __file__ ->
        self._module_dependencies: dict[str, dict[str, types.ModuleType]] = {}
        self._failed_module_filenames: set[str] = set()

    def find_dependencies(
        self, module: types.ModuleType, excludes: list[str]
    ) -> dict[str, types.ModuleType]:
        if not hasattr(module, "__file__") or module.__file__ is None:
            return {}

        file = module.__file__
        if module.__file__ in self._failed_module_filenames:
            return {}

        if file in self._module_dependencies:
            return self._module_dependencies[file]

        finder = modulefinder.ModuleFinder(excludes=excludes)
        try:
            with warnings.catch_warnings():
                # We temporarily ignore warnings to avoid spamming the console,
                # since the watcher runs in a loop
                warnings.simplefilter("ignore")
                finder.run_script(module.__file__)
        except SyntaxError:
            # user introduced a syntax error, maybe; still check if the
            # module itself has been modified
            return {}
        except Exception:
            # some modules like numpy fail when called with run_script;
            # run_script takes a long time before failing on them, so
            # don't try to analyze them again
            self._failed_module_filenames.add(file)
            return {}
        else:
            # False positives
            self._module_dependencies[file] = finder.modules  # type: ignore[assignment]
            return finder.modules  # type: ignore[return-value]

    def cached(self, module: types.ModuleType) -> bool:
        if not hasattr(module, "__file__") or module.__file__ is None:
            return False

        return module.__file__ in self._module_dependencies

    def evict_from_cache(self, module: types.ModuleType) -> None:
        file = module.__file__
        if file in self._module_dependencies:
            del self._module_dependencies[file]

#+END_SRC
*** Class ModuleReloader
#+BEGIN_SRC python
class ModuleReloader:
    """Thread-safe module reloader."""

    def __init__(self) -> None:
        # Modules that failed to reload: {module: mtime-on-failed-reload, ...}
        self.failed: dict[str, float] = {}
        # For replacing old code objects
        self.old_objects: OldObjectsMapping = {}
        # module-name -> mtime (module modification timestamps)
        self.modules_mtimes: dict[str, float] = {}
        # set of modules names known to be stale but haven't been reloaded
        self.stale_modules: set[str] = set()
        # for thread-safety
        self.lock = threading.Lock()
        self._module_dependency_finder = ModuleDependencyFinder()

        # Timestamp existing modules
        self.check(modules=sys.modules, reload=False)

    def filename_and_mtime(
        self, module: types.ModuleType
    ) -> ModuleMTime | None:
        if not hasattr(module, "__file__") or module.__file__ is None:
            return None

        if getattr(module, "__name__", None) in [
            None,
            "__mp_main__",
            "__main__",
            "sys",
            "builtins",
        ]:
            # we cannot reload(__main__) or reload(__mp_main__);
            # Python advises against reloading sys and builtins
            return None

        filename = module.__file__
        _, ext = os.path.splitext(filename)

        if ext.lower() == ".py":
            py_filename = filename
        else:
            try:
                py_filename = source_from_cache(filename)
            except ValueError:
                return None

        try:
            pymtime = os.stat(py_filename).st_mtime
        except OSError:
            return None
        return ModuleMTime(py_filename, pymtime)

    def cell_uses_stale_modules(self, cell: CellImpl) -> bool:
        with self.lock:
            return bool(
                self.stale_modules
                & modules_imported_by_cell(cell, sys.modules)
            )

    def check(
        self, modules: dict[str, types.ModuleType], reload: bool
    ) -> set[types.ModuleType]:
        """Check timestamps of modules, optionally reload them.

        Also patches existing objects with hot-reloaded ones.

        Returns a set of modules that were found to have been modified.
        """

        # module watcher thread and kernel thread might try to use the
        # reloader at the same time, but reloader mutates state
        #
        # Holds a lock because this method modifies stale_modules
        # and also iterates over it
        with self.lock:
            modified_modules: set[types.ModuleType] = set()
            # materialize the module keys, since we'll be reloading while
            # iterating
            for modname in list(modules.keys()):
                m = modules.get(modname, None)
                if m is None:
                    continue

                module_mtime = self.filename_and_mtime(m)
                if module_mtime is None:
                    continue
                py_filename, pymtime = module_mtime.name, module_mtime.mtime

                try:
                    if pymtime <= self.modules_mtimes[modname]:
                        continue
                except KeyError:
                    self.modules_mtimes[modname] = pymtime
                    continue
                else:
                    if self.failed.get(py_filename, None) == pymtime:
                        continue

                self.modules_mtimes[modname] = pymtime
                modified_modules.add(m)
                self.stale_modules.add(modname)
                self._module_dependency_finder.evict_from_cache(m)

            if not reload:
                return modified_modules

            for modname in self.stale_modules:
                # Reload after the check loop: if there are any
                # previously discovered stale modules, reload those as well
                m = modules.get(modname, None)
                if m is None:
                    continue

                module_mtime = self.filename_and_mtime(m)
                if module_mtime is None:
                    continue
                py_filename, pymtime = module_mtime.name, module_mtime.mtime

                LOGGER.debug(f"Reloading '{modname}'.")
                try:
                    superreload(m, self.old_objects)
                    if py_filename in self.failed:
                        del self.failed[py_filename]
                except Exception:
                    msg = "[autoreload of {} failed: {}]"
                    LOGGER.debug(
                        msg.format(modname, traceback.format_exc(10)),
                    )
                    self.failed[py_filename] = pymtime
                else:
                    # TODO or always evict?
                    self._module_dependency_finder.evict_from_cache(m)

            self.stale_modules.clear()
        return modified_modules

    def get_module_dependencies(
        self, module: types.ModuleType, excludes: list[str]
    ) -> dict[str, types.ModuleType]:
        return self._module_dependency_finder.find_dependencies(
            module, excludes
        )

#+END_SRC
*** Function update_function
#+BEGIN_SRC python
def update_function(old: object, new: object) -> None:
    """Upgrade the code object of a function"""
    for name in func_attrs:
        try:
            setattr(old, name, getattr(new, name))
        except (AttributeError, TypeError):
            pass

#+END_SRC
*** Function update_instances
#+BEGIN_SRC python
def update_instances(old: object, new: object) -> None:
    """Use garbage collector to find all instances that refer to the old
    class definition and update their __class__ to point to the new class
    definition"""

    refs = gc.get_referrers(old)

    for ref in refs:
        if type(ref) is old:
            object.__setattr__(ref, "__class__", new)

#+END_SRC
*** Function update_class
#+BEGIN_SRC python
def update_class(old: object, new: object) -> None:
    """Replace stuff in the __dict__ of a class, and upgrade
    method code objects, and add new methods, if any"""
    for key in list(old.__dict__.keys()):
        old_obj = getattr(old, key)
        new_obj: object | None = None
        try:
            new_obj = getattr(new, key)
            # explicitly checking that comparison returns True to handle
            # cases where `==` doesn't return a boolean.
            if (old_obj == new_obj) is True:
                continue
        except AttributeError:
            # obsolete attribute: remove it
            try:
                delattr(old, key)
            except (AttributeError, TypeError):
                pass
            continue
        except ValueError:
            # can't compare nested structures containing
            # numpy arrays using `==`
            pass

        if new_obj is None or update_generic(old_obj, new_obj):
            continue

        try:
            setattr(old, key, getattr(new, key))
        except (AttributeError, TypeError):
            pass  # skip non-writable attributes

    for key in list(new.__dict__.keys()):
        if key not in list(old.__dict__.keys()):
            try:
                setattr(old, key, getattr(new, key))
            except (AttributeError, TypeError):
                pass  # skip non-writable attributes

    # update all instances of class
    update_instances(old, new)

#+END_SRC
*** Function update_property
#+BEGIN_SRC python
def update_property(old: object, new: object) -> None:
    """Replace get/set/del functions of a property"""
    update_generic(old.fdel, new.fdel)  # type:ignore[attr-defined]
    update_generic(old.fget, new.fget)  # type:ignore[attr-defined]
    update_generic(old.fset, new.fset)  # type:ignore[attr-defined]

#+END_SRC
*** Function isinstance2
#+BEGIN_SRC python
def isinstance2(a: object, b: object, typ: Type[Any]) -> bool:
    return isinstance(a, typ) and isinstance(b, typ)

#+END_SRC
*** Assignment UPDATE_RULES
#+BEGIN_SRC python
UPDATE_RULES: list[
    tuple[Callable[[object, object], bool], Callable[[object, object], None]]
] = [
    (lambda a, b: isinstance2(a, b, type), update_class),
    (lambda a, b: isinstance2(a, b, types.FunctionType), update_function),
    (lambda a, b: isinstance2(a, b, property), update_property),
]

#+END_SRC
*** Call UPDATE_RULES.extend
#+BEGIN_SRC python
UPDATE_RULES.extend(
    [
        (
            lambda a, b: isinstance2(a, b, types.MethodType),
            lambda a, b: update_function(a.__func__, b.__func__),  # type: ignore[attr-defined]  # noqa: E501
        ),
    ]
)

#+END_SRC
*** Function update_generic
#+BEGIN_SRC python
def update_generic(a: object, b: object) -> bool:
    for type_check, update in UPDATE_RULES:
        if type_check(a, b):
            update(a, b)
            return True
    return False

#+END_SRC
*** Assignment T = TypeVar("T")
#+BEGIN_SRC python
T = TypeVar("T")

#+END_SRC
*** Class StrongRef
#+BEGIN_SRC python
class StrongRef(Generic[T]):
    def __init__(self, obj: T) -> None:
        self.obj = obj

    def __call__(self) -> T:
        return self.obj

#+END_SRC
*** Function append_obj
#+BEGIN_SRC python
def append_obj(
    module: types.ModuleType,
    d: OldObjectsMapping,
    # object name
    name: str,
    obj: object,
) -> bool:
    in_module = (
        hasattr(obj, "__module__") and obj.__module__ == module.__name__
    )
    if not in_module:
        return False

    key = (module.__name__, name)
    try:
        d.setdefault(key, []).append(weakref.ref(obj))
    except TypeError:
        pass
    return True

#+END_SRC
*** Function superreload
#+BEGIN_SRC python
def superreload(
    module: types.ModuleType, old_objects: OldObjectsMapping | None
) -> types.ModuleType:
    """Enhanced version of the builtin reload function.

    superreload remembers objects previously in the module, and

    - upgrades the class dictionary of every old class in the module
    - upgrades the code object of every old function and method
    - clears the module's namespace before reloading

    """
    if old_objects is None:
        old_objects = {}

    # collect old objects in the module
    for name, obj in list(module.__dict__.items()):
        if not append_obj(module, old_objects, name, obj):
            continue
        key = (module.__name__, name)
        try:
            old_objects.setdefault(key, []).append(weakref.ref(obj))
        except TypeError:
            pass

    # reload module
    old_dict: dict[str, Any] | None = None
    try:
        # clear namespace first from old cruft
        old_dict = module.__dict__.copy()
        old_name = module.__name__
        module.__dict__.clear()
        module.__dict__["__name__"] = old_name
        module.__dict__["__loader__"] = old_dict["__loader__"]
    except (TypeError, AttributeError, KeyError):
        pass

    try:
        module = reload(module)
    except Exception as e:
        # User introduced a SyntaxError, ModuleNotFoundError, etc -- they
        # should be told, and module dict should not be restored, ie don't fail
        # silently.
        #
        # It's possible that the module fails to reload for some other reason.
        # In this case, too, the failure shouldn't be silent!
        sys.stderr.write(
            f"Error trying to reload module {module.__name__}: {str(e)} \n"
        )
        tmpio = io.StringIO()
        traceback.print_exc(file=tmpio)
        tmpio.seek(0)
        write_traceback(tmpio.read())
        raise

    # iterate over all objects and update functions & classes
    for name, new_obj in list(module.__dict__.items()):
        key = (module.__name__, name)
        if key not in old_objects:
            continue

        new_refs = []
        for old_ref in old_objects[key]:
            old_obj = old_ref()
            if old_obj is None:
                continue
            new_refs.append(old_ref)
            update_generic(old_obj, new_obj)

        if new_refs:
            old_objects[key] = new_refs
        else:
            del old_objects[key]

    return module

#+END_SRC
** module_watcher
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.reload.module_watcher
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/reload/module_watcher.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import itertools
import pathlib
import sys
import threading
import time
from typing import TYPE_CHECKING, Callable, Literal

from marimo import _loggers
from marimo._messaging.types import Stream
from marimo._runtime import dataflow
from marimo._runtime.reload.autoreload import (
    ModuleReloader,
    modules_imported_by_cell,
)

#+END_SRC
*** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
if TYPE_CHECKING:
    import types

    from marimo._ast.cell import CellId_t

LOGGER = _loggers.marimo_logger()

#+END_SRC
*** Function is_submodule
#+BEGIN_SRC python
def is_submodule(src_name: str, target_name: str) -> bool:
    """Returns True if src_name is a parent of target_name

    eg: "marimo.plugins" is a parent of "marimo.plugins.ui", returns True
    """
    src_parts = src_name.split(".")
    target_parts = target_name.split(".")
    if len(src_parts) > len(target_parts):
        return False
    return all(src_parts[i] == target_parts[i] for i in range(len(src_parts)))

#+END_SRC
*** Function _depends_on
#+BEGIN_SRC python
def _depends_on(
    src_module: types.ModuleType,
    target_modules: set[types.ModuleType],
    excludes: list[str],
    reloader: ModuleReloader,
) -> bool:
    """Returns whether src_module depends on any of target_filenames"""
    if src_module in target_modules:
        return True

    module_dependencies = reloader.get_module_dependencies(
        src_module, excludes=excludes
    )

    target_filenames = set(
        t.__file__ for t in target_modules if hasattr(t, "__file__")
    )
    for found_module in itertools.chain(
        [src_module], module_dependencies.values()
    ):
        file = getattr(found_module, "__file__", None)
        if file is None:
            continue

        # easy case: a discovered module was directly modified
        if file in target_filenames:
            return True

        # if a discovered module is a package, check if any of the modified
        # modules are contained in that package
        if file.endswith("__init__.py") and any(
            is_submodule(src_module.__name__, target_module.__name__)
            for target_module in target_modules
        ):
            return True

    return False

#+END_SRC
*** Function _is_third_party_module
#+BEGIN_SRC python
def _is_third_party_module(module: types.ModuleType) -> bool:
    filepath = getattr(module, "__file__", None)
    if filepath is None:
        return False
    return "site-packages" in pathlib.Path(filepath).parts

#+END_SRC
*** Function _get_excluded_modules
#+BEGIN_SRC python
def _get_excluded_modules(modules: dict[str, types.ModuleType]) -> list[str]:
    return [
        modname
        for modname in modules
        if (m := modules.get(modname)) is not None
        and _is_third_party_module(m)
    ]

#+END_SRC
*** Function _check_modules
#+BEGIN_SRC python
def _check_modules(
    modules: dict[str, types.ModuleType],
    reloader: ModuleReloader,
    sys_modules: dict[str, types.ModuleType],
) -> dict[str, types.ModuleType]:
    """Returns the set of modules used by the graph that have been modified"""
    stale_modules: dict[str, types.ModuleType] = {}
    modified_modules = reloader.check(modules=sys_modules, reload=False)
    # TODO(akshayka): could also exclude modules part of the standard library;
    # haven't found a reliable way to do this, however.
    excludes = _get_excluded_modules(sys_modules)
    for modname, module in modules.items():
        if _depends_on(
            src_module=module,
            target_modules=set(m for m in modified_modules if m is not None),
            excludes=excludes,
            reloader=reloader,
        ):
            stale_modules[modname] = module
    return stale_modules

#+END_SRC
*** Function watch_modules
#+BEGIN_SRC python
def watch_modules(
    graph: dataflow.DirectedGraph,
    reloader: ModuleReloader,
    mode: Literal["lazy", "autorun"],
    enqueue_run_stale_cells: Callable[[], None],
    should_exit: threading.Event,
    run_is_processed: threading.Event,
    stream: Stream,
) -> None:
    """Watches for changes to modules used by graph

    The modules used by the graph are determined statically, by analyzing the
    modules imported by the notebook as well as the modules imported by those
    modules, recursively.
    """
    # work with a copy to avoid race conditions
    # in CPython, dict.copy() is atomic
    sys_modules = sys.modules.copy()
    while not should_exit.is_set():
        # Collect the modules used by each cell
        modules: dict[str, types.ModuleType] = {}
        modname_to_cell_id: dict[str, CellId_t] = {}
        with graph.lock:
            for cell_id, cell in graph.cells.items():
                for modname in modules_imported_by_cell(cell, sys_modules):
                    if modname in sys_modules:
                        modules[modname] = sys_modules[modname]
                        modname_to_cell_id[modname] = cell_id

        stale_modules = _check_modules(
            modules=modules,
            reloader=reloader,
            sys_modules=sys_modules,
        )

        if stale_modules:
            LOGGER.debug(
                "Found stale modules; acquiring lock to update graph."
            )
            with graph.lock:
                LOGGER.debug("Acquired graph lock.")
                for modname in stale_modules.keys():
                    # prune definitions that are derived from stale modules
                    cell = graph.cells[modname_to_cell_id[modname]]
                    defs_to_prune = [
                        import_data.definition
                        for import_data in cell.imports
                        if import_data.module == modname
                    ]
                    cell.import_workspace.imported_defs -= set(defs_to_prune)

                # If any modules are stale, communicate that to the FE
                # and update the backend's view of the importing cells'
                # staleness
                stale_cell_ids = dataflow.transitive_closure(
                    graph,
                    set(
                        modname_to_cell_id[modname]
                        for modname in stale_modules
                    ),
                    relatives=dataflow.import_block_relatives,
                )
                for cid in stale_cell_ids:
                    graph.cells[cid].set_stale(stale=True, stream=stream)
            LOGGER.debug("Released graph lock and updated stale statuses.")

            if mode == "autorun":
                run_is_processed.clear()
                enqueue_run_stale_cells()

        # Don't proceed until enqueue_run_stale_cells() has been processed,
        # ie until stale cells have been rerun
        run_is_processed.wait()
        time.sleep(1)
        # Update our snapshot of sys.modules
        sys_modules = sys.modules.copy()

#+END_SRC
*** Class ModuleWatcher
#+BEGIN_SRC python
class ModuleWatcher:
    def __init__(
        self,
        graph: dataflow.DirectedGraph,
        reloader: ModuleReloader,
        mode: Literal["lazy", "autorun"],
        enqueue_run_stale_cells: Callable[[], None],
        stream: Stream,
    ) -> None:
        # ModuleWatcher uses the graph to determine the modules used by the
        # notebook
        self.graph = graph
        # Reloader is used to keep track of stale modules
        self.reloader = reloader
        # When set, signals the watcher thread to exit
        self.should_exit = threading.Event()
        # When False, an ExecuteStaleRequest is inflight to the kernel
        self.run_is_processed = threading.Event()
        self.run_is_processed.set()
        # To communicate staleness to the FE
        self.stream = stream
        # If autorun, stale cells are automatically scheduled for execution
        self.mode = mode
        # A callable that signals the kernel to run stale cells
        self.enqueue_run_stale_cells = enqueue_run_stale_cells
        threading.Thread(
            target=watch_modules,
            args=(
                self.graph,
                self.reloader,
                self.mode,
                self.enqueue_run_stale_cells,
                self.should_exit,
                self.run_is_processed,
                self.stream,
            ),
            daemon=True,
        ).start()

    def stop(self) -> None:
        self.should_exit.set()

#+END_SRC
* runner
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.runner
:END:
** __init__
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.runner.__init__
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/runner/__init__.py
:END:
*** Comment
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.

#+END_SRC
** cell_runner
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.runner.cell_runner
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/runner/cell_runner.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

import asyncio
import contextlib
import functools
import io
import signal
import threading
import traceback
from dataclasses import dataclass
from typing import TYPE_CHECKING, Any, Callable, Iterator, Optional, Union

from marimo._ast.cell import CellId_t, CellImpl
from marimo._config.config import ExecutionType, OnCellChangeType
from marimo._loggers import marimo_logger
from marimo._messaging.errors import (
    Error,
    MarimoExceptionRaisedError,
    MarimoStrictExecutionError,
    UnknownError,
)
from marimo._messaging.tracebacks import write_traceback
from marimo._runtime import dataflow
from marimo._runtime.control_flow import MarimoInterrupt, MarimoStopError
from marimo._runtime.executor import (
    MarimoMissingRefError,
    MarimoNameError,
    MarimoRuntimeException,
    execute_cell,
    execute_cell_async,
)
from marimo._runtime.marimo_pdb import MarimoPdb
from marimo._utils.variables import unmangle_local

#+END_SRC
*** Assignment LOGGER = marimo_logger()
#+BEGIN_SRC python
LOGGER = marimo_logger()

#+END_SRC
*** Function cell_filename
#+BEGIN_SRC python
if TYPE_CHECKING:
    from collections.abc import Sequence

    from marimo._runtime.context.types import ExecutionContext
    from marimo._runtime.runner.hooks_on_finish import OnFinishHookType
    from marimo._runtime.runner.hooks_post_execution import (
        PostExecutionHookType,
    )
    from marimo._runtime.runner.hooks_pre_execution import PreExecutionHookType
    from marimo._runtime.runner.hooks_preparation import PreparationHookType
    from marimo._runtime.state import State


def cell_filename(cell_id: CellId_t) -> str:
    """Filename to use when running cells through exec."""
    return f"<cell-{cell_id}>"

#+END_SRC
*** Assignment ErrorObjects = Union[BaseException, Error]
#+BEGIN_SRC python
ErrorObjects = Union[BaseException, Error]

#+END_SRC
*** @dataclass: Class RunResult
#+BEGIN_SRC python
@dataclass
class RunResult:
    # Raw output of cell: last expression
    output: Any
    # Exception raised by cell, if any
    exception: Optional[ErrorObjects]
    # Accumulated output: via imperative mo.output.append()
    accumulated_output: Any = None

    def success(self) -> bool:
        """Whether the cell expected successfully"""
        return self.exception is None

#+END_SRC
*** Class Runner
#+BEGIN_SRC python
class Runner:
    """Runner for a collection of cells."""

    def __init__(
        self,
        roots: set[CellId_t],
        graph: dataflow.DirectedGraph,
        glbls: dict[Any, Any],
        debugger: MarimoPdb | None,
        execution_mode: OnCellChangeType = "autorun",
        execution_type: ExecutionType = "relaxed",
        excluded_cells: set[CellId_t] | None = None,
        execution_context: Callable[
            [CellId_t], contextlib._GeneratorContextManager[ExecutionContext]
        ]
        | None = None,
        preparation_hooks: Sequence[PreparationHookType] | None = None,
        pre_execution_hooks: Sequence[PreExecutionHookType] | None = None,
        post_execution_hooks: Sequence[PostExecutionHookType] | None = None,
        on_finish_hooks: Sequence[OnFinishHookType] | None = None,
    ):
        self.graph = graph
        self.debugger = debugger
        self.excluded_cells = excluded_cells or set()

        # injected context and hooks
        self.execution_context = execution_context
        self.preparation_hooks: Sequence[Callable[["Runner"], Any]] = (
            preparation_hooks or []
        )
        self.pre_execution_hooks: Sequence[
            Callable[[CellImpl, "Runner"], Any]
        ] = pre_execution_hooks or []
        self.post_execution_hooks: Sequence[
            Callable[[CellImpl, "Runner", RunResult], Any]
        ] = post_execution_hooks or []
        self.on_finish_hooks: Sequence[Callable[["Runner"], Any]] = (
            on_finish_hooks or []
        )

        # runtime globals
        self.glbls = glbls
        self.execution_mode: OnCellChangeType = execution_mode
        self.execution_type = execution_type

        # cells that the runner will run, subtracting out cells with errors:
        #
        # cells with errors can't be run, but are still in the graph
        # so that they can be transitioned out of error if a future
        # run request repairs the graph
        self.roots = roots
        self.cells_to_run: list[CellId_t]

        self.cells_to_run = Runner.compute_cells_to_run(
            self.graph, self.roots, self.excluded_cells, self.execution_mode
        )

        # map from a cell that was cancelled to its descendants that have
        # not yet run:
        self.cells_cancelled: dict[CellId_t, set[CellId_t]] = {}
        # whether the runner has been interrupted
        self.interrupted = False
        # mapping from cell_id to exception it raised
        self.exceptions: dict[CellId_t, ErrorObjects] = {}

        # each cell's position in the run queue
        self._run_position = {
            cell_id: index for index, cell_id in enumerate(self.cells_to_run)
        }

    @staticmethod
    def compute_cells_to_run(
        graph: dataflow.DirectedGraph,
        roots: set[CellId_t],
        excluded_cells: set[CellId_t],
        execution_mode: OnCellChangeType,
    ) -> list[CellId_t]:
        # Runner always runs stale ancestors, if any.
        cells_to_run = roots.union(
            dataflow.transitive_closure(
                graph,
                roots,
                children=False,
                inclusive=False,
                predicate=lambda cell: cell.stale,
            )
        )
        if execution_mode == "autorun":
            # in autorun/eager mode, descendants are also run;
            cells_to_run = dataflow.transitive_closure(
                graph, cells_to_run, relatives=dataflow.import_block_relatives
            )

        return dataflow.topological_sort(
            graph,
            cells_to_run - excluded_cells,
        )

    # Adapted from
    # https://github.com/ipython/ipykernel/blob/eddd3e666a82ebec287168b0da7cfa03639a3772/ipykernel/ipkernel.py#L312  # noqa: E501
    @staticmethod
    @contextlib.contextmanager
    def _cancel_on_sigint(future: asyncio.Future[Any]) -> Iterator[None]:
        """ContextManager for capturing SIGINT and cancelling a future

        SIGINT raises in the event loop when running async code,
        but we want it to halt a coroutine.

        Ideally, it would raise KeyboardInterrupt, but this turns it into a
        CancelledError.
        """
        sigint_future: asyncio.Future[int] = asyncio.Future()

        # whichever future finishes first,
        # cancel the other one
        def cancel_unless_done(f: asyncio.Future[Any], _: Any) -> None:
            if f.cancelled() or f.done():
                return
            f.cancel()

        # when sigint finishes,
        # abort the coroutine with CancelledError
        sigint_future.add_done_callback(
            functools.partial(cancel_unless_done, future)
        )
        # when the main future finishes,
        # stop watching for SIGINT events
        future.add_done_callback(
            functools.partial(cancel_unless_done, sigint_future)
        )

        def handle_sigint(*_: Any) -> None:
            if sigint_future.cancelled() or sigint_future.done():
                return
            # mark as done, to trigger cancellation
            sigint_future.set_result(1)

        # set the custom sigint handler during this context
        save_sigint = signal.signal(signal.SIGINT, handle_sigint)
        try:
            yield
        finally:
            # restore the previous sigint handler
            signal.signal(signal.SIGINT, save_sigint)

    def cancel(self, cell_id: CellId_t) -> None:
        """Mark a cell (and its descendants) as cancelled."""
        self.cells_cancelled[cell_id] = set(
            cid
            for cid in dataflow.transitive_closure(self.graph, set([cell_id]))
            if cid in self.cells_to_run
        )
        for cid in self.cells_cancelled[cell_id]:
            self.graph.cells[cid].set_run_result_status("cancelled")

    def cancelled(self, cell_id: CellId_t) -> bool:
        """Return whether a cell has been cancelled."""
        return any(
            cell_id in cancelled for cancelled in self.cells_cancelled.values()
        )

    def pending(self) -> bool:
        """Whether there are more cells to run."""
        return not self.interrupted and len(self.cells_to_run) > 0

    def _get_run_position(self, cell_id: CellId_t) -> Optional[int]:
        """Position in the original run queue"""
        return (
            self._run_position[cell_id]
            if cell_id in self._run_position
            else None
        )

    def _runs_after(
        self, source: CellId_t, target: CellId_t
    ) -> Optional[bool]:
        """Compare run positions.

        Returns `True` if source runs after target, `False` if target runs
        after source, or `None` if not comparable
        """
        source_pos = self._get_run_position(source)
        target_pos = self._get_run_position(target)
        if source_pos is None or target_pos is None:
            return None
        return source_pos > target_pos

    def resolve_state_updates(
        self,
        state_updates: dict[State[Any], CellId_t],
    ) -> set[CellId_t]:
        """
        Get cells that need to be run as a consequence of state updates

        A cell is marked as needing to run if all of the following are true:

            1. The runner was not interrupted.
            2. It was not already run after its setter was called.
            3. It isn't the cell that called the setter (unless the state
               object was configured to allow self loops).
            4. It is not errored (unable to run) or cancelled.
            5. It has among its refs the state object whose setter
               was invoked.

        (3) means that a state update in a given cell will never re-trigger
        the same cell to run. This is similar to how interacting with
        a UI element in the cell that created it won't re-trigger the cell,
        and this behavior is useful when tying UI elements together with a
        state object.

        **Arguments.**

        - state_updates: mapping from state object to the cell that last ran
          its setter
        - errored_cells: cell ids that are unable to run
        """
        # No updates when the runner is interrupted (condition 1)
        if self.interrupted:
            return set()

        cids_to_run: set[CellId_t] = set()
        for state, setter_cell_id in state_updates.items():
            for cid, cell in self.graph.cells.items():
                # Don't re-run cells that already ran with new state (2)
                if self._runs_after(source=cid, target=setter_cell_id):
                    continue
                # No self-loops (3)
                if cid == setter_cell_id and not state.allow_self_loops:
                    continue
                # No errorred/cancelled cells (4)
                if cid in self.excluded_cells or self.cancelled(cid):
                    continue
                # State object in refs (5)
                for ref in cell.refs:
                    # run this cell if any of its refs match the state object
                    # by object ID (via is operator)
                    if ref in self.glbls and self.glbls[ref] is state:
                        cids_to_run.add(cid)
        return cids_to_run

    def pop_cell(self) -> CellId_t:
        """Get the next cell to run."""
        return self.cells_to_run.pop(0)

    async def run(self, cell_id: CellId_t) -> RunResult:
        """Run a cell."""

        cell = self.graph.cells[cell_id]
        try:
            if cell.is_coroutine():
                return_value_future = asyncio.ensure_future(
                    execute_cell_async(
                        cell,
                        self.glbls,
                        self.graph,
                        execution_type=self.execution_type,
                    )
                )
                if threading.current_thread() == threading.main_thread():
                    # edit mode: need to handle user interrupts
                    with Runner._cancel_on_sigint(return_value_future):
                        return_value = await return_value_future
                else:
                    # run mode: can't use signal.signal, not interruptible
                    # by user anyway.
                    return_value = await return_value_future
            else:
                return_value = execute_cell(
                    cell,
                    self.glbls,
                    self.graph,
                    execution_type=self.execution_type,
                )
            run_result = RunResult(output=return_value, exception=None)
        except asyncio.exceptions.CancelledError:
            # User interrupt
            # interrupt the entire runner
            # Async cells can only be cancelled via a user interrupt
            run_result = RunResult(output=None, exception=MarimoInterrupt())
            # Still provide a general traceback.
            tmpio = io.StringIO()
            traceback.print_exc(file=tmpio)
            tmpio.seek(0)
            write_traceback(tmpio.read())
        # Strict mode errors may also raise errors outside of execution.
        except MarimoNameError as e:
            self.cancel(cell_id)
            strict_exception = MarimoStrictExecutionError(str(e), e.ref, None)
            run_result = RunResult(
                output=strict_exception, exception=strict_exception
            )
        except MarimoMissingRefError as e:
            # In strict mode, marimo refuses to evaluate a cell if there are
            # missing definitions. Since the cell hasn't run, this is a pre
            # check error, but still mark descendants as cancelled.
            self.cancel(cell_id)
            ref, blamed_cell = self._get_blamed_cell(e)
            name_output = MarimoStrictExecutionError(
                "marimo was unable to resolve "
                f"a reference to `{ref}` in cell : ",
                ref,
                blamed_cell,
            )
            run_result = RunResult(output=name_output, exception=name_output)
        # Should cover all cell runtime exceptions.
        except MarimoRuntimeException as e:
            print_traceback = True
            output: Any = None
            unwrapped_exception: Optional[BaseException] = e.__cause__
            exception: Optional[ErrorObjects] = unwrapped_exception

            # Exceptions trigger cancellation of descendants.
            self.cancel(cell_id)

            if isinstance(exception, MarimoMissingRefError):
                ref, blamed_cell = self._get_blamed_cell(exception)
                # All MarimoMissingRefErrors should be caused caused by
                # NameErrors if they are the cause of MarimoRuntimeExceptions.
                if exception.name_error is not None:
                    unwrapped_exception = exception.name_error
                # Provide output context for said missing reference errors.
                if self.execution_type == "strict":
                    output = MarimoExceptionRaisedError(
                        f"marimo came across the undefined variable `{ref}` "
                        "during runtime. This is possible in strict mode when "
                        "static analysis is unable to properly resolve the "
                        "reference due  to direct access (e.g. "
                        "`globals()['var']`) or circuitous definitions (e.g.  "
                        "by reassigning variables to different functions). If "
                        "this failure is not the result of either of these "
                        "cases, please consider reporting this issue to "
                        "https://github.com/marimo-team/marimo/issues. "
                        "Definition expected in cell : ",
                        "NameError",
                        blamed_cell,
                    )
                    exception = output
                elif blamed_cell != cell_id:
                    output = MarimoExceptionRaisedError(
                        f"marimo came across the undefined variable `{ref}` "
                        "during runtime. Definition expected in cell : ",
                        "NameError",
                        blamed_cell,
                    )
                    exception = output
                else:
                    # Default to regular error for self reference in relaxed
                    # mode.
                    exception = unwrapped_exception

            # Handle other special runtime errors.
            elif isinstance(unwrapped_exception, ModuleNotFoundError):
                self.missing_packages = True

            elif isinstance(unwrapped_exception, MarimoStopError):
                output = unwrapped_exception.output
                exception = unwrapped_exception
                # don't print a traceback, since quitting is the intended
                # behavior (like sys.exit())
                print_traceback = False

            run_result = RunResult(output=output, exception=exception)
            if print_traceback:
                tmpio = io.StringIO()
                # The executors explicitly raise cell exceptions from base
                # exceptions such that the stack trace is cleaner.
                # Verbosity is for Python < 3.10 compat
                # See https://docs.python.org/3/library/traceback.html
                exception_type = (
                    type(unwrapped_exception) if unwrapped_exception else None
                )
                maybe_traceback = (
                    unwrapped_exception.__traceback__
                    if unwrapped_exception
                    else None
                )
                traceback.print_exception(
                    exception_type,
                    unwrapped_exception,
                    maybe_traceback,
                    file=tmpio,
                )
                tmpio.seek(0)
                write_traceback(tmpio.read())
        except BaseException as e:
            # Check that MarimoRuntimeException has't already handled the
            # error, since exceptions fall through except blocks.
            # If not, then this is an unexpected error.
            if not isinstance(e, MarimoRuntimeException):
                LOGGER.error(f"Unexpected error type: {e}")
                self.cancel(cell_id)
                unknown_error = UnknownError(f"{e}")
                run_result = RunResult(output=None, exception=unknown_error)
                tmpio = io.StringIO()
                traceback.print_exc(file=tmpio)
                tmpio.seek(0)
                write_traceback(tmpio.read())
        finally:
            # Mark as interrupted if the cell raised a MarimoInterrupt
            # Set here since failed async can also trigger an Interrupt.
            if isinstance(run_result.exception, MarimoInterrupt):
                self.interrupted = True

            # if a debugger is active, force it to skip past marimo code.
            try:
                # Bdb defines the botframe attribute and sets it to non-None
                # when it starts up
                if (
                    self.debugger is not None
                    and hasattr(self.debugger, "botframe")
                    and self.debugger.botframe is not None
                ):
                    self.debugger.set_continue()
            except Exception as debugger_error:
                # This has never been hit, but just in case -- don't want
                # to crash the kernel.
                LOGGER.error(
                    """Internal marimo error. Please copy this message and
                    paste it in a GitHub issue:

                    https://github.com/marimo-team/marimo/issues

                    An exception raised attempting to continue debugger (%s).
                    """,
                    str(debugger_error),
                )

        if run_result.exception is not None:
            self.exceptions[cell_id] = run_result.exception

        return run_result

    def _get_blamed_cell(
        self, e: MarimoMissingRefError
    ) -> tuple[str, Optional[CellId_t]]:
        ref = e.ref
        blamed_cell = None
        try:
            (blamed_cell, *_) = self.graph.get_defining_cells(ref)
        except KeyError:
            # The reference is not found anywhere else in the graph
            # but it might be private
            ref, var_cell_id = unmangle_local(ref)
            if var_cell_id:
                blamed_cell = var_cell_id
        return ref, blamed_cell

    async def run_all(self) -> None:
        LOGGER.debug("Running preparation hooks")
        for prep_hook in self.preparation_hooks:
            prep_hook(self)

        while self.pending():
            cell_id = self.pop_cell()
            LOGGER.debug("Cell runner processing %s", cell_id)
            cell = self.graph.cells[cell_id]

            # Update run result status for cells that won't run.
            #
            # Hack: frontend sets status to queued on run, so we also have to
            # set runtime_state to get FE to transition.
            if self.cancelled(cell_id):
                LOGGER.debug("%s cancelled", cell_id)
                cell.set_run_result_status("cancelled")
                cell.set_runtime_state("idle")
                continue
            if cell.config.disabled:
                LOGGER.debug("%s disabled", cell_id)
                cell.set_run_result_status("disabled")
                cell.set_runtime_state("idle")
                continue
            if self.graph.is_disabled(cell_id):
                LOGGER.debug("%s disabled transitively", cell_id)
                cell.set_run_result_status("disabled")
                cell.set_runtime_state("disabled-transitively")
                continue

            LOGGER.debug("Running pre_execution hooks")
            for pre_hook in self.pre_execution_hooks:
                pre_hook(cell, self)
            LOGGER.debug("Running cell %s", cell_id)
            if self.execution_context is not None:
                with self.execution_context(cell_id) as exc_ctx:
                    run_result = await self.run(cell_id)
                    run_result.accumulated_output = exc_ctx.output
            else:
                run_result = await self.run(cell_id)
            LOGGER.debug("Running post_execution hooks")
            for post_hook in self.post_execution_hooks:
                post_hook(cell, self, run_result)

        LOGGER.debug("Running on_finish hooks")
        for finish_hook in self.on_finish_hooks:
            finish_hook(self)

#+END_SRC
** hooks
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.runner.hooks
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/runner/hooks.py
:END:
*** Assignment __all__
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
__all__ = [
    # hooks to run before the runner starts running its subgraph
    "PREPARATION_HOOKS",
    # hooks to run right before each cell is run
    "PRE_EXECUTION_HOOKS",
    # hooks to run right after each cell is run
    "POST_EXECUTION_HOOKS",
    # hooks to run once the runner has finished executing its subgraph
    "ON_FINISH_HOOKS",
]

#+END_SRC
*** Import
#+BEGIN_SRC python
from marimo._runtime.runner.hooks_on_finish import ON_FINISH_HOOKS
from marimo._runtime.runner.hooks_post_execution import POST_EXECUTION_HOOKS
from marimo._runtime.runner.hooks_pre_execution import PRE_EXECUTION_HOOKS
from marimo._runtime.runner.hooks_preparation import PREPARATION_HOOKS

#+END_SRC
** hooks_on_finish
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.runner.hooks_on_finish
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/runner/hooks_on_finish.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import Callable

from marimo import _loggers
from marimo._messaging.errors import (
    Error,
    MarimoAncestorPreventedError,
    MarimoAncestorStoppedError,
    MarimoExceptionRaisedError,
    MarimoInterruptionError,
    MarimoStrictExecutionError,
)
from marimo._messaging.ops import CellOp
from marimo._runtime.control_flow import MarimoStopError
from marimo._runtime.runner import cell_runner
from marimo._tracer import kernel_tracer

#+END_SRC
*** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
LOGGER = _loggers.marimo_logger()

#+END_SRC
*** Assignment OnFinishHookType = Callable[[cell_runner.Runner], None]
#+BEGIN_SRC python
OnFinishHookType = Callable[[cell_runner.Runner], None]

#+END_SRC
*** @kernel_tracer.start_as_current_span("send_interrupt_errors"): Function _send_interrupt_errors
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("send_interrupt_errors")
def _send_interrupt_errors(runner: cell_runner.Runner) -> None:
    if runner.cells_to_run:
        assert runner.interrupted
        for cid in runner.cells_to_run:
            # `cid` was not run
            runner.graph.cells[cid].set_runtime_state("idle")
            CellOp.broadcast_error(
                data=[MarimoInterruptionError()],
                # these cells are transitioning from queued to stopped
                # (interrupted); they didn't get to run, so their consoles
                # reflect a previous run and should be cleared
                clear_console=True,
                cell_id=cid,
            )

#+END_SRC
*** @kernel_tracer.start_as_current_span("send_cancellation_errors"): Function _send_cancellation_errors
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("send_cancellation_errors")
def _send_cancellation_errors(runner: cell_runner.Runner) -> None:
    for raising_cell in runner.cells_cancelled:
        for cid in runner.cells_cancelled[raising_cell]:
            # `cid` was not run
            cell = runner.graph.cells[cid]
            if cell.runtime_state != "idle":
                # the cell raising an exception will already be
                # idle, but its descendants won't be.
                cell.set_runtime_state("idle")

            exception = runner.exceptions[raising_cell]
            data: Error
            if isinstance(exception, MarimoStopError):
                data = MarimoAncestorStoppedError(
                    msg=(
                        "This cell wasn't run because an "
                        "ancestor was stopped with `mo.stop`: "
                    ),
                    raising_cell=raising_cell,
                )
            elif isinstance(exception, MarimoStrictExecutionError):
                data = MarimoAncestorPreventedError(
                    msg=(
                        "This cell wasn't run because an "
                        f"ancestor failed to resolve the "
                        f"reference `{exception.ref}` : "
                    ),
                    raising_cell=raising_cell,
                    blamed_cell=exception.blamed_cell,
                )
            else:
                exception_type = type(runner.exceptions[raising_cell]).__name__
                data = MarimoExceptionRaisedError(
                    msg=(
                        "An ancestor raised an exception "
                        f"({exception_type}): "
                    ),
                    exception_type=exception_type,
                    raising_cell=raising_cell,
                )
            CellOp.broadcast_error(
                data=[data],
                # these cells are transitioning from queued to stopped
                # (interrupted); they didn't get to run, so their consoles
                # reflect a previous run and should be cleared
                clear_console=True,
                cell_id=cid,
            )

#+END_SRC
*** Assignment ON_FINISH_HOOKS
#+BEGIN_SRC python
ON_FINISH_HOOKS: list[OnFinishHookType] = [
    _send_interrupt_errors,
    _send_cancellation_errors,
]

#+END_SRC
** hooks_post_execution
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.runner.hooks_post_execution
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/runner/hooks_post_execution.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import Callable

from marimo import _loggers
from marimo._ast.cell import CellImpl
from marimo._data.get_datasets import (
    get_datasets_from_duckdb,
    get_datasets_from_variables,
    has_updates_to_datasource,
)
from marimo._dependencies.dependencies import DependencyManager
from marimo._messaging.cell_output import CellChannel
from marimo._messaging.errors import (
    MarimoExceptionRaisedError,
    MarimoInterruptionError,
    MarimoStrictExecutionError,
)
from marimo._messaging.ops import (
    CellOp,
    Datasets,
    VariableValue,
    VariableValues,
)
from marimo._messaging.tracebacks import write_traceback
from marimo._output import formatting
from marimo._plugins.ui._core.ui_element import UIElement
from marimo._runtime.context.types import get_context, get_global_context
from marimo._runtime.control_flow import MarimoInterrupt, MarimoStopError
from marimo._runtime.runner import cell_runner
from marimo._tracer import kernel_tracer
from marimo._utils.flatten import contains_instance

#+END_SRC
*** Assignment LOGGER = _loggers.marimo_logger()
#+BEGIN_SRC python
LOGGER = _loggers.marimo_logger()

#+END_SRC
*** Assignment PostExecutionHookType
#+BEGIN_SRC python
PostExecutionHookType = Callable[
    [CellImpl, cell_runner.Runner, cell_runner.RunResult], None
]

#+END_SRC
*** @kernel_tracer.start_as_current_span("set_imported_defs"): Function _set_imported_defs
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("set_imported_defs")
def _set_imported_defs(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    del run_result
    LOGGER.debug("Acquiring graph lock to update cell import workspace")
    with runner.graph.lock:
        LOGGER.debug("Acquired graph lock to update import workspace.")
        if cell.import_workspace.is_import_block:
            cell.import_workspace.imported_defs = set(
                name for name in cell.defs if name in runner.glbls
            )

#+END_SRC
*** @kernel_tracer.start_as_current_span("set_status_idle"): Function _set_status_idle
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("set_status_idle")
def _set_status_idle(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    del run_result
    del runner
    cell.set_runtime_state(status="idle")

#+END_SRC
*** @kernel_tracer.start_as_current_span("set_run_result_status"): Function _set_run_result_status
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("set_run_result_status")
def _set_run_result_status(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    if isinstance(run_result.exception, MarimoInterruptionError):
        cell.set_run_result_status("interrupted")
    elif runner.cancelled(cell.cell_id):
        cell.set_run_result_status("cancelled")
    elif run_result.exception is not None:
        cell.set_run_result_status("exception")
    else:
        cell.set_run_result_status("success")

#+END_SRC
*** @kernel_tracer.start_as_current_span("broadcast_variables"): Function _broadcast_variables
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("broadcast_variables")
def _broadcast_variables(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    del run_result
    values = [
        VariableValue(
            name=variable,
            value=(
                runner.glbls[variable] if variable in runner.glbls else None
            ),
        )
        for variable in cell.defs
    ]
    if values:
        VariableValues(variables=values).broadcast()

#+END_SRC
*** @kernel_tracer.start_as_current_span("broadcast_datasets"): Function _broadcast_datasets
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("broadcast_datasets")
def _broadcast_datasets(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    del run_result
    tables = get_datasets_from_variables(
        [
            (variable, runner.glbls[variable])
            for variable in cell.defs
            if variable in runner.glbls
        ]
    )
    if tables:
        LOGGER.debug("Broadcasting data tables")
        Datasets(tables=tables).broadcast()

#+END_SRC
*** @kernel_tracer.start_as_current_span("broadcast_duckdb_tables"): Function _broadcast_duckdb_tables
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("broadcast_duckdb_tables")
def _broadcast_duckdb_tables(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    del run_result
    del runner
    if not DependencyManager.duckdb.has():
        return

    try:
        sqls = cell.sqls
        if not sqls:
            return
        modifies_datasources = any(
            has_updates_to_datasource(sql) for sql in sqls
        )
        if not modifies_datasources:
            return

        tables = get_datasets_from_duckdb()
        if not tables:
            return

        LOGGER.debug("Broadcasting duckdb tables")
        Datasets(tables=tables, clear_channel="duckdb").broadcast()
    except Exception:
        return

#+END_SRC
*** @kernel_tracer.start_as_current_span("store_reference_to_output"): Function _store_reference_to_output
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("store_reference_to_output")
def _store_reference_to_output(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    del runner

    # Stores a reference to the output if it contains a UIElement;
    # this is required to make RPCs work for unnamed UI elements.
    if isinstance(run_result.output, UIElement):
        cell.set_output(run_result.output)
    elif run_result.output is not None:
        if contains_instance(run_result.output, UIElement):
            cell.set_output(run_result.output)

#+END_SRC
*** Function _store_state_reference
#+BEGIN_SRC python
def _store_state_reference(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    del run_result
    # Associate state variables with variable names
    ctx = get_context()
    ctx.state_registry.register_scope(runner.glbls, defs=cell.defs)
    privates = set().union(
        *[cell.temporaries for cell in ctx.graph.cells.values()]
    )
    ctx.state_registry.retain_active_states(
        set(runner.graph.definitions.keys()) | privates
    )

#+END_SRC
*** @kernel_tracer.start_as_current_span("broadcast_outputs"): Function _broadcast_outputs
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("broadcast_outputs")
def _broadcast_outputs(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    # TODO: clean this logic up ...
    #
    # Send the output to the frontend
    #
    # Don't rebroadcast an output that was already sent
    #
    # 1. if run_result.output is not None, need to send it
    # 2. otherwise if exc_ctx.output is None, then need to send
    #    the (empty) output (to clear it)
    should_send_output = (
        run_result.output is not None or run_result.accumulated_output is None
    )
    if (
        run_result.success()
        or isinstance(run_result.exception, MarimoStopError)
    ) and should_send_output:

        def format_output() -> formatting.FormattedOutput:
            formatted_output = formatting.try_format(run_result.output)

            if formatted_output.exception is not None:
                # Try a plain formatter; maybe an opinionated one failed.
                formatted_output = formatting.try_format(
                    run_result.output, include_opinionated=False
                )

            if formatted_output.traceback is not None:
                write_traceback(formatted_output.traceback)
            return formatted_output

        if runner.execution_context is not None:
            with runner.execution_context(cell.cell_id):
                formatted_output = format_output()
        else:
            formatted_output = format_output()

        CellOp.broadcast_output(
            channel=CellChannel.OUTPUT,
            mimetype=formatted_output.mimetype,
            data=formatted_output.data,
            cell_id=cell.cell_id,
            status=None,
        )
    elif isinstance(run_result.exception, MarimoStrictExecutionError):
        LOGGER.debug("Cell %s raised a strict error", cell.cell_id)
        # Cell never runs, so clear console
        CellOp.broadcast_error(
            data=[run_result.output],
            clear_console=True,
            cell_id=cell.cell_id,
        )
    elif isinstance(run_result.exception, MarimoInterrupt):
        LOGGER.debug("Cell %s was interrupted", cell.cell_id)
        # don't clear console because this cell was running and
        # its console outputs are not stale
        CellOp.broadcast_error(
            data=[MarimoInterruptionError()],
            clear_console=False,
            cell_id=cell.cell_id,
        )
    elif isinstance(run_result.exception, MarimoExceptionRaisedError):
        CellOp.broadcast_error(
            data=[run_result.exception],
            clear_console=False,
            cell_id=cell.cell_id,
        )
    elif run_result.exception is not None:
        LOGGER.debug(
            "Cell %s raised %s",
            cell.cell_id,
            type(run_result.exception).__name__,
        )
        # don't clear console because this cell was running and
        # its console outputs are not stale
        exception_type = type(run_result.exception).__name__
        CellOp.broadcast_error(
            data=[
                MarimoExceptionRaisedError(
                    msg="This cell raised an exception: %s%s"
                    % (
                        exception_type,
                        (
                            f"('{str(run_result.exception)}')"
                            if str(run_result.exception)
                            else ""
                        ),
                    ),
                    exception_type=exception_type,
                    raising_cell=None,
                )
            ],
            clear_console=False,
            cell_id=cell.cell_id,
        )

#+END_SRC
*** @kernel_tracer.start_as_current_span("reset_matplotlib_context"): Function _reset_matplotlib_context
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("reset_matplotlib_context")
def _reset_matplotlib_context(
    cell: CellImpl,
    runner: cell_runner.Runner,
    run_result: cell_runner.RunResult,
) -> None:
    del cell
    del run_result
    if get_global_context().mpl_installed:
        # ensures that every cell gets a fresh axis.
        exec("__marimo__._output.mpl.close_figures()", runner.glbls)

#+END_SRC
*** Assignment POST_EXECUTION_HOOKS
#+BEGIN_SRC python
POST_EXECUTION_HOOKS: list[PostExecutionHookType] = [
    _set_imported_defs,
    _set_run_result_status,
    _store_reference_to_output,
    _store_state_reference,
    _broadcast_variables,
    _broadcast_datasets,
    _broadcast_duckdb_tables,
    _broadcast_outputs,
    _reset_matplotlib_context,
    # set status to idle after all post-processing is done, in case the
    # other hooks take a long time (broadcast outputs can take a long time
    # if a formatter is slow).
    _set_status_idle,
]

#+END_SRC
** hooks_pre_execution
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.runner.hooks_pre_execution
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/runner/hooks_pre_execution.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import Callable

from marimo._ast.cell import CellImpl
from marimo._runtime.runner import cell_runner
from marimo._tracer import kernel_tracer

#+END_SRC
*** Assignment PreExecutionHookType = Callable[[CellImpl, cell_runner.Runner], None]
#+BEGIN_SRC python
PreExecutionHookType = Callable[[CellImpl, cell_runner.Runner], None]

#+END_SRC
*** @kernel_tracer.start_as_current_span("set_staleness"): Function _set_staleness
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("set_staleness")
def _set_staleness(
    cell: CellImpl,
    runner: cell_runner.Runner,
) -> None:
    graph = runner.graph

    if runner.execution_mode == "lazy" and not graph.is_any_ancestor_stale(
        cell.cell_id
    ):
        # TODO: The above check could be omitted as an optimization as long as
        # parents are guaranteed to run before child.
        #
        # Only no longer stale if its parents are not stale
        cell.set_stale(stale=False)

#+END_SRC
*** @kernel_tracer.start_as_current_span("set_status_to_running"): Function _set_status_to_running
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("set_status_to_running")
def _set_status_to_running(
    cell: CellImpl,
    runner: cell_runner.Runner,
) -> None:
    del runner
    cell.set_runtime_state("running")

#+END_SRC
*** Assignment PRE_EXECUTION_HOOKS
#+BEGIN_SRC python
PRE_EXECUTION_HOOKS: list[PreExecutionHookType] = [
    _set_staleness,
    _set_status_to_running,
]

#+END_SRC
** hooks_preparation
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.runner.hooks_preparation
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/runner/hooks_preparation.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import Callable

from marimo._runtime import dataflow
from marimo._runtime.dataflow import import_block_relatives
from marimo._runtime.runner import cell_runner
from marimo._tracer import kernel_tracer

#+END_SRC
*** Assignment PreparationHookType = Callable[[cell_runner.Runner], None]
#+BEGIN_SRC python
PreparationHookType = Callable[[cell_runner.Runner], None]

#+END_SRC
*** @kernel_tracer.start_as_current_span("update_stale_statuses"): Function _update_stale_statuses
#+BEGIN_SRC python
@kernel_tracer.start_as_current_span("update_stale_statuses")
def _update_stale_statuses(runner: cell_runner.Runner) -> None:
    graph = runner.graph

    if runner.execution_mode == "lazy":
        for cid in dataflow.transitive_closure(
            graph,
            set(runner.cells_to_run),
            inclusive=False,
            relatives=import_block_relatives,
        ):
            graph.cells[cid].set_stale(stale=True)

    for cid in runner.cells_to_run:
        if graph.is_disabled(cid):
            graph.cells[cid].set_stale(stale=True)
        else:
            graph.cells[cid].set_runtime_state(status="queued")
            if graph.cells[cid].stale:
                if runner.execution_mode == "autorun":
                    graph.cells[cid].set_stale(stale=False)

#+END_SRC
*** Assignment PREPARATION_HOOKS: list[PreparationHookType] = [_update_stale_statuses]
#+BEGIN_SRC python
PREPARATION_HOOKS: list[PreparationHookType] = [_update_stale_statuses]

#+END_SRC
* utils
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.utils
:END:
** set_ui_element_request_manager
:PROPERTIES:
:LITERATE_ORG_MODULE: marimo._runtime.utils.set_ui_element_request_manager
:header-args: :tangle /Users/jingtao/projects/marimo/marimo/_runtime/utils/set_ui_element_request_manager.py
:END:
*** Import statements
#+BEGIN_SRC python
# Copyright 2024 Marimo. All rights reserved.
from __future__ import annotations

from typing import TYPE_CHECKING, Any

from marimo._plugins.ui._core.registry import UIElementId
from marimo._runtime.requests import SetUIElementValueRequest
from marimo._server.types import QueueType

#+END_SRC
*** Class SetUIElementRequestManager
#+BEGIN_SRC python
if TYPE_CHECKING:
    import asyncio


class SetUIElementRequestManager:
    def __init__(
        self,
        set_ui_element_queue: QueueType[SetUIElementValueRequest]
        | asyncio.Queue[SetUIElementValueRequest],
    ) -> None:
        self._set_ui_element_queue = set_ui_element_queue
        self._processed_request_tokens: set[str] = set()

    def process_request(
        self, request: SetUIElementValueRequest
    ) -> SetUIElementValueRequest | None:
        request_batch: list[SetUIElementValueRequest] = []
        if request.token not in self._processed_request_tokens:
            request_batch.append(request)
            self._processed_request_tokens.add(request.token)
        else:
            self._processed_request_tokens.remove(request.token)

        while not self._set_ui_element_queue.empty():
            r = self._set_ui_element_queue.get_nowait()
            if r.token not in self._processed_request_tokens:
                request_batch.append(r)
                self._processed_request_tokens.add(r.token)
            else:
                self._processed_request_tokens.remove(r.token)

        return self._merge_set_ui_element_requests(request_batch)

    def _merge_set_ui_element_requests(
        self,
        requests: list[SetUIElementValueRequest],
    ) -> SetUIElementValueRequest | None:
        if not requests:
            return None

        merged: dict[UIElementId, Any] = {}
        for request in requests:
            for ui_id, value in request.ids_and_values:
                merged[ui_id] = value
        return SetUIElementValueRequest(
            object_ids=list(merged.keys()),
            values=list(merged.values()),
            token="",
        )

#+END_SRC
